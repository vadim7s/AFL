{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original as of 28 Aug 2018\n",
    "\n",
    "def get_drive():\n",
    "    '''\n",
    "    this is to automate switching between home PC and laptop\n",
    "    it returns J:\\\\AFL\\\\ or D:\\\\AFL\\\\ depending if D:\\ is available\n",
    "    \n",
    "    No parameters required\n",
    "    '''\n",
    "    \n",
    "    import win32api\n",
    "    drives = win32api.GetLogicalDriveStrings()\n",
    "    drives = drives.split('\\000')[:-1]\n",
    "    if 'D:\\\\' in drives:\n",
    "        drive = 'D:\\\\AFL\\\\'\n",
    "    else:\n",
    "        drive = 'J:\\\\AFL\\\\'\n",
    "    return drive\n",
    "\n",
    "\n",
    "def get_proxy(proxy):\n",
    "        if proxy:\n",
    "            from os import environ\n",
    "            #pwd = input('Please enter your LAN Pwd')\n",
    "            environ[\"http_proxy\"]=\"http://c819325:sWeater78-@http-gw.tcif.telstra.com.au:8080\"\n",
    "            environ[\"https_proxy\"]=environ.get(\"http_proxy\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fix_round(round_in):\n",
    "    '''\n",
    "    this function convert Round values into sequential integers\n",
    "    '''\n",
    "    if round_in=='QF':\n",
    "        rnd='25'\n",
    "    elif round_in=='EF':\n",
    "        rnd='26'\n",
    "    elif round_in=='SF':\n",
    "        rnd='27'\n",
    "    elif round_in=='PF':\n",
    "        rnd='28'\n",
    "    elif round_in=='GF':\n",
    "        rnd='29'\n",
    "    elif round_in[0]=='R':\n",
    "        rnd=round_in[1:]\n",
    "    else:\n",
    "        rnd=round_in\n",
    "    return int(rnd)\n",
    "\n",
    "def fix_team_name(name):\n",
    "    '''\n",
    "    this function converts any team name to a consistent\n",
    "    set of  names which are usable for joins\n",
    "    '''\n",
    "    if 'Crows' in name:\n",
    "        team_name='Adelaide'\n",
    "    elif name.strip()=='Adelaide Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='AD':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='BL':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='Lions':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='CA':\n",
    "        team_name='Carlton'\n",
    "    elif name=='Blues':\n",
    "        team_name='Carlton'\n",
    "    elif name=='CW':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='Magpies':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='ES':\n",
    "        team_name='Essendon'\n",
    "    elif name=='Bombers':\n",
    "        team_name='Essendon'\n",
    "    elif name=='FR':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='Dockers':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='GE':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Geelong Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='GC':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Gold Coast Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='GWS Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GWS':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW Sydney':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='HW':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='Hawks':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='ME':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Demons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Deamons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='KA':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='NM':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='Kangaroos':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='PA':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='Power':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='RI':\n",
    "        team_name='Richmond'\n",
    "    elif name=='Tigers':\n",
    "        team_name='Richmond'\n",
    "    elif name=='SK':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='Saints':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='SY':\n",
    "        team_name='Sydney'\n",
    "    elif 'Swans' in name:\n",
    "        team_name='Sydney'\n",
    "    elif name=='WC':\n",
    "        team_name='West Coast'\n",
    "    elif name=='West Coast Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='WB':\n",
    "        team_name='Western Bulldogs'\n",
    "    elif name=='Bulldogs':\n",
    "        team_name='Western Bulldogs'\n",
    "    else:\n",
    "        team_name=name\n",
    "    return team_name\n",
    "\n",
    "def fix_venue(name):\n",
    "    if name=='AAMI':\n",
    "        ground = 'Olympic Park'\n",
    "    elif name=='ANZ':\n",
    "        ground = 'Stadium Australia'\n",
    "    elif name=='Adelaide':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Aurora':\n",
    "        ground = 'York Park'\n",
    "    elif name=='Blacktown':\n",
    "        ground='Blacktown'\n",
    "    elif name=='Blundstone Arena':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name=='Blundstone':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name==\"Cazaly's\":\n",
    "        ground= \"Cazaly's Stadium\"\n",
    "    elif name=='Domain':\n",
    "        ground='Subiaco'\n",
    "    elif name=='Etihad Stadium':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='Etihad':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='GMHBA Stadium':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='GMHBA':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='Gabba':\n",
    "        ground = 'Gabba'\n",
    "    elif name=='Jiangwan':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='Jiangwan Stadium, China':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='M.C.G':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='MCG':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='Mars Stadium, Ballarat':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Mars':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Metricon Stadium':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Metricon':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Perth':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='SCG':\n",
    "        ground='S.C.G.'\n",
    "    elif name=='Spotless Stadium':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='Spotless':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='UNSW Canberra Oval':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='StarTrack':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='Treager Park, Alice Springs':\n",
    "        ground='Traeger Park'\n",
    "    elif name=='TIO Stadium, Darwin':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='TIO':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='University of Tasmania Stadium':\n",
    "        ground='York Park'\n",
    "    elif name=='UTAS':\n",
    "        ground='York Park'\n",
    "    elif name=='Westpac':\n",
    "        ground='Wellington'\n",
    "    else:\n",
    "        ground=name\n",
    "    return ground\n",
    "\n",
    "def get_ladder(seas_from,seas_to,proxy=False):\n",
    "    '''\n",
    "    this is just to get the ladder history\n",
    "\n",
    "    Input required - update season from and to in the function call at the bottom\n",
    "    this function returns a dataframe for AFL ladder position history\n",
    "    seas_from - season to start from\n",
    "    seas_to - season end - inclusive\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    ladder = pd.DataFrame(columns=['Team','Games','Points','Percentage','Round','Position','Season'])\n",
    "    for season in range(seas_from-1,seas_to+1): \n",
    "        cur_url = 'http://afltables.com/afl/seas/'+str(season)+'.html'\n",
    "        dfs = pd.read_html(cur_url)\n",
    "\n",
    "        for df in dfs:\n",
    "            if df.columns.nlevels>1:\n",
    "                break\n",
    "            if len(df)>1 and 'Ladder' in df[0][0] and 'Rd' in df[0][0] and len(df.columns)>2:\n",
    "                rnd = df[0][0][3:5]\n",
    "                ldr = df.copy() \n",
    "                ldr = ldr.drop(0,0)\n",
    "                ldr.columns = ['Team','Games','Points','Percentage']\n",
    "                ldr['Round']=rnd\n",
    "                ldr['Position']=ldr.index\n",
    "                ldr['Season']=season\n",
    "                ladder = pd.concat([ladder,ldr])\n",
    "    ladder['Team'] = [fix_team_name(x) for x in ladder['Team']]\n",
    "    \n",
    "    # repeat last round for last and until 29\n",
    "    ladder_f = ladder.copy()\n",
    "    ladder_f.drop_duplicates(subset=['Team','Season'], keep='last', inplace=True)\n",
    "\n",
    "    # get last round for each season\n",
    "    ladder_y = ladder_f.copy()\n",
    "    ladder_y.drop_duplicates(subset=['Season'], keep='last', inplace=True)\n",
    "    ladder_y=ladder_y.drop(['Team','Games','Points','Percentage','Position'],1)\n",
    "    rnd=[]\n",
    "    seas=[]\n",
    "    for index, row in ladder_y.iterrows():\n",
    "        st = int(row.Round)\n",
    "        #print(type(st))\n",
    "        for i in range(st+1,30):\n",
    "            rnd.append(i)\n",
    "            seas.append(row.Season)\n",
    "    ldr = pd.DataFrame()\n",
    "    ldr['Season'] = seas\n",
    "    ldr['Round'] = rnd\n",
    "    #ldr = pd.merge(ladder_f.drop(['Round'],1),ldr,how='inner',on=['Season'])\n",
    "    ladder = pd.concat([ladder,ldr])\n",
    "    ladder = ladder.sort_values(by=['Team','Season'],axis=0)\n",
    "    ladder['PosOld']=ladder.Position.shift(1)  #previous ladder position taken\n",
    "    ladder = ladder.drop(['Position'],1)\n",
    "    ladder['Round']= [int(x) for x in ladder['Round']]\n",
    "    ladder=ladder.dropna(axis=0)\n",
    "    ladder['PosOld']= [int(x) for x in ladder['PosOld']]  \n",
    "    return ladder\n",
    "\n",
    "def get_fixture(proxy=False):\n",
    "    '''\n",
    "    this is to get AFL fixture from theroar.com.au\n",
    "    set proxy=True if you are on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    url='https://www.theroar.com.au/afl-draw/'\n",
    "    sauce = urllib.request.urlopen(url)\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "    fixture = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "\n",
    "    for x in soup.find_all('tbody'):\n",
    "        rnd_counter = 0\n",
    "\n",
    "        for y in x.find_all('tr'):\n",
    "\n",
    "            if y.find_all('strong'):\n",
    "                rnd_counter +=1\n",
    "\n",
    "            else:\n",
    "                if not y.find_all('h3') and 'Byes' not in y.text and 'TBC' not in y.text:\n",
    "                    dt,teams,venue,tm = y.text.strip().split('\\n')\n",
    "                    if dt == 'Sar Apr 21':\n",
    "                        dt = 'Sat Apr 21'\n",
    "\n",
    "                    dt = parser.parse(dt)\n",
    "                    if teams == 'North Melbourne Carlton':\n",
    "                            hm_team = 'North Melbourne'\n",
    "                            aw_team = 'Carlton'\n",
    "                    else:\n",
    "                        hm_team, aw_team = teams.split(' vs ')\n",
    "\n",
    "                    #print(rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue))\n",
    "                    df = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "                    df.loc[0]=[rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue)]\n",
    "                    fixture = pd.concat([fixture,df])\n",
    "    return fixture\n",
    "\n",
    "def get_odds_history(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this function gets odds history from footywire.com\n",
    "    min season from is 2010- so it will make the min date 2010 if less than that\n",
    "    set proxy=True if on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    if season_from<2010:\n",
    "        season_from=2010\n",
    "    odds_history=pd.DataFrame()\n",
    "    for season in range(season_from,season_to+1):\n",
    "        print('Getting odds for season',season,'...')\n",
    "        sauce = urllib.request.urlopen('https://www.footywire.com/afl/footy/afl_betting?year='+str(season))\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "\n",
    "        for x in soup.find_all('div',class_ ='datadiv'):\n",
    "            date=[]\n",
    "            venue=[]\n",
    "            team_HM=[]\n",
    "            odds_HM=[]\n",
    "            team_AW=[]\n",
    "            odds_AW=[]\n",
    "            counter =0\n",
    "\n",
    "            home_team_cursor = True\n",
    "            for y in x.find_all('tr'):\n",
    "\n",
    "                for z in y.find_all('td',class_='data'):\n",
    "                    counter = counter+1\n",
    "                    if z.has_attr('height'):\n",
    "                        counter = 0\n",
    "                        #print('new game ',z.text)\n",
    "                        date.append(z.text)\n",
    "                    elif z.has_attr('rowspan'):\n",
    "                        #print('venue ', z.text)\n",
    "                        venue.append(z.text)\n",
    "                    elif not z.has_attr('align'):\n",
    "                        if counter == 2:\n",
    "                            #print('Home team: ', z.text)\n",
    "                            team_HM.append(z.text)\n",
    "                            home_team_cursor=True    \n",
    "                        else:\n",
    "                            #print('Away team: ', z.text)\n",
    "                            counter = 0\n",
    "                            team_AW.append(z.text)\n",
    "                            home_team_cursor=False\n",
    "                    elif counter ==3 and not home_team_cursor:\n",
    "                        #print('away team odds: ',z.text)\n",
    "                        odds_AW.append(z.text)\n",
    "                    elif counter==5 and home_team_cursor:\n",
    "                        #print('home team odds: ',z.text)\n",
    "                        odds_HM.append(z.text)\n",
    "        odds = pd.DataFrame()\n",
    "        odds['Date']=[parser.parse(x,dayfirst=True) for x in date]\n",
    "        odds['Venue']=[fix_venue(x) for x in venue]\n",
    "        odds['HomeTeam']=[fix_team_name(x) for x in team_HM]\n",
    "        odds['OddsHome']=[x for x in odds_HM]\n",
    "        odds['AwayTeam']=[fix_team_name(x) for x in team_AW]\n",
    "        odds['OddsAway']=[x for x in odds_AW]\n",
    "        odds_history = pd.concat([odds_history,odds])  \n",
    "    odds = odds.drop_duplicates(subset=['Date','HomeTeam','AwayTeam'],keep='last')\n",
    "    return odds_history\n",
    "\n",
    "def get_games(proxy=False):\n",
    "    \n",
    "    '''\n",
    "    this function gets past games history\n",
    "    and gets attendance where it is available\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "        \n",
    "    col_specification =[(7, 15), (16, 33), (51, 68), (87, 116),(117,128)]\n",
    "    attend = pd.read_fwf('https://afltables.com/afl/stats/biglists/bg7.txt', \n",
    "                         colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    attend.columns = ['Attendance', 'HomeTeam', 'AwayTeam', 'Venue','Date']\n",
    "    attend['Date']  = pd.to_datetime(attend['Date'],dayfirst=True)\n",
    "    attend['Attendance'] = attend.Attendance.str.replace(r\"[\\*]\",'')\n",
    "    col_specification =[(0, 5), (7, 18), (24, 27), (29, 46),(47,63), (64,81),(82,99),(100,117)]\n",
    "    games= pd.read_fwf('http://afltables.com/afl/stats/biglists/bg3.txt', \n",
    "                       colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    games.columns = ['GameID', 'Date', 'Round', 'HomeTeam', 'ScoreHm','AwayTeam','ScoreAw','Venue']\n",
    "    games = pd.merge(games,attend,how='left',on=['Venue','Date','HomeTeam','AwayTeam'])\n",
    "\n",
    "    #fix rounds in games\n",
    "    games['Round'] = [fix_round(x) for x in games['Round']]\n",
    "    \n",
    "    games['Year']=games['Date'].map(lambda x: x.year)\n",
    "\n",
    "    #fix North Melb in games\n",
    "    games['HomeTeam'] = [fix_team_name(x) for x in games['HomeTeam']]\n",
    "    games['AwayTeam'] = [fix_team_name(x) for x in games['AwayTeam']]\n",
    "\n",
    "    # get result\n",
    "    games['H'] = [int(x.split('.')[2]) for x in games['ScoreHm']]\n",
    "    games['A'] = [int(x.split('.')[2]) for x in games['ScoreAw']]\n",
    "    games = games.drop(['ScoreHm','ScoreAw'],1)\n",
    "    games['Result'] = [round((x[0] /(x[0] +x[1])),3) for x in zip(games['H'],games['A'])]\n",
    "    #games = games.drop(['H','A'],1)\n",
    "    games['ResultWL'] = [1 if x>=0.5 else 0 for x in games.Result]\n",
    "    return games\n",
    "\n",
    "\n",
    "def get_team_performance_hist(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this is to get the team performance history\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BH'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CG'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BR'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CM'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    return team_performace\n",
    "\n",
    "\n",
    "def get_lineup(year,rnd,proxy=False):\n",
    "    '''\n",
    "    returns all available line-up for given year\n",
    "    year - current year you need to specify\n",
    "    rnd - current round where line-up has been released (could be improved into auto later)\n",
    "    proxy = True if on LAN\n",
    "    Pre-requisites: \n",
    "     1.TeamRef.csv - file which maps team names to AFL line-up abbreviated names\n",
    "     2.Fixture function is used\n",
    "\n",
    "    '''    \n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "\n",
    "    fixture = get_fixture(proxy)\n",
    "    fixture = fixture[fixture.Round==rnd]  #this limits to current round only\n",
    "    teams = pd.read_csv(get_drive()+'TeamRef.csv')\n",
    "\n",
    "    this_1 = pd.merge(fixture,teams,how=\"inner\",left_on=['HomeTeam'],right_on=['Team'])\n",
    "    this_2 = pd.merge(this_1,teams,how=\"inner\",left_on=['AwayTeam'],right_on=['Team'])\n",
    "    rounds = this_2.drop(['Team_x','Team_y'],1)\n",
    "    rounds['Game'] = [x + '-v-' +y for x,y in zip(rounds.AFL_Team_Nm_x,rounds.AFL_Team_Nm_y)]\n",
    "    rounds = rounds.drop(['AFL_Team_Nm_x','AFL_Team_Nm_y'],1)\n",
    "\n",
    "\n",
    "    # now get available line-up for player ref working\n",
    "\n",
    "    #rounds = rounds[rounds.Round<=max_round]    # needs updating, just available\n",
    "\n",
    "    lineup=pd.DataFrame()\n",
    "    for gm,rnd in zip(rounds['Game'],rounds['Round']):\n",
    "        url='http://www.afl.com.au/match-centre/'+str(year)+'/'+str(rnd)+'/'+gm\n",
    "        \n",
    "        sauce = urllib.request.urlopen(url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        plrs=[]\n",
    "        for x in soup.find_all('div',class_ ='lineup'):\n",
    "            for t in x.find_all('div',class_ ='text-inouts'):\n",
    "                team=''\n",
    "                for tm in t.find_all('h4'):\n",
    "                    team=tm.text\n",
    "\n",
    "                for p in t.find_all('div',class_ ='posGroup'):\n",
    "                    position=''\n",
    "                    for pos in p.find_all('p',class_ ='pos'):\n",
    "                        position =pos.text.strip()\n",
    "                    for player in p.find_all('li'):\n",
    "                        if position in ['B','HB','C','HF','F','Fol','I/C']:\n",
    "                            tms.append(team)\n",
    "                            plrs.append(player.text.strip().strip(','))\n",
    "\n",
    "        d = pd.DataFrame()\n",
    "        d['Team'] = tms\n",
    "        d['Player'] = plrs\n",
    "        lineup=pd.concat([lineup,d])\n",
    "    lineup['Team']=[fix_team_name(x) for x in lineup['Team']]\n",
    "    return lineup\n",
    "\n",
    "def get_player_base(proxy):\n",
    "    '''\n",
    "    !!! run only when need to update for new players !!!\n",
    "    returns a dataframe of player base table to enable to skip older players\n",
    "    e.g. players[players.DoB>'1975-01-01']  this gives 2.5k player subset\n",
    "    \n",
    "    typical use - to create Players.csv file in AFL directory - !!! pre-requisite for getting player performance\n",
    "\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    players = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days'])\n",
    "\n",
    "    # get player urls\n",
    "    links = []\n",
    "    for c in ascii_uppercase :\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/players'+c+'_idx.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "        for url in soup.find_all('a',href=True):\n",
    "            links.append('https://afltables.com/afl/stats/'+url['href'])\n",
    "    # now remove non-player links - ones that contain 'idx'\n",
    "    links = [item for item in links if 'players' in item and 'idx' not in item and 'afl_index' not in item]        \n",
    "\n",
    "    for cur_url in links:\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        #Name\n",
    "        x = soup.find_all('h1')\n",
    "        name = x[0].text\n",
    "\n",
    "        #DoB\n",
    "        found_dob=False\n",
    "\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Born:':\n",
    "                dob = x.next_sibling\n",
    "                found_dob=True\n",
    "                break\n",
    "        if found_dob:\n",
    "            dob=parser.parse(dob[0:11],dayfirst=True)\n",
    "        else:\n",
    "            dob = datetime.datetime(1900, 1, 1, 0, 0)\n",
    "\n",
    "        #Debut\n",
    "        found_debut = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Debut:':\n",
    "                debut = x.next_sibling\n",
    "                found_debut=True\n",
    "                break\n",
    "        if found_debut:\n",
    "            debut =debut.split()\n",
    "            debut1 = ''.join(c for c in debut[0] if c.isdigit())\n",
    "            if len(debut)>1:\n",
    "                debut2 = ''.join(c for c in debut[1] if c.isdigit())\n",
    "                debut = int(debut1)+int(debut2)/365\n",
    "            else:\n",
    "                debut = int(debut1)\n",
    "        else:\n",
    "            debut = 100\n",
    "        #age last played\n",
    "        found_last = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Last:':\n",
    "                age_last = x.next_sibling\n",
    "                found_last=True\n",
    "                break\n",
    "        if found_last:\n",
    "            age_last =age_last.split()\n",
    "            a1 = ''.join(c for c in age_last[0] if c.isdigit())\n",
    "            if len(age_last)>1:\n",
    "                a2 = ''.join(c for c in age_last[1] if c.isdigit())\n",
    "                age_last = int(a1)*365.25+int(a2) #in days\n",
    "            else:\n",
    "                age_last = int(a1)*365.25\n",
    "        else:\n",
    "            age_last = 40*365.25\n",
    "        today = datetime.datetime.today()\n",
    "        last_played_date = dob + datetime.timedelta(days=age_last)\n",
    "        since_last_game=today-last_played_date\n",
    "        df = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days','Last_Played_Date'])\n",
    "        df.loc[0]=[name,dob,cur_url,debut,age_last,last_played_date]\n",
    "        players = pd.concat([players,df])\n",
    "        print(name)\n",
    "    return players\n",
    "\n",
    "\n",
    "\n",
    "def get_player_perf(DoB_min='1975-01-01',proxy=False):\n",
    "    '''\n",
    "    Use this only once per complete round and save into CSV as it takes a while to run\n",
    "    this function returns a dataframe of player performance history\n",
    "    Entire player history is returned\n",
    "    DoB_min is limiting factor to get only player born after the date - for performance reasons\n",
    "    change the default if you need to go more back into older players or in reverse\n",
    "    Pre-requisite: Players.csv file exists in the AFL directory\n",
    "    set proxy=True when on office LAN\n",
    "    \n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "    players = pd.read_csv(get_drive()+'Players.csv')\n",
    "    players =players[players['DoB']>DoB_min]\n",
    "\n",
    "    player_stats = pd.DataFrame(columns=['Url','Team','Year'])\n",
    "\n",
    "    for cur_url in players.Url:\n",
    "        print(cur_url)\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        found=False\n",
    "        dfs=[]\n",
    "        for table in soup.find_all('table'):\n",
    "            #t1=tables[7]\n",
    "            t=table.find('tbody')\n",
    "            res = []\n",
    "            row = []\n",
    "            rows = t.find_all('tr')\n",
    "            for tr in rows:\n",
    "                for td in tr.find_all('td'):\n",
    "                    row.append(td.text)\n",
    "                res.append(row)\n",
    "                row = []\n",
    "            df=pd.DataFrame(data=res)\n",
    "\n",
    "            if len(df.columns)==28: # found first game\n",
    "                    found = True\n",
    "            if found:\n",
    "                h=table.find('thead')\n",
    "                h1 = h.find('tr')\n",
    "                h2 = h1.find('th')\n",
    "                header =h2.text\n",
    "                team_year = header.split('-')\n",
    "                team = team_year[0].strip()\n",
    "                year = team_year[1].strip()\n",
    "                df['Url']=cur_url\n",
    "                df['Team']=team\n",
    "                df['Year']=year\n",
    "                player_stats = pd.concat([player_stats,df])\n",
    "    player_stats = player_stats.rename(columns={0:'GameNo',1:'Opponent',2:'Round',3:'Result',4:'Jersey',5:'KI',6:'MK',7:'HB',8:'DI',9:'GL',10:'BH',11:'HO',12:'TK',13:'RB',14:'IF',15:'CL',16:'CG',17:'FF',18:'FA',19:'BR',20:'CP',21:'UP',22:'CM',23:'MI',24:'1%',25:'BO',26:'GA',27:'%P'})\n",
    "    player_stats['Round']=[fix_round(x) for x in player_stats['Round']]\n",
    "\n",
    "\n",
    "    games_set = get_games(proxy=False)\n",
    "\n",
    "\n",
    "\n",
    "    #create one game row for each team\n",
    "    gamesH = games_set.drop(['AwayTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesA = games_set.drop(['HomeTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesH=gamesH.rename(columns={'HomeTeam':'Team'})\n",
    "    gamesA=gamesA.rename(columns={'AwayTeam':'Team'})\n",
    "    gamesAH=pd.concat([gamesH,gamesA])\n",
    "    gamesAH['Year'] = [str(x) for x in gamesAH['Year']]\n",
    "    # get date and game id for each player record\n",
    "    player_stats=pd.merge(player_stats,gamesAH,how='inner',on=['Team','Year','Round'])\n",
    "    player_stats=player_stats.drop_duplicates(subset=['Url','Year','Round'],keep='first')\n",
    "    \n",
    "    return player_stats\n",
    "\n",
    "def get_pastXthis_opponent(x,team,opponent,dt,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, opponent, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    #last 3 against this team\n",
    "    tp = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Opponent']==opponent) ]  # later row.Team\n",
    "    tp = tp.sort_values(by=['Date'],ascending=False)\n",
    "    tp = tp.head(x)\n",
    "    tp = tp.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp_avg = tp.groupby(by='Team').aggregate('mean')\n",
    "    tp_avg.columns = [str(col) + '_lstXopp' for col in tp_avg.columns]\n",
    "    if tp_avg.shape[0]==0:\n",
    "        print('empty row generated for ', dt,' team:',team, ' vs.', opponent)\n",
    "    return tp_avg\n",
    "\n",
    "def get_pastXground(x,team,dt,venue,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date and venue of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    tp2 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Venue'] == venue)] \n",
    "    tp2 = tp2.sort_values(by=['Date'],ascending=False)\n",
    "    tp2 = tp2.head(x)\n",
    "    tp2 = tp2.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp2_avg = tp2.groupby(by='Team').aggregate('mean')\n",
    "    tp2_avg.columns = [str(col) + '_lstXgrd' for col in tp2_avg.columns]\n",
    "    if tp2_avg.shape[0]==0:\n",
    "        print('empty row generated for ',dt,' at ', venue,' team:',team)\n",
    "    return tp2_avg\n",
    "\n",
    "def get_pastX(x,team,dt,team_performaceDF,print_missing=False):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tp1 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt)] \n",
    "    tp1 = tp1.sort_values(by=['Date'],ascending=False)\n",
    "    tp1 = tp1.head(x)\n",
    "    tp1 = tp1.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp1_avg = tp1.groupby(by='Team').aggregate('mean')\n",
    "    tp1_avg.columns = [str(col) + '_lstX' for col in tp1_avg.columns]\n",
    "    if tp1_avg.shape[0]==0 and print_missing:\n",
    "        print('empty row generated for ', dt,' team:',team)\n",
    "    return tp1_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version after 27 Aug 2018 changes\n",
    "\n",
    "def get_drive():\n",
    "    '''\n",
    "    this is to automate switching between home PC and laptop\n",
    "    it returns J:\\\\AFL\\\\ or D:\\\\AFL\\\\ depending if D:\\ is available\n",
    "    \n",
    "    No parameters required\n",
    "    '''\n",
    "    \n",
    "    import win32api\n",
    "    drives = win32api.GetLogicalDriveStrings()\n",
    "    drives = drives.split('\\000')[:-1]\n",
    "    if 'D:\\\\' in drives:\n",
    "        drive = 'D:\\\\AFL\\\\'\n",
    "    else:\n",
    "        drive = 'J:\\\\AFL\\\\'\n",
    "    return drive\n",
    "\n",
    "\n",
    "def get_proxy(proxy):\n",
    "        if proxy:\n",
    "            from os import environ\n",
    "            #pwd = input('Please enter your LAN Pwd')\n",
    "            environ[\"http_proxy\"]=\"http://c819325:sWeater78-@http-gw.tcif.telstra.com.au:8080\"\n",
    "            environ[\"https_proxy\"]=environ.get(\"http_proxy\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fix_round(round_in):\n",
    "    '''\n",
    "    this function convert Round values into sequential integers\n",
    "    '''\n",
    "    if round_in=='QF':\n",
    "        rnd='25'\n",
    "    elif round_in=='EF':\n",
    "        rnd='26'\n",
    "    elif round_in=='SF':\n",
    "        rnd='27'\n",
    "    elif round_in=='PF':\n",
    "        rnd='28'\n",
    "    elif round_in=='GF':\n",
    "        rnd='29'\n",
    "    elif round_in[0]=='R':\n",
    "        rnd=round_in[1:]\n",
    "    else:\n",
    "        rnd=round_in\n",
    "    return int(rnd)\n",
    "\n",
    "def fix_team_name(name):\n",
    "    '''\n",
    "    this function converts any team name to a consistent\n",
    "    set of  names which are usable for joins\n",
    "    '''\n",
    "    if 'Crows' in name:\n",
    "        team_name='Adelaide'\n",
    "    elif name.strip()=='Adelaide Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='AD':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='BL':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='Lions':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='CA':\n",
    "        team_name='Carlton'\n",
    "    elif name=='Blues':\n",
    "        team_name='Carlton'\n",
    "    elif name=='CW':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='Magpies':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='ES':\n",
    "        team_name='Essendon'\n",
    "    elif name=='Bombers':\n",
    "        team_name='Essendon'\n",
    "    elif name=='FR':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='Dockers':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='GE':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Geelong Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='GC':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Gold Coast Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='GWS Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GWS':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW Sydney':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='HW':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='Hawks':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='ME':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Demons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Deamons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='KA':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='NM':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='Kangaroos':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='PA':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='Power':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='RI':\n",
    "        team_name='Richmond'\n",
    "    elif name=='Tigers':\n",
    "        team_name='Richmond'\n",
    "    elif name=='SK':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='Saints':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='SY':\n",
    "        team_name='Sydney'\n",
    "    elif 'Swans' in name:\n",
    "        team_name='Sydney'\n",
    "    elif name=='WC':\n",
    "        team_name='West Coast'\n",
    "    elif name=='West Coast Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='WB':\n",
    "        team_name='Western Bulldogs'\n",
    "    elif name=='Bulldogs':\n",
    "        team_name='Western Bulldogs'\n",
    "    else:\n",
    "        team_name=name\n",
    "    return team_name\n",
    "\n",
    "def fix_venue(name):\n",
    "    if name=='AAMI':\n",
    "        ground = 'Olympic Park'\n",
    "    elif name=='ANZ':\n",
    "        ground = 'Stadium Australia'\n",
    "    elif name=='Adelaide':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Aurora':\n",
    "        ground = 'York Park'\n",
    "    elif name=='Blacktown':\n",
    "        ground='Blacktown'\n",
    "    elif name=='Blundstone Arena':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name=='Blundstone':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name==\"Cazaly's\":\n",
    "        ground= \"Cazaly's Stadium\"\n",
    "    elif name=='Domain':\n",
    "        ground='Subiaco'\n",
    "    elif name=='Etihad Stadium':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='Etihad':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='GMHBA Stadium':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='GMHBA':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='Gabba':\n",
    "        ground = 'Gabba'\n",
    "    elif name=='Jiangwan':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='Jiangwan Stadium, China':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='M.C.G':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='MCG':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='Mars Stadium, Ballarat':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Mars':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Metricon Stadium':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Metricon':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Perth':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='SCG':\n",
    "        ground='S.C.G.'\n",
    "    elif name=='Spotless Stadium':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='Spotless':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='UNSW Canberra Oval':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='StarTrack':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='Treager Park, Alice Springs':\n",
    "        ground='Traeger Park'\n",
    "    elif name=='TIO Stadium, Darwin':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='TIO':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='University of Tasmania Stadium':\n",
    "        ground='York Park'\n",
    "    elif name=='UTAS':\n",
    "        ground='York Park'\n",
    "    elif name=='Westpac':\n",
    "        ground='Wellington'\n",
    "    else:\n",
    "        ground=name\n",
    "    return ground\n",
    "\n",
    "def get_ladder(seas_from,seas_to,proxy=False):\n",
    "    '''\n",
    "    this is just to get the ladder history\n",
    "\n",
    "    Input required - update season from and to in the function call at the bottom\n",
    "    this function returns a dataframe for AFL ladder position history\n",
    "    seas_from - season to start from\n",
    "    seas_to - season end - inclusive\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    ladder = pd.DataFrame(columns=['Team','Games','Points','Percentage','Round','Position','Season'])\n",
    "    for season in range(seas_from-1,seas_to+1): \n",
    "        cur_url = 'http://afltables.com/afl/seas/'+str(season)+'.html'\n",
    "        dfs = pd.read_html(cur_url)\n",
    "\n",
    "        for df in dfs:\n",
    "            if df.columns.nlevels>1:\n",
    "                break\n",
    "            if len(df)>1 and 'Ladder' in df[0][0] and 'Rd' in df[0][0] and len(df.columns)>2:\n",
    "                rnd = df[0][0][3:5]\n",
    "                ldr = df.copy() \n",
    "                ldr = ldr.drop(0,0)\n",
    "                ldr.columns = ['Team','Games','Points','Percentage']\n",
    "                ldr['Round']=rnd\n",
    "                ldr['Position']=ldr.index\n",
    "                ldr['Season']=season\n",
    "                ladder = pd.concat([ladder,ldr])\n",
    "    ladder['Team'] = [fix_team_name(x) for x in ladder['Team']]\n",
    "    \n",
    "    # repeat last round for last and until 29\n",
    "    ladder_f = ladder.copy()\n",
    "    ladder_f.drop_duplicates(subset=['Team','Season'], keep='last', inplace=True)\n",
    "\n",
    "    # get last round for each season\n",
    "    ladder_y = ladder_f.copy()\n",
    "    ladder_y.drop_duplicates(subset=['Season'], keep='last', inplace=True)\n",
    "    ladder_y=ladder_y.drop(['Team','Games','Points','Percentage','Position'],1)\n",
    "    rnd=[]\n",
    "    seas=[]\n",
    "    for index, row in ladder_y.iterrows():\n",
    "        st = int(row.Round)\n",
    "        #print(type(st))\n",
    "        for i in range(st+1,30):\n",
    "            rnd.append(i)\n",
    "            seas.append(row.Season)\n",
    "    ldr = pd.DataFrame()\n",
    "    ldr['Season'] = seas\n",
    "    ldr['Round'] = rnd\n",
    "    #ldr = pd.merge(ladder_f.drop(['Round'],1),ldr,how='inner',on=['Season'])\n",
    "    ladder = pd.concat([ladder,ldr],sort=False)\n",
    "    ladder = ladder.sort_values(by=['Team','Season'],axis=0)\n",
    "    ladder['PosOld']=ladder.Position.shift(1)  #previous ladder position taken\n",
    "    ladder = ladder.drop(['Position'],1)\n",
    "    ladder['Round']= [int(x) for x in ladder['Round']]\n",
    "    ladder=ladder.dropna(axis=0)\n",
    "    ladder['PosOld']= [int(x) for x in ladder['PosOld']]  \n",
    "    return ladder\n",
    "\n",
    "def get_fixture(proxy=False):\n",
    "    '''\n",
    "    this is to get AFL fixture from theroar.com.au\n",
    "    set proxy=True if you are on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    url='https://www.theroar.com.au/afl-draw/'\n",
    "    sauce = urllib.request.urlopen(url)\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "    fixture = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "\n",
    "    for x in soup.find_all('tbody'):\n",
    "        rnd_counter = 0\n",
    "\n",
    "        for y in x.find_all('tr'):\n",
    "\n",
    "            if y.find_all('strong'):\n",
    "                rnd_counter +=1\n",
    "\n",
    "            else:\n",
    "                if not y.find_all('h3') and 'Byes' not in y.text and 'TBC' not in y.text:\n",
    "                    dt,teams,venue,tm = y.text.strip().split('\\n')\n",
    "                    if dt == 'Sar Apr 21':\n",
    "                        dt = 'Sat Apr 21'\n",
    "\n",
    "                    dt = parser.parse(dt)\n",
    "                    if teams == 'North Melbourne Carlton':\n",
    "                            hm_team = 'North Melbourne'\n",
    "                            aw_team = 'Carlton'\n",
    "                    else:\n",
    "                        hm_team, aw_team = teams.split(' vs ')\n",
    "\n",
    "                    #print(rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue))\n",
    "                    df = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "                    df.loc[0]=[rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue)]\n",
    "                    fixture = pd.concat([fixture,df])\n",
    "    return fixture\n",
    "\n",
    "def get_odds_history(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this function gets odds history from footywire.com\n",
    "    min season from is 2010- so it will make the min date 2010 if less than that\n",
    "    set proxy=True if on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    if season_from<2010:\n",
    "        season_from=2010\n",
    "    odds_history=pd.DataFrame()\n",
    "    for season in range(season_from,season_to+1):\n",
    "        print('Getting odds for season',season,'...')\n",
    "        sauce = urllib.request.urlopen('https://www.footywire.com/afl/footy/afl_betting?year='+str(season))\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "\n",
    "        for x in soup.find_all('div',class_ ='datadiv'):\n",
    "            date=[]\n",
    "            venue=[]\n",
    "            team_HM=[]\n",
    "            odds_HM=[]\n",
    "            team_AW=[]\n",
    "            odds_AW=[]\n",
    "            counter =0\n",
    "\n",
    "            home_team_cursor = True\n",
    "            for y in x.find_all('tr'):\n",
    "\n",
    "                for z in y.find_all('td',class_='data'):\n",
    "                    counter = counter+1\n",
    "                    if z.has_attr('height'):\n",
    "                        counter = 0\n",
    "                        #print('new game ',z.text)\n",
    "                        date.append(z.text)\n",
    "                    elif z.has_attr('rowspan'):\n",
    "                        #print('venue ', z.text)\n",
    "                        venue.append(z.text)\n",
    "                    elif not z.has_attr('align'):\n",
    "                        if counter == 2:\n",
    "                            #print('Home team: ', z.text)\n",
    "                            team_HM.append(z.text)\n",
    "                            home_team_cursor=True    \n",
    "                        else:\n",
    "                            #print('Away team: ', z.text)\n",
    "                            counter = 0\n",
    "                            team_AW.append(z.text)\n",
    "                            home_team_cursor=False\n",
    "                    elif counter ==3 and not home_team_cursor:\n",
    "                        #print('away team odds: ',z.text)\n",
    "                        odds_AW.append(z.text)\n",
    "                    elif counter==5 and home_team_cursor:\n",
    "                        #print('home team odds: ',z.text)\n",
    "                        odds_HM.append(z.text)\n",
    "        odds = pd.DataFrame()\n",
    "        odds['Date']=[parser.parse(x,dayfirst=True) for x in date]\n",
    "        odds['Venue']=[fix_venue(x) for x in venue]\n",
    "        odds['HomeTeam']=[fix_team_name(x) for x in team_HM]\n",
    "        odds['OddsHome']=[x for x in odds_HM]\n",
    "        odds['AwayTeam']=[fix_team_name(x) for x in team_AW]\n",
    "        odds['OddsAway']=[x for x in odds_AW]\n",
    "        odds_history = pd.concat([odds_history,odds])  \n",
    "    odds = odds.drop_duplicates(subset=['Date','HomeTeam','AwayTeam'],keep='last')\n",
    "    return odds_history\n",
    "\n",
    "def get_games(proxy=False):\n",
    "    \n",
    "    '''\n",
    "    this function gets past games history\n",
    "    and gets attendance where it is available\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "        \n",
    "    col_specification =[(7, 15), (16, 33), (51, 68), (87, 116),(117,128)]\n",
    "    attend = pd.read_fwf('https://afltables.com/afl/stats/biglists/bg7.txt', \n",
    "                         colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    attend.columns = ['Attendance', 'HomeTeam', 'AwayTeam', 'Venue','Date']\n",
    "    attend['Date']  = pd.to_datetime(attend['Date'],dayfirst=True)\n",
    "    attend['Attendance'] = attend.Attendance.str.replace(r\"[\\*]\",'')\n",
    "    col_specification =[(0, 5), (7, 18), (24, 27), (29, 46),(47,63), (64,81),(82,99),(100,117)]\n",
    "    games= pd.read_fwf('http://afltables.com/afl/stats/biglists/bg3.txt', \n",
    "                       colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    games.columns = ['GameID', 'Date', 'Round', 'HomeTeam', 'ScoreHm','AwayTeam','ScoreAw','Venue']\n",
    "    games = pd.merge(games,attend,how='left',on=['Venue','Date','HomeTeam','AwayTeam'])\n",
    "\n",
    "    #fix rounds in games\n",
    "    games['Round'] = [fix_round(x) for x in games['Round']]\n",
    "    \n",
    "    games['Year']=games['Date'].map(lambda x: x.year)\n",
    "\n",
    "    #fix North Melb in games\n",
    "    games['HomeTeam'] = [fix_team_name(x) for x in games['HomeTeam']]\n",
    "    games['AwayTeam'] = [fix_team_name(x) for x in games['AwayTeam']]\n",
    "\n",
    "    # get result\n",
    "    games['H'] = [int(x.split('.')[2]) for x in games['ScoreHm']]\n",
    "    games['A'] = [int(x.split('.')[2]) for x in games['ScoreAw']]\n",
    "    games = games.drop(['ScoreHm','ScoreAw'],1)\n",
    "    games['Result'] = [round((x[0] /(x[0] +x[1])),3) for x in zip(games['H'],games['A'])]\n",
    "    #games = games.drop(['H','A'],1)\n",
    "    games['ResultWL'] = [1 if x>=0.5 else 0 for x in games.Result]\n",
    "    return games\n",
    "\n",
    "\n",
    "def get_team_performance_hist(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this is to get the team performance history\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BH'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CG'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BR'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CM'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    return team_performace\n",
    "\n",
    "\n",
    "def get_lineup(year,rnd,proxy=False):\n",
    "    '''\n",
    "    returns all available line-up for given year\n",
    "    year - current year you need to specify\n",
    "    rnd - current round where line-up has been released (could be improved into auto later)\n",
    "    proxy = True if on LAN\n",
    "    Pre-requisites: \n",
    "     1.TeamRef.csv - file which maps team names to AFL line-up abbreviated names\n",
    "     2.Fixture function is used\n",
    "\n",
    "    '''    \n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "\n",
    "    fixture = get_fixture(proxy)\n",
    "    fixture = fixture[fixture.Round==rnd]  #this limits to current round only\n",
    "    teams = pd.read_csv(get_drive()+'TeamRef.csv')\n",
    "\n",
    "    this_1 = pd.merge(fixture,teams,how=\"inner\",left_on=['HomeTeam'],right_on=['Team'])\n",
    "    this_2 = pd.merge(this_1,teams,how=\"inner\",left_on=['AwayTeam'],right_on=['Team'])\n",
    "    rounds = this_2.drop(['Team_x','Team_y'],1)\n",
    "    rounds['Game'] = [x + '-v-' +y for x,y in zip(rounds.AFL_Team_Nm_x,rounds.AFL_Team_Nm_y)]\n",
    "    rounds = rounds.drop(['AFL_Team_Nm_x','AFL_Team_Nm_y'],1)\n",
    "\n",
    "\n",
    "    # now get available line-up for player ref working\n",
    "\n",
    "    #rounds = rounds[rounds.Round<=max_round]    # needs updating, just available\n",
    "\n",
    "    lineup=pd.DataFrame()\n",
    "    for gm,rnd in zip(rounds['Game'],rounds['Round']):\n",
    "        url='http://www.afl.com.au/match-centre/'+str(year)+'/'+str(rnd)+'/'+gm\n",
    "        \n",
    "        sauce = urllib.request.urlopen(url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        plrs=[]\n",
    "        for x in soup.find_all('div',class_ ='lineup'):\n",
    "            for t in x.find_all('div',class_ ='text-inouts'):\n",
    "                team=''\n",
    "                for tm in t.find_all('h4'):\n",
    "                    team=tm.text\n",
    "\n",
    "                for p in t.find_all('div',class_ ='posGroup'):\n",
    "                    position=''\n",
    "                    for pos in p.find_all('p',class_ ='pos'):\n",
    "                        position =pos.text.strip()\n",
    "                    for player in p.find_all('li'):\n",
    "                        if position in ['B','HB','C','HF','F','Fol','I/C']:\n",
    "                            tms.append(team)\n",
    "                            plrs.append(player.text.strip().strip(','))\n",
    "\n",
    "        d = pd.DataFrame()\n",
    "        d['Team'] = tms\n",
    "        d['Player'] = plrs\n",
    "        lineup=pd.concat([lineup,d])\n",
    "    lineup['Team']=[fix_team_name(x) for x in lineup['Team']]\n",
    "    return lineup\n",
    "\n",
    "def get_player_base(proxy):\n",
    "    '''\n",
    "    !!! run only when need to update for new players !!!\n",
    "    returns a dataframe of player base table to enable to skip older players\n",
    "    e.g. players[players.DoB>'1975-01-01']  this gives 2.5k player subset\n",
    "    \n",
    "    typical use - to create Players.csv file in AFL directory - !!! pre-requisite for getting player performance\n",
    "\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    players = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days'])\n",
    "\n",
    "    # get player urls\n",
    "    links = []\n",
    "    for c in ascii_uppercase :\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/players'+c+'_idx.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "        for url in soup.find_all('a',href=True):\n",
    "            links.append('https://afltables.com/afl/stats/'+url['href'])\n",
    "    # now remove non-player links - ones that contain 'idx'\n",
    "    links = [item for item in links if 'players' in item and 'idx' not in item and 'afl_index' not in item]        \n",
    "\n",
    "    for cur_url in links:\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        #Name\n",
    "        x = soup.find_all('h1')\n",
    "        name = x[0].text\n",
    "\n",
    "        #DoB\n",
    "        found_dob=False\n",
    "\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Born:':\n",
    "                dob = x.next_sibling\n",
    "                found_dob=True\n",
    "                break\n",
    "        if found_dob:\n",
    "            dob=parser.parse(dob[0:11],dayfirst=True)\n",
    "        else:\n",
    "            dob = datetime.datetime(1900, 1, 1, 0, 0)\n",
    "\n",
    "        #Debut\n",
    "        found_debut = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Debut:':\n",
    "                debut = x.next_sibling\n",
    "                found_debut=True\n",
    "                break\n",
    "        if found_debut:\n",
    "            debut =debut.split()\n",
    "            debut1 = ''.join(c for c in debut[0] if c.isdigit())\n",
    "            if len(debut)>1:\n",
    "                debut2 = ''.join(c for c in debut[1] if c.isdigit())\n",
    "                debut = int(debut1)+int(debut2)/365\n",
    "            else:\n",
    "                debut = int(debut1)\n",
    "        else:\n",
    "            debut = 100\n",
    "        #age last played\n",
    "        found_last = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Last:':\n",
    "                age_last = x.next_sibling\n",
    "                found_last=True\n",
    "                break\n",
    "        if found_last:\n",
    "            age_last =age_last.split()\n",
    "            a1 = ''.join(c for c in age_last[0] if c.isdigit())\n",
    "            if len(age_last)>1:\n",
    "                a2 = ''.join(c for c in age_last[1] if c.isdigit())\n",
    "                age_last = int(a1)*365.25+int(a2) #in days\n",
    "            else:\n",
    "                age_last = int(a1)*365.25\n",
    "        else:\n",
    "            age_last = 40*365.25\n",
    "        today = datetime.datetime.today()\n",
    "        last_played_date = dob + datetime.timedelta(days=age_last)\n",
    "        since_last_game=today-last_played_date\n",
    "        df = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days','Last_Played_Date'])\n",
    "        df.loc[0]=[name,dob,cur_url,debut,age_last,last_played_date]\n",
    "        players = pd.concat([players,df])\n",
    "        print(name)\n",
    "    return players\n",
    "\n",
    "\n",
    "\n",
    "def get_player_perf(DoB_min='1975-01-01',proxy=False):\n",
    "    '''\n",
    "    Use this only once per complete round and save into CSV as it takes a while to run\n",
    "    this function returns a dataframe of player performance history\n",
    "    Entire player history is returned\n",
    "    DoB_min is limiting factor to get only player born after the date - for performance reasons\n",
    "    change the default if you need to go more back into older players or in reverse\n",
    "    Pre-requisite: Players.csv file exists in the AFL directory\n",
    "    set proxy=True when on office LAN\n",
    "    \n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "    players = pd.read_csv(get_drive()+'Players.csv')\n",
    "    players =players[players['DoB']>DoB_min]\n",
    "\n",
    "    player_stats = pd.DataFrame(columns=['Url','Team','Year'])\n",
    "\n",
    "    for cur_url in players.Url:\n",
    "        print(cur_url)\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        found=False\n",
    "        dfs=[]\n",
    "        for table in soup.find_all('table'):\n",
    "            #t1=tables[7]\n",
    "            t=table.find('tbody')\n",
    "            res = []\n",
    "            row = []\n",
    "            rows = t.find_all('tr')\n",
    "            for tr in rows:\n",
    "                for td in tr.find_all('td'):\n",
    "                    row.append(td.text)\n",
    "                res.append(row)\n",
    "                row = []\n",
    "            df=pd.DataFrame(data=res)\n",
    "\n",
    "            if len(df.columns)==28: # found first game\n",
    "                    found = True\n",
    "            if found:\n",
    "                h=table.find('thead')\n",
    "                h1 = h.find('tr')\n",
    "                h2 = h1.find('th')\n",
    "                header =h2.text\n",
    "                team_year = header.split('-')\n",
    "                team = team_year[0].strip()\n",
    "                year = team_year[1].strip()\n",
    "                df['Url']=cur_url\n",
    "                df['Team']=team\n",
    "                df['Year']=year\n",
    "                player_stats = pd.concat([player_stats,df])\n",
    "    player_stats = player_stats.rename(columns={0:'GameNo',1:'Opponent',2:'Round',3:'Result',4:'Jersey',5:'KI',6:'MK',7:'HB',8:'DI',9:'GL',10:'BH',11:'HO',12:'TK',13:'RB',14:'IF',15:'CL',16:'CG',17:'FF',18:'FA',19:'BR',20:'CP',21:'UP',22:'CM',23:'MI',24:'1%',25:'BO',26:'GA',27:'%P'})\n",
    "    player_stats['Round']=[fix_round(x) for x in player_stats['Round']]\n",
    "\n",
    "\n",
    "    games_set = get_games(proxy=False)\n",
    "\n",
    "\n",
    "\n",
    "    #create one game row for each team\n",
    "    gamesH = games_set.drop(['AwayTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesA = games_set.drop(['HomeTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesH=gamesH.rename(columns={'HomeTeam':'Team'})\n",
    "    gamesA=gamesA.rename(columns={'AwayTeam':'Team'})\n",
    "    gamesAH=pd.concat([gamesH,gamesA])\n",
    "    gamesAH['Year'] = [str(x) for x in gamesAH['Year']]\n",
    "    # get date and game id for each player record\n",
    "    player_stats=pd.merge(player_stats,gamesAH,how='inner',on=['Team','Year','Round'])\n",
    "    player_stats=player_stats.drop_duplicates(subset=['Url','Year','Round'],keep='first')\n",
    "    \n",
    "    return player_stats\n",
    "\n",
    "def get_pastXthis_opponent(x,team,opponent,dt,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, opponent, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    #last 3 against this team\n",
    "    tp = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Opponent']==opponent) ]  # later row.Team\n",
    "    tp = tp.sort_values(by=['Date'],ascending=False)\n",
    "    tp = tp.head(x)\n",
    "    tp = tp.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp_avg = tp.groupby(by='Team').aggregate('mean')\n",
    "    tp_avg.columns = [str(col) + '_lstXopp' for col in tp_avg.columns]\n",
    "    if tp_avg.shape[0]==0:\n",
    "        print('empty row generated for ', dt,' team:',team, ' vs.', opponent)\n",
    "    return tp_avg\n",
    "\n",
    "def get_pastXground(x,team,dt,venue,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date and venue of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    tp2 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Venue'] == venue)] \n",
    "    tp2 = tp2.sort_values(by=['Date'],ascending=False)\n",
    "    tp2 = tp2.head(x)\n",
    "    tp2 = tp2.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp2_avg = tp2.groupby(by='Team').aggregate('mean')\n",
    "    tp2_avg.columns = [str(col) + '_lstXgrd' for col in tp2_avg.columns]\n",
    "    if tp2_avg.shape[0]==0:\n",
    "        print('empty row generated for ',dt,' at ', venue,' team:',team)\n",
    "    return tp2_avg\n",
    "\n",
    "def get_pastX(x,team,dt,team_performaceDF,print_missing=False):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tp1 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt)] \n",
    "    tp1 = tp1.sort_values(by=['Date'],ascending=False)\n",
    "    tp1 = tp1.head(x)\n",
    "    tp1 = tp1.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp1_avg = tp1.groupby(by='Team').aggregate('mean')\n",
    "    tp1_avg.columns = [str(col) + '_lstX' for col in tp1_avg.columns]\n",
    "    if tp1_avg.shape[0]==0 and print_missing:\n",
    "        print('empty row generated for ', dt,' team:',team)\n",
    "    return tp1_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version after 28 Aug 2018 changes\n",
    "# get past X functions calculate Margin/Result\n",
    "\n",
    "def get_drive():\n",
    "    '''\n",
    "    this is to automate switching between home PC and laptop\n",
    "    it returns J:\\\\AFL\\\\ or D:\\\\AFL\\\\ depending if D:\\ is available\n",
    "    \n",
    "    No parameters required\n",
    "    '''\n",
    "    \n",
    "    import win32api\n",
    "    drives = win32api.GetLogicalDriveStrings()\n",
    "    drives = drives.split('\\000')[:-1]\n",
    "    if 'D:\\\\' in drives:\n",
    "        drive = 'D:\\\\AFL\\\\'\n",
    "    else:\n",
    "        drive = 'J:\\\\AFL\\\\'\n",
    "    return drive\n",
    "\n",
    "\n",
    "def get_proxy(proxy):\n",
    "        if proxy:\n",
    "            from os import environ\n",
    "            #pwd = input('Please enter your LAN Pwd')\n",
    "            environ[\"http_proxy\"]=\"http://c819325:sWeater78-@http-gw.tcif.telstra.com.au:8080\"\n",
    "            environ[\"https_proxy\"]=environ.get(\"http_proxy\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fix_round(round_in):\n",
    "    '''\n",
    "    this function convert Round values into sequential integers\n",
    "    '''\n",
    "    if round_in=='QF':\n",
    "        rnd='25'\n",
    "    elif round_in=='EF':\n",
    "        rnd='26'\n",
    "    elif round_in=='SF':\n",
    "        rnd='27'\n",
    "    elif round_in=='PF':\n",
    "        rnd='28'\n",
    "    elif round_in=='GF':\n",
    "        rnd='29'\n",
    "    elif round_in[0]=='R':\n",
    "        rnd=round_in[1:]\n",
    "    else:\n",
    "        rnd=round_in\n",
    "    return int(rnd)\n",
    "\n",
    "def fix_team_name(name):\n",
    "    '''\n",
    "    this function converts any team name to a consistent\n",
    "    set of  names which are usable for joins\n",
    "    '''\n",
    "    if 'Crows' in name:\n",
    "        team_name='Adelaide'\n",
    "    elif name.strip()=='Adelaide Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='AD':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='BL':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='Lions':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='CA':\n",
    "        team_name='Carlton'\n",
    "    elif name=='Blues':\n",
    "        team_name='Carlton'\n",
    "    elif name=='CW':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='Magpies':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='ES':\n",
    "        team_name='Essendon'\n",
    "    elif name=='Bombers':\n",
    "        team_name='Essendon'\n",
    "    elif name=='FR':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='Dockers':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='GE':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Geelong Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='GC':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Gold Coast Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='GWS Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GWS':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW Sydney':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='HW':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='Hawks':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='ME':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Demons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Deamons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='KA':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='NM':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='Kangaroos':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='PA':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='Power':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='RI':\n",
    "        team_name='Richmond'\n",
    "    elif name=='Tigers':\n",
    "        team_name='Richmond'\n",
    "    elif name=='SK':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='Saints':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='SY':\n",
    "        team_name='Sydney'\n",
    "    elif 'Swans' in name:\n",
    "        team_name='Sydney'\n",
    "    elif name=='WC':\n",
    "        team_name='West Coast'\n",
    "    elif name=='West Coast Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='WB':\n",
    "        team_name='Western Bulldogs'\n",
    "    elif name=='Bulldogs':\n",
    "        team_name='Western Bulldogs'\n",
    "    else:\n",
    "        team_name=name\n",
    "    return team_name\n",
    "\n",
    "def fix_venue(name):\n",
    "    if name=='AAMI':\n",
    "        ground = 'Olympic Park'\n",
    "    elif name=='ANZ':\n",
    "        ground = 'Stadium Australia'\n",
    "    elif name=='Adelaide':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Aurora':\n",
    "        ground = 'York Park'\n",
    "    elif name=='Blacktown':\n",
    "        ground='Blacktown'\n",
    "    elif name=='Blundstone Arena':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name=='Blundstone':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name==\"Cazaly's\":\n",
    "        ground= \"Cazaly's Stadium\"\n",
    "    elif name=='Domain':\n",
    "        ground='Subiaco'\n",
    "    elif name=='Etihad Stadium':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='Etihad':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='GMHBA Stadium':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='GMHBA':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='Gabba':\n",
    "        ground = 'Gabba'\n",
    "    elif name=='Jiangwan':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='Jiangwan Stadium, China':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='M.C.G':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='MCG':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='Mars Stadium, Ballarat':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Mars':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Metricon Stadium':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Metricon':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Perth':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='SCG':\n",
    "        ground='S.C.G.'\n",
    "    elif name=='Spotless Stadium':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='Spotless':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='UNSW Canberra Oval':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='StarTrack':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='Treager Park, Alice Springs':\n",
    "        ground='Traeger Park'\n",
    "    elif name=='TIO Stadium, Darwin':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='TIO':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='University of Tasmania Stadium':\n",
    "        ground='York Park'\n",
    "    elif name=='UTAS':\n",
    "        ground='York Park'\n",
    "    elif name=='Westpac':\n",
    "        ground='Wellington'\n",
    "    else:\n",
    "        ground=name\n",
    "    return ground\n",
    "\n",
    "def get_ladder(seas_from,seas_to,proxy=False):\n",
    "    '''\n",
    "    this is just to get the ladder history\n",
    "\n",
    "    Input required - update season from and to in the function call at the bottom\n",
    "    this function returns a dataframe for AFL ladder position history\n",
    "    seas_from - season to start from\n",
    "    seas_to - season end - inclusive\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    ladder = pd.DataFrame(columns=['Team','Games','Points','Percentage','Round','Position','Season'])\n",
    "    for season in range(seas_from-1,seas_to+1): \n",
    "        cur_url = 'http://afltables.com/afl/seas/'+str(season)+'.html'\n",
    "        dfs = pd.read_html(cur_url)\n",
    "\n",
    "        for df in dfs:\n",
    "            if df.columns.nlevels>1:\n",
    "                break\n",
    "            if len(df)>1 and 'Ladder' in df[0][0] and 'Rd' in df[0][0] and len(df.columns)>2:\n",
    "                rnd = df[0][0][3:5]\n",
    "                ldr = df.copy() \n",
    "                ldr = ldr.drop(0,0)\n",
    "                ldr.columns = ['Team','Games','Points','Percentage']\n",
    "                ldr['Round']=rnd\n",
    "                ldr['Position']=ldr.index\n",
    "                ldr['Season']=season\n",
    "                ladder = pd.concat([ladder,ldr])\n",
    "    ladder['Team'] = [fix_team_name(x) for x in ladder['Team']]\n",
    "    \n",
    "    # repeat last round for last and until 29\n",
    "    ladder_f = ladder.copy()\n",
    "    ladder_f.drop_duplicates(subset=['Team','Season'], keep='last', inplace=True)\n",
    "\n",
    "    # get last round for each season\n",
    "    ladder_y = ladder_f.copy()\n",
    "    ladder_y.drop_duplicates(subset=['Season'], keep='last', inplace=True)\n",
    "    ladder_y=ladder_y.drop(['Team','Games','Points','Percentage','Position'],1)\n",
    "    rnd=[]\n",
    "    seas=[]\n",
    "    for index, row in ladder_y.iterrows():\n",
    "        st = int(row.Round)\n",
    "        #print(type(st))\n",
    "        for i in range(st+1,30):\n",
    "            rnd.append(i)\n",
    "            seas.append(row.Season)\n",
    "    ldr = pd.DataFrame()\n",
    "    ldr['Season'] = seas\n",
    "    ldr['Round'] = rnd\n",
    "    #ldr = pd.merge(ladder_f.drop(['Round'],1),ldr,how='inner',on=['Season'])\n",
    "    ladder = pd.concat([ladder,ldr],sort=False)\n",
    "    ladder = ladder.sort_values(by=['Team','Season'],axis=0)\n",
    "    ladder['PosOld']=ladder.Position.shift(1)  #previous ladder position taken\n",
    "    ladder = ladder.drop(['Position'],1)\n",
    "    ladder['Round']= [int(x) for x in ladder['Round']]\n",
    "    ladder=ladder.dropna(axis=0)\n",
    "    ladder['PosOld']= [int(x) for x in ladder['PosOld']]  \n",
    "    return ladder\n",
    "\n",
    "def get_fixture(proxy=False):\n",
    "    '''\n",
    "    this is to get AFL fixture from theroar.com.au\n",
    "    set proxy=True if you are on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    url='https://www.theroar.com.au/afl-draw/'\n",
    "    sauce = urllib.request.urlopen(url)\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "    fixture = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "\n",
    "    for x in soup.find_all('tbody'):\n",
    "        rnd_counter = 0\n",
    "\n",
    "        for y in x.find_all('tr'):\n",
    "\n",
    "            if y.find_all('strong'):\n",
    "                rnd_counter +=1\n",
    "\n",
    "            else:\n",
    "                if not y.find_all('h3') and 'Byes' not in y.text and 'TBC' not in y.text:\n",
    "                    dt,teams,venue,tm = y.text.strip().split('\\n')\n",
    "                    if dt == 'Sar Apr 21':\n",
    "                        dt = 'Sat Apr 21'\n",
    "\n",
    "                    dt = parser.parse(dt)\n",
    "                    if teams == 'North Melbourne Carlton':\n",
    "                            hm_team = 'North Melbourne'\n",
    "                            aw_team = 'Carlton'\n",
    "                    else:\n",
    "                        hm_team, aw_team = teams.split(' vs ')\n",
    "\n",
    "                    #print(rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue))\n",
    "                    df = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "                    df.loc[0]=[rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue)]\n",
    "                    fixture = pd.concat([fixture,df])\n",
    "    return fixture\n",
    "\n",
    "def get_odds_history(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this function gets odds history from footywire.com\n",
    "    min season from is 2010- so it will make the min date 2010 if less than that\n",
    "    set proxy=True if on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    if season_from<2010:\n",
    "        season_from=2010\n",
    "    odds_history=pd.DataFrame()\n",
    "    for season in range(season_from,season_to+1):\n",
    "        print('Getting odds for season',season,'...')\n",
    "        sauce = urllib.request.urlopen('https://www.footywire.com/afl/footy/afl_betting?year='+str(season))\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "\n",
    "        for x in soup.find_all('div',class_ ='datadiv'):\n",
    "            date=[]\n",
    "            venue=[]\n",
    "            team_HM=[]\n",
    "            odds_HM=[]\n",
    "            team_AW=[]\n",
    "            odds_AW=[]\n",
    "            counter =0\n",
    "\n",
    "            home_team_cursor = True\n",
    "            for y in x.find_all('tr'):\n",
    "\n",
    "                for z in y.find_all('td',class_='data'):\n",
    "                    counter = counter+1\n",
    "                    if z.has_attr('height'):\n",
    "                        counter = 0\n",
    "                        #print('new game ',z.text)\n",
    "                        date.append(z.text)\n",
    "                    elif z.has_attr('rowspan'):\n",
    "                        #print('venue ', z.text)\n",
    "                        venue.append(z.text)\n",
    "                    elif not z.has_attr('align'):\n",
    "                        if counter == 2:\n",
    "                            #print('Home team: ', z.text)\n",
    "                            team_HM.append(z.text)\n",
    "                            home_team_cursor=True    \n",
    "                        else:\n",
    "                            #print('Away team: ', z.text)\n",
    "                            counter = 0\n",
    "                            team_AW.append(z.text)\n",
    "                            home_team_cursor=False\n",
    "                    elif counter ==3 and not home_team_cursor:\n",
    "                        #print('away team odds: ',z.text)\n",
    "                        odds_AW.append(z.text)\n",
    "                    elif counter==5 and home_team_cursor:\n",
    "                        #print('home team odds: ',z.text)\n",
    "                        odds_HM.append(z.text)\n",
    "        odds = pd.DataFrame()\n",
    "        odds['Date']=[parser.parse(x,dayfirst=True) for x in date]\n",
    "        odds['Venue']=[fix_venue(x) for x in venue]\n",
    "        odds['HomeTeam']=[fix_team_name(x) for x in team_HM]\n",
    "        odds['OddsHome']=[x for x in odds_HM]\n",
    "        odds['AwayTeam']=[fix_team_name(x) for x in team_AW]\n",
    "        odds['OddsAway']=[x for x in odds_AW]\n",
    "        odds_history = pd.concat([odds_history,odds])  \n",
    "    odds = odds.drop_duplicates(subset=['Date','HomeTeam','AwayTeam'],keep='last')\n",
    "    return odds_history\n",
    "\n",
    "def get_games(proxy=False):\n",
    "    \n",
    "    '''\n",
    "    this function gets past games history\n",
    "    and gets attendance where it is available\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "        \n",
    "    col_specification =[(7, 15), (16, 33), (51, 68), (87, 116),(117,128)]\n",
    "    attend = pd.read_fwf('https://afltables.com/afl/stats/biglists/bg7.txt', \n",
    "                         colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    attend.columns = ['Attendance', 'HomeTeam', 'AwayTeam', 'Venue','Date']\n",
    "    attend['Date']  = pd.to_datetime(attend['Date'],dayfirst=True)\n",
    "    attend['Attendance'] = attend.Attendance.str.replace(r\"[\\*]\",'')\n",
    "    col_specification =[(0, 5), (7, 18), (24, 27), (29, 46),(47,63), (64,81),(82,99),(100,117)]\n",
    "    games= pd.read_fwf('http://afltables.com/afl/stats/biglists/bg3.txt', \n",
    "                       colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    games.columns = ['GameID', 'Date', 'Round', 'HomeTeam', 'ScoreHm','AwayTeam','ScoreAw','Venue']\n",
    "    games = pd.merge(games,attend,how='left',on=['Venue','Date','HomeTeam','AwayTeam'])\n",
    "\n",
    "    #fix rounds in games\n",
    "    games['Round'] = [fix_round(x) for x in games['Round']]\n",
    "    \n",
    "    games['Year']=games['Date'].map(lambda x: x.year)\n",
    "\n",
    "    #fix North Melb in games\n",
    "    games['HomeTeam'] = [fix_team_name(x) for x in games['HomeTeam']]\n",
    "    games['AwayTeam'] = [fix_team_name(x) for x in games['AwayTeam']]\n",
    "\n",
    "    # get result\n",
    "    games['H'] = [int(x.split('.')[2]) for x in games['ScoreHm']]\n",
    "    games['A'] = [int(x.split('.')[2]) for x in games['ScoreAw']]\n",
    "    games = games.drop(['ScoreHm','ScoreAw'],1)\n",
    "    games['Result'] = [round((x[0] /(x[0] +x[1])),3) for x in zip(games['H'],games['A'])]\n",
    "    #games = games.drop(['H','A'],1)\n",
    "    games['ResultWL'] = [1 if x>=0.5 else 0 for x in games.Result]\n",
    "    return games\n",
    "\n",
    "\n",
    "def get_team_performance_hist(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this is to get the team performance history\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BH'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CG'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BR'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CM'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    return team_performace\n",
    "\n",
    "\n",
    "def get_lineup(year,rnd,proxy=False):\n",
    "    '''\n",
    "    returns all available line-up for given year\n",
    "    year - current year you need to specify\n",
    "    rnd - current round where line-up has been released (could be improved into auto later)\n",
    "    proxy = True if on LAN\n",
    "    Pre-requisites: \n",
    "     1.TeamRef.csv - file which maps team names to AFL line-up abbreviated names\n",
    "     2.Fixture function is used\n",
    "\n",
    "    '''    \n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "\n",
    "    fixture = get_fixture(proxy)\n",
    "    fixture = fixture[fixture.Round==rnd]  #this limits to current round only\n",
    "    teams = pd.read_csv(get_drive()+'TeamRef.csv')\n",
    "\n",
    "    this_1 = pd.merge(fixture,teams,how=\"inner\",left_on=['HomeTeam'],right_on=['Team'])\n",
    "    this_2 = pd.merge(this_1,teams,how=\"inner\",left_on=['AwayTeam'],right_on=['Team'])\n",
    "    rounds = this_2.drop(['Team_x','Team_y'],1)\n",
    "    rounds['Game'] = [x + '-v-' +y for x,y in zip(rounds.AFL_Team_Nm_x,rounds.AFL_Team_Nm_y)]\n",
    "    rounds = rounds.drop(['AFL_Team_Nm_x','AFL_Team_Nm_y'],1)\n",
    "\n",
    "\n",
    "    # now get available line-up for player ref working\n",
    "\n",
    "    #rounds = rounds[rounds.Round<=max_round]    # needs updating, just available\n",
    "\n",
    "    lineup=pd.DataFrame()\n",
    "    for gm,rnd in zip(rounds['Game'],rounds['Round']):\n",
    "        url='http://www.afl.com.au/match-centre/'+str(year)+'/'+str(rnd)+'/'+gm\n",
    "        \n",
    "        sauce = urllib.request.urlopen(url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        plrs=[]\n",
    "        for x in soup.find_all('div',class_ ='lineup'):\n",
    "            for t in x.find_all('div',class_ ='text-inouts'):\n",
    "                team=''\n",
    "                for tm in t.find_all('h4'):\n",
    "                    team=tm.text\n",
    "\n",
    "                for p in t.find_all('div',class_ ='posGroup'):\n",
    "                    position=''\n",
    "                    for pos in p.find_all('p',class_ ='pos'):\n",
    "                        position =pos.text.strip()\n",
    "                    for player in p.find_all('li'):\n",
    "                        if position in ['B','HB','C','HF','F','Fol','I/C']:\n",
    "                            tms.append(team)\n",
    "                            plrs.append(player.text.strip().strip(','))\n",
    "\n",
    "        d = pd.DataFrame()\n",
    "        d['Team'] = tms\n",
    "        d['Player'] = plrs\n",
    "        lineup=pd.concat([lineup,d])\n",
    "    lineup['Team']=[fix_team_name(x) for x in lineup['Team']]\n",
    "    return lineup\n",
    "\n",
    "def get_player_base(proxy):\n",
    "    '''\n",
    "    !!! run only when need to update for new players !!!\n",
    "    returns a dataframe of player base table to enable to skip older players\n",
    "    e.g. players[players.DoB>'1975-01-01']  this gives 2.5k player subset\n",
    "    \n",
    "    typical use - to create Players.csv file in AFL directory - !!! pre-requisite for getting player performance\n",
    "\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    players = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days'])\n",
    "\n",
    "    # get player urls\n",
    "    links = []\n",
    "    for c in ascii_uppercase :\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/players'+c+'_idx.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "        for url in soup.find_all('a',href=True):\n",
    "            links.append('https://afltables.com/afl/stats/'+url['href'])\n",
    "    # now remove non-player links - ones that contain 'idx'\n",
    "    links = [item for item in links if 'players' in item and 'idx' not in item and 'afl_index' not in item]        \n",
    "\n",
    "    for cur_url in links:\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        #Name\n",
    "        x = soup.find_all('h1')\n",
    "        name = x[0].text\n",
    "\n",
    "        #DoB\n",
    "        found_dob=False\n",
    "\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Born:':\n",
    "                dob = x.next_sibling\n",
    "                found_dob=True\n",
    "                break\n",
    "        if found_dob:\n",
    "            dob=parser.parse(dob[0:11],dayfirst=True)\n",
    "        else:\n",
    "            dob = datetime.datetime(1900, 1, 1, 0, 0)\n",
    "\n",
    "        #Debut\n",
    "        found_debut = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Debut:':\n",
    "                debut = x.next_sibling\n",
    "                found_debut=True\n",
    "                break\n",
    "        if found_debut:\n",
    "            debut =debut.split()\n",
    "            debut1 = ''.join(c for c in debut[0] if c.isdigit())\n",
    "            if len(debut)>1:\n",
    "                debut2 = ''.join(c for c in debut[1] if c.isdigit())\n",
    "                debut = int(debut1)+int(debut2)/365\n",
    "            else:\n",
    "                debut = int(debut1)\n",
    "        else:\n",
    "            debut = 100\n",
    "        #age last played\n",
    "        found_last = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Last:':\n",
    "                age_last = x.next_sibling\n",
    "                found_last=True\n",
    "                break\n",
    "        if found_last:\n",
    "            age_last =age_last.split()\n",
    "            a1 = ''.join(c for c in age_last[0] if c.isdigit())\n",
    "            if len(age_last)>1:\n",
    "                a2 = ''.join(c for c in age_last[1] if c.isdigit())\n",
    "                age_last = int(a1)*365.25+int(a2) #in days\n",
    "            else:\n",
    "                age_last = int(a1)*365.25\n",
    "        else:\n",
    "            age_last = 40*365.25\n",
    "        today = datetime.datetime.today()\n",
    "        last_played_date = dob + datetime.timedelta(days=age_last)\n",
    "        since_last_game=today-last_played_date\n",
    "        df = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days','Last_Played_Date'])\n",
    "        df.loc[0]=[name,dob,cur_url,debut,age_last,last_played_date]\n",
    "        players = pd.concat([players,df])\n",
    "        print(name)\n",
    "    return players\n",
    "\n",
    "\n",
    "\n",
    "def get_player_perf(DoB_min='1975-01-01',proxy=False):\n",
    "    '''\n",
    "    Use this only once per complete round and save into CSV as it takes a while to run\n",
    "    this function returns a dataframe of player performance history\n",
    "    Entire player history is returned\n",
    "    DoB_min is limiting factor to get only player born after the date - for performance reasons\n",
    "    change the default if you need to go more back into older players or in reverse\n",
    "    Pre-requisite: Players.csv file exists in the AFL directory\n",
    "    set proxy=True when on office LAN\n",
    "    \n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "    players = pd.read_csv(get_drive()+'Players.csv')\n",
    "    players =players[players['DoB']>DoB_min]\n",
    "\n",
    "    player_stats = pd.DataFrame(columns=['Url','Team','Year'])\n",
    "\n",
    "    for cur_url in players.Url:\n",
    "        print(cur_url)\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        found=False\n",
    "        dfs=[]\n",
    "        for table in soup.find_all('table'):\n",
    "            #t1=tables[7]\n",
    "            t=table.find('tbody')\n",
    "            res = []\n",
    "            row = []\n",
    "            rows = t.find_all('tr')\n",
    "            for tr in rows:\n",
    "                for td in tr.find_all('td'):\n",
    "                    row.append(td.text)\n",
    "                res.append(row)\n",
    "                row = []\n",
    "            df=pd.DataFrame(data=res)\n",
    "\n",
    "            if len(df.columns)==28: # found first game\n",
    "                    found = True\n",
    "            if found:\n",
    "                h=table.find('thead')\n",
    "                h1 = h.find('tr')\n",
    "                h2 = h1.find('th')\n",
    "                header =h2.text\n",
    "                team_year = header.split('-')\n",
    "                team = team_year[0].strip()\n",
    "                year = team_year[1].strip()\n",
    "                df['Url']=cur_url\n",
    "                df['Team']=team\n",
    "                df['Year']=year\n",
    "                player_stats = pd.concat([player_stats,df])\n",
    "    player_stats = player_stats.rename(columns={0:'GameNo',1:'Opponent',2:'Round',3:'Result',4:'Jersey',5:'KI',6:'MK',7:'HB',8:'DI',9:'GL',10:'BH',11:'HO',12:'TK',13:'RB',14:'IF',15:'CL',16:'CG',17:'FF',18:'FA',19:'BR',20:'CP',21:'UP',22:'CM',23:'MI',24:'1%',25:'BO',26:'GA',27:'%P'})\n",
    "    player_stats['Round']=[fix_round(x) for x in player_stats['Round']]\n",
    "\n",
    "\n",
    "    games_set = get_games(proxy=False)\n",
    "\n",
    "\n",
    "\n",
    "    #create one game row for each team\n",
    "    gamesH = games_set.drop(['AwayTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesA = games_set.drop(['HomeTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesH=gamesH.rename(columns={'HomeTeam':'Team'})\n",
    "    gamesA=gamesA.rename(columns={'AwayTeam':'Team'})\n",
    "    gamesAH=pd.concat([gamesH,gamesA])\n",
    "    gamesAH['Year'] = [str(x) for x in gamesAH['Year']]\n",
    "    # get date and game id for each player record\n",
    "    player_stats=pd.merge(player_stats,gamesAH,how='inner',on=['Team','Year','Round'])\n",
    "    player_stats=player_stats.drop_duplicates(subset=['Url','Year','Round'],keep='first')\n",
    "    \n",
    "    return player_stats\n",
    "\n",
    "def get_pastXthis_opponent(x,team,opponent,dt,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, opponent, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    #last 3 against this team\n",
    "    tp = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Opponent']==opponent) ]  # later row.Team\n",
    "    tp = tp.sort_values(by=['Date'],ascending=False)\n",
    "    tp = tp.head(x)\n",
    "    tp = tp.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp['Score']=[g*6+b for g,b in zip(tp['GL'],tp['BH'])]  # new line this version\n",
    "    tp_avg = tp.groupby(by='Team').aggregate('mean')\n",
    "    tp_avg.columns = [str(col) + '_lstXopp' for col in tp_avg.columns]\n",
    "    if tp_avg.shape[0]==0:\n",
    "        print('empty row generated for ', dt,' team:',team, ' vs.', opponent)\n",
    "    return tp_avg\n",
    "\n",
    "def get_pastXground(x,team,dt,venue,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date and venue of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    tp2 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Venue'] == venue)] \n",
    "    tp2 = tp2.sort_values(by=['Date'],ascending=False)\n",
    "    tp2 = tp2.head(x)\n",
    "    tp2 = tp2.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp2['Score']=[g*6+b for g,b in zip(tp2['GL'],tp2['BH'])]  # new line this version\n",
    "    tp2_avg = tp2.groupby(by='Team').aggregate('mean')\n",
    "    tp2_avg.columns = [str(col) + '_lstXgrd' for col in tp2_avg.columns]\n",
    "    if tp2_avg.shape[0]==0:\n",
    "        print('empty row generated for ',dt,' at ', venue,' team:',team)\n",
    "    return tp2_avg\n",
    "\n",
    "def get_pastX(x,team,dt,team_performaceDF,print_missing=False):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tp1 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt)] \n",
    "    tp1 = tp1.sort_values(by=['Date'],ascending=False)\n",
    "    tp1 = tp1.head(x)\n",
    "    tp1 = tp1.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp1['Score']=[g*6+b for g,b in zip(tp1['GL'],tp1['BH'])] # new line this version\n",
    "    tp1_avg = tp1.groupby(by='Team').aggregate('mean')\n",
    "    tp1_avg.columns = [str(col) + '_lstX' for col in tp1_avg.columns]\n",
    "    if tp1_avg.shape[0]==0 and print_missing:\n",
    "        print('empty row generated for ', dt,' team:',team)\n",
    "    return tp1_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version 29 Aug 2018 \n",
    "# adding more metrics to team performance:\n",
    "# Make main meric e.g. KI as absolute difference between home team and opponent\n",
    "# added 2 sets of metrics for team and opponent (suffixed with \"t\" and \"o\" respectively)\n",
    "\n",
    "# on Aug 30 - added relative version of team performance\n",
    "\n",
    "# on Aug 30 - added relative version of team performance\n",
    "# Subiaco = Perth Stadium, Football Park = Adelaide Oval\n",
    "\n",
    "def get_drive():\n",
    "    '''\n",
    "    this is to automate switching between home PC and laptop\n",
    "    it returns J:\\\\AFL\\\\ or D:\\\\AFL\\\\ depending if D:\\ is available\n",
    "    \n",
    "    No parameters required\n",
    "    '''\n",
    "    \n",
    "    import win32api\n",
    "    drives = win32api.GetLogicalDriveStrings()\n",
    "    drives = drives.split('\\000')[:-1]\n",
    "    if 'D:\\\\' in drives:\n",
    "        drive = 'D:\\\\AFL\\\\'\n",
    "    else:\n",
    "        drive = 'J:\\\\AFL\\\\'\n",
    "    return drive\n",
    "\n",
    "\n",
    "def get_proxy(proxy):\n",
    "        if proxy:\n",
    "            from os import environ\n",
    "            #pwd = input('Please enter your LAN Pwd')\n",
    "            environ[\"http_proxy\"]=\"http://c819325:sWeater78-@http-gw.tcif.telstra.com.au:8080\"\n",
    "            environ[\"https_proxy\"]=environ.get(\"http_proxy\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fix_round(round_in):\n",
    "    '''\n",
    "    this function convert Round values into sequential integers\n",
    "    '''\n",
    "    if round_in=='QF':\n",
    "        rnd='25'\n",
    "    elif round_in=='EF':\n",
    "        rnd='26'\n",
    "    elif round_in=='SF':\n",
    "        rnd='27'\n",
    "    elif round_in=='PF':\n",
    "        rnd='28'\n",
    "    elif round_in=='GF':\n",
    "        rnd='29'\n",
    "    elif round_in[0]=='R':\n",
    "        rnd=round_in[1:]\n",
    "    else:\n",
    "        rnd=round_in\n",
    "    return int(rnd)\n",
    "\n",
    "def fix_team_name(name):\n",
    "    '''\n",
    "    this function converts any team name to a consistent\n",
    "    set of  names which are usable for joins\n",
    "    '''\n",
    "    if 'Crows' in name:\n",
    "        team_name='Adelaide'\n",
    "    elif name.strip()=='Adelaide Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='AD':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='BL':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='Lions':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='CA':\n",
    "        team_name='Carlton'\n",
    "    elif name=='Blues':\n",
    "        team_name='Carlton'\n",
    "    elif name=='CW':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='Magpies':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='ES':\n",
    "        team_name='Essendon'\n",
    "    elif name=='Bombers':\n",
    "        team_name='Essendon'\n",
    "    elif name=='FR':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='Dockers':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='GE':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Geelong Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='GC':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Gold Coast Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='GWS Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GWS':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW Sydney':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='HW':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='Hawks':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='ME':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Demons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Deamons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='KA':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='NM':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='Kangaroos':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='PA':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='Power':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='RI':\n",
    "        team_name='Richmond'\n",
    "    elif name=='Tigers':\n",
    "        team_name='Richmond'\n",
    "    elif name=='SK':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='Saints':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='SY':\n",
    "        team_name='Sydney'\n",
    "    elif 'Swans' in name:\n",
    "        team_name='Sydney'\n",
    "    elif name=='WC':\n",
    "        team_name='West Coast'\n",
    "    elif name=='West Coast Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='WB':\n",
    "        team_name='Western Bulldogs'\n",
    "    elif name=='Bulldogs':\n",
    "        team_name='Western Bulldogs'\n",
    "    else:\n",
    "        team_name=name\n",
    "    return team_name\n",
    "\n",
    "def fix_venue(name):\n",
    "    if name=='AAMI':\n",
    "        ground = 'Olympic Park'\n",
    "    elif name=='ANZ':\n",
    "        ground = 'Stadium Australia'\n",
    "    elif name=='Football Park':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Adelaide':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Aurora':\n",
    "        ground = 'York Park'\n",
    "    elif name=='Blacktown':\n",
    "        ground='Blacktown'\n",
    "    elif name=='Blundstone Arena':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name=='Blundstone':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name==\"Cazaly's\":\n",
    "        ground= \"Cazaly's Stadium\"\n",
    "    elif name=='Domain':\n",
    "        ground='Subiaco'\n",
    "    elif name=='Etihad Stadium':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='Etihad':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='GMHBA Stadium':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='GMHBA':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='Gabba':\n",
    "        ground = 'Gabba'\n",
    "    elif name=='Jiangwan':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='Jiangwan Stadium, China':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='M.C.G':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='MCG':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='Mars Stadium, Ballarat':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Mars':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Metricon Stadium':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Metricon':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Perth':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='Subiaco':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='SCG':\n",
    "        ground='S.C.G.'\n",
    "    elif name=='Spotless Stadium':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='Spotless':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='UNSW Canberra Oval':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='StarTrack':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='Treager Park, Alice Springs':\n",
    "        ground='Traeger Park'\n",
    "    elif name=='TIO Stadium, Darwin':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='TIO':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='University of Tasmania Stadium':\n",
    "        ground='York Park'\n",
    "    elif name=='UTAS':\n",
    "        ground='York Park'\n",
    "    elif name=='Westpac':\n",
    "        ground='Wellington'\n",
    "    else:\n",
    "        ground=name\n",
    "    return ground\n",
    "\n",
    "def get_ladder(seas_from,seas_to,proxy=False):\n",
    "    '''\n",
    "    this is just to get the ladder history\n",
    "\n",
    "    Input required - update season from and to in the function call at the bottom\n",
    "    this function returns a dataframe for AFL ladder position history\n",
    "    seas_from - season to start from\n",
    "    seas_to - season end - inclusive\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    ladder = pd.DataFrame(columns=['Team','Games','Points','Percentage','Round','Position','Season'])\n",
    "    for season in range(seas_from-1,seas_to+1): \n",
    "        cur_url = 'http://afltables.com/afl/seas/'+str(season)+'.html'\n",
    "        dfs = pd.read_html(cur_url)\n",
    "\n",
    "        for df in dfs:\n",
    "            if df.columns.nlevels>1:\n",
    "                break\n",
    "            if len(df)>1 and 'Ladder' in df[0][0] and 'Rd' in df[0][0] and len(df.columns)>2:\n",
    "                rnd = df[0][0][3:5]\n",
    "                ldr = df.copy() \n",
    "                ldr = ldr.drop(0,0)\n",
    "                ldr.columns = ['Team','Games','Points','Percentage']\n",
    "                ldr['Round']=rnd\n",
    "                ldr['Position']=ldr.index\n",
    "                ldr['Season']=season\n",
    "                ladder = pd.concat([ladder,ldr])\n",
    "    ladder['Team'] = [fix_team_name(x) for x in ladder['Team']]\n",
    "    \n",
    "    # repeat last round for last and until 29\n",
    "    ladder_f = ladder.copy()\n",
    "    ladder_f.drop_duplicates(subset=['Team','Season'], keep='last', inplace=True)\n",
    "\n",
    "    # get last round for each season\n",
    "    ladder_y = ladder_f.copy()\n",
    "    ladder_y.drop_duplicates(subset=['Season'], keep='last', inplace=True)\n",
    "    ladder_y=ladder_y.drop(['Team','Games','Points','Percentage','Position'],1)\n",
    "    rnd=[]\n",
    "    seas=[]\n",
    "    for index, row in ladder_y.iterrows():\n",
    "        st = int(row.Round)\n",
    "        #print(type(st))\n",
    "        for i in range(st+1,30):\n",
    "            rnd.append(i)\n",
    "            seas.append(row.Season)\n",
    "    ldr = pd.DataFrame()\n",
    "    ldr['Season'] = seas\n",
    "    ldr['Round'] = rnd\n",
    "    #ldr = pd.merge(ladder_f.drop(['Round'],1),ldr,how='inner',on=['Season'])\n",
    "    ladder = pd.concat([ladder,ldr],sort=False)\n",
    "    ladder = ladder.sort_values(by=['Team','Season'],axis=0)\n",
    "    ladder['PosOld']=ladder.Position.shift(1)  #previous ladder position taken\n",
    "    ladder = ladder.drop(['Position'],1)\n",
    "    ladder['Round']= [int(x) for x in ladder['Round']]\n",
    "    ladder=ladder.dropna(axis=0)\n",
    "    ladder['PosOld']= [int(x) for x in ladder['PosOld']]  \n",
    "    return ladder\n",
    "\n",
    "def get_fixture(proxy=False):\n",
    "    '''\n",
    "    this is to get AFL fixture from theroar.com.au\n",
    "    set proxy=True if you are on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    url='https://www.theroar.com.au/afl-draw/'\n",
    "    sauce = urllib.request.urlopen(url)\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "    fixture = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "\n",
    "    for x in soup.find_all('tbody'):\n",
    "        rnd_counter = 0\n",
    "\n",
    "        for y in x.find_all('tr'):\n",
    "\n",
    "            if y.find_all('strong'):\n",
    "                rnd_counter +=1\n",
    "\n",
    "            else:\n",
    "                if not y.find_all('h3') and 'Byes' not in y.text and 'TBC' not in y.text:\n",
    "                    dt,teams,venue,tm = y.text.strip().split('\\n')\n",
    "                    if dt == 'Sar Apr 21':\n",
    "                        dt = 'Sat Apr 21'\n",
    "\n",
    "                    dt = parser.parse(dt)\n",
    "                    if teams == 'North Melbourne Carlton':\n",
    "                            hm_team = 'North Melbourne'\n",
    "                            aw_team = 'Carlton'\n",
    "                    else:\n",
    "                        hm_team, aw_team = teams.split(' vs ')\n",
    "\n",
    "                    #print(rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue))\n",
    "                    df = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "                    df.loc[0]=[rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue)]\n",
    "                    fixture = pd.concat([fixture,df])\n",
    "    return fixture\n",
    "\n",
    "def get_odds_history(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this function gets odds history from footywire.com\n",
    "    min season from is 2010- so it will make the min date 2010 if less than that\n",
    "    set proxy=True if on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    if season_from<2010:\n",
    "        season_from=2010\n",
    "    odds_history=pd.DataFrame()\n",
    "    for season in range(season_from,season_to+1):\n",
    "        print('Getting odds for season',season,'...')\n",
    "        sauce = urllib.request.urlopen('https://www.footywire.com/afl/footy/afl_betting?year='+str(season))\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "\n",
    "        for x in soup.find_all('div',class_ ='datadiv'):\n",
    "            date=[]\n",
    "            venue=[]\n",
    "            team_HM=[]\n",
    "            odds_HM=[]\n",
    "            team_AW=[]\n",
    "            odds_AW=[]\n",
    "            counter =0\n",
    "\n",
    "            home_team_cursor = True\n",
    "            for y in x.find_all('tr'):\n",
    "\n",
    "                for z in y.find_all('td',class_='data'):\n",
    "                    counter = counter+1\n",
    "                    if z.has_attr('height'):\n",
    "                        counter = 0\n",
    "                        #print('new game ',z.text)\n",
    "                        date.append(z.text)\n",
    "                    elif z.has_attr('rowspan'):\n",
    "                        #print('venue ', z.text)\n",
    "                        venue.append(z.text)\n",
    "                    elif not z.has_attr('align'):\n",
    "                        if counter == 2:\n",
    "                            #print('Home team: ', z.text)\n",
    "                            team_HM.append(z.text)\n",
    "                            home_team_cursor=True    \n",
    "                        else:\n",
    "                            #print('Away team: ', z.text)\n",
    "                            counter = 0\n",
    "                            team_AW.append(z.text)\n",
    "                            home_team_cursor=False\n",
    "                    elif counter ==3 and not home_team_cursor:\n",
    "                        #print('away team odds: ',z.text)\n",
    "                        odds_AW.append(z.text)\n",
    "                    elif counter==5 and home_team_cursor:\n",
    "                        #print('home team odds: ',z.text)\n",
    "                        odds_HM.append(z.text)\n",
    "        odds = pd.DataFrame()\n",
    "        odds['Date']=[parser.parse(x,dayfirst=True) for x in date]\n",
    "        odds['Venue']=[fix_venue(x) for x in venue]\n",
    "        odds['HomeTeam']=[fix_team_name(x) for x in team_HM]\n",
    "        odds['OddsHome']=[x for x in odds_HM]\n",
    "        odds['AwayTeam']=[fix_team_name(x) for x in team_AW]\n",
    "        odds['OddsAway']=[x for x in odds_AW]\n",
    "        odds_history = pd.concat([odds_history,odds])  \n",
    "    odds = odds.drop_duplicates(subset=['Date','HomeTeam','AwayTeam'],keep='last')\n",
    "    return odds_history\n",
    "\n",
    "def get_games(proxy=False):\n",
    "    \n",
    "    '''\n",
    "    this function gets past games history\n",
    "    and gets attendance where it is available\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "        \n",
    "    col_specification =[(7, 15), (16, 33), (51, 68), (87, 116),(117,128)]\n",
    "    attend = pd.read_fwf('https://afltables.com/afl/stats/biglists/bg7.txt', \n",
    "                         colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    attend.columns = ['Attendance', 'HomeTeam', 'AwayTeam', 'Venue','Date']\n",
    "    attend['Date']  = pd.to_datetime(attend['Date'],dayfirst=True)\n",
    "    attend['Attendance'] = attend.Attendance.str.replace(r\"[\\*]\",'')\n",
    "    col_specification =[(0, 5), (7, 18), (24, 27), (29, 46),(47,63), (64,81),(82,99),(100,117)]\n",
    "    games= pd.read_fwf('http://afltables.com/afl/stats/biglists/bg3.txt', \n",
    "                       colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    games.columns = ['GameID', 'Date', 'Round', 'HomeTeam', 'ScoreHm','AwayTeam','ScoreAw','Venue']\n",
    "    games = pd.merge(games,attend,how='left',on=['Venue','Date','HomeTeam','AwayTeam'])\n",
    "\n",
    "    #fix rounds in games\n",
    "    games['Round'] = [fix_round(x) for x in games['Round']]\n",
    "    \n",
    "    games['Year']=games['Date'].map(lambda x: x.year)\n",
    "\n",
    "    #fix North Melb in games\n",
    "    games['HomeTeam'] = [fix_team_name(x) for x in games['HomeTeam']]\n",
    "    games['AwayTeam'] = [fix_team_name(x) for x in games['AwayTeam']]\n",
    "\n",
    "    # get result\n",
    "    games['H'] = [int(x.split('.')[2]) for x in games['ScoreHm']]\n",
    "    games['A'] = [int(x.split('.')[2]) for x in games['ScoreAw']]\n",
    "    games = games.drop(['ScoreHm','ScoreAw'],1)\n",
    "    games['Result'] = [round((x[0] /(x[0] +x[1])),3) for x in zip(games['H'],games['A'])]\n",
    "    #games = games.drop(['H','A'],1)\n",
    "    games['ResultWL'] = [1 if x>=0.5 else 0 for x in games.Result]\n",
    "    games['Venue']=[fix_venue(x) for x in games['Venue']]\n",
    "    return games\n",
    "\n",
    "\n",
    "def get_team_performance_hist(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this is to get the team performance history\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BHt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CGt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BRt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CMt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%t'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    #added Score metric SC\n",
    "    team_performace['SCt'] = [g*6+b for g,b in zip(team_performace['GLt'],team_performace['BHt'])]\n",
    "    # this version change - getting opponent's stats \"o\" in column name is for \"opposition\"\n",
    "    team_performace['KIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['KI']]\n",
    "    team_performace['MKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MK']]\n",
    "    team_performace['HBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HB']]\n",
    "    team_performace['DIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['DI']]\n",
    "    team_performace['GLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GL']]\n",
    "    team_performace['BHo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BH']]\n",
    "    team_performace['HOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HO']]\n",
    "    team_performace['TKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['TK']]\n",
    "    team_performace['RBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['RB']]\n",
    "    team_performace['IFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['IF']]\n",
    "    team_performace['CLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CL']]\n",
    "    team_performace['CGo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CG']]\n",
    "    team_performace['FFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FF']]\n",
    "    team_performace['FAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FA']]\n",
    "    team_performace['BRo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BR']]\n",
    "    team_performace['CPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CP']]\n",
    "    team_performace['UPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['UP']]\n",
    "    team_performace['CMo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CM']]\n",
    "    team_performace['MIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MI']]\n",
    "    team_performace['1%o'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['1%']]\n",
    "    team_performace['BOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BO']]\n",
    "    team_performace['GAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GA']]\n",
    "    team_performace['SCo'] = [g*6+b for g,b in zip(team_performace['GLo'],team_performace['BHo'])]\n",
    "    #added Score metric SC\n",
    "    \n",
    "    #difference metric\n",
    "    team_performace['KI'] = [t-o for t,o in zip(team_performace['KIt'],team_performace['KIo'])]\n",
    "    team_performace['MK'] = [t-o for t,o in zip(team_performace['MKt'],team_performace['MKo'])]\n",
    "    team_performace['HB'] = [t-o for t,o in zip(team_performace['HBt'],team_performace['HBo'])]\n",
    "    team_performace['DI'] = [t-o for t,o in zip(team_performace['DIt'],team_performace['DIo'])]\n",
    "    team_performace['GL'] = [t-o for t,o in zip(team_performace['GLt'],team_performace['GLo'])]\n",
    "    team_performace['BH'] = [t-o for t,o in zip(team_performace['BHt'],team_performace['BHo'])]\n",
    "    team_performace['HO'] = [t-o for t,o in zip(team_performace['HOt'],team_performace['HOo'])]\n",
    "    team_performace['TK'] = [t-o for t,o in zip(team_performace['TKt'],team_performace['TKo'])]\n",
    "    team_performace['RB'] = [t-o for t,o in zip(team_performace['RBt'],team_performace['RBo'])]\n",
    "    team_performace['IF'] = [t-o for t,o in zip(team_performace['IFt'],team_performace['IFo'])]\n",
    "    team_performace['CL'] = [t-o for t,o in zip(team_performace['CLt'],team_performace['CLo'])]\n",
    "    team_performace['CG'] = [t-o for t,o in zip(team_performace['CGt'],team_performace['CGo'])]\n",
    "    team_performace['FF'] = [t-o for t,o in zip(team_performace['FFt'],team_performace['FFo'])]\n",
    "    team_performace['FA'] = [t-o for t,o in zip(team_performace['FAt'],team_performace['FAo'])]\n",
    "    team_performace['BR'] = [t-o for t,o in zip(team_performace['BRt'],team_performace['BRo'])]\n",
    "    team_performace['CP'] = [t-o for t,o in zip(team_performace['CPt'],team_performace['CPo'])]\n",
    "    team_performace['UP'] = [t-o for t,o in zip(team_performace['UPt'],team_performace['UPo'])]\n",
    "    team_performace['CM'] = [t-o for t,o in zip(team_performace['CMt'],team_performace['CMo'])]\n",
    "    team_performace['MI'] = [t-o for t,o in zip(team_performace['MIt'],team_performace['MIo'])]\n",
    "    team_performace['1%'] = [t-o for t,o in zip(team_performace['1%t'],team_performace['1%o'])]\n",
    "    team_performace['BO'] = [t-o for t,o in zip(team_performace['BOt'],team_performace['BOo'])]\n",
    "    team_performace['GA'] = [t-o for t,o in zip(team_performace['GAt'],team_performace['GAo'])]\n",
    "    team_performace['SC'] = [t-o for t,o in zip(team_performace['SCt'],team_performace['SCo'])]\n",
    "    return team_performace\n",
    "\n",
    "def get_team_performance_hist_rel(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this relative version of team performance history\n",
    "    main metric is expressed as team's relative advantage over the opponent\n",
    "    e.g. if team goals is 12 and opponent goals is 6\n",
    "    the main GL metric shows (12-6)/(12+6) = 0.333\n",
    "    if both team and opponent metrics are zero then combined one =0\n",
    "    so values range from -1 to +1\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BHt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CGt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BRt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CMt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%t'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    #added Score metric SC\n",
    "    team_performace['SCt'] = [g*6+b for g,b in zip(team_performace['GLt'],team_performace['BHt'])]\n",
    "    # this version change - getting opponent's stats \"o\" in column name is for \"opposition\"\n",
    "    team_performace['KIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['KI']]\n",
    "    team_performace['MKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MK']]\n",
    "    team_performace['HBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HB']]\n",
    "    team_performace['DIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['DI']]\n",
    "    team_performace['GLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GL']]\n",
    "    team_performace['BHo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BH']]\n",
    "    team_performace['HOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HO']]\n",
    "    team_performace['TKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['TK']]\n",
    "    team_performace['RBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['RB']]\n",
    "    team_performace['IFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['IF']]\n",
    "    team_performace['CLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CL']]\n",
    "    team_performace['CGo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CG']]\n",
    "    team_performace['FFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FF']]\n",
    "    team_performace['FAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FA']]\n",
    "    team_performace['BRo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BR']]\n",
    "    team_performace['CPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CP']]\n",
    "    team_performace['UPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['UP']]\n",
    "    team_performace['CMo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CM']]\n",
    "    team_performace['MIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MI']]\n",
    "    team_performace['1%o'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['1%']]\n",
    "    team_performace['BOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BO']]\n",
    "    team_performace['GAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GA']]\n",
    "    team_performace['SCo'] = [g*6+b for g,b in zip(team_performace['GLo'],team_performace['BHo'])]\n",
    "    #added Score metric SC\n",
    "    \n",
    "    #difference metric - now relative version ranging from -1 to +1 where 0 is even performance\n",
    "    team_performace['KI'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['KIt'],team_performace['KIo'])]\n",
    "    team_performace['MK'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['MKt'],team_performace['MKo'])]\n",
    "    team_performace['HB'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['HBt'],team_performace['HBo'])]\n",
    "    team_performace['DI'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['DIt'],team_performace['DIo'])]\n",
    "    team_performace['GL'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['GLt'],team_performace['GLo'])]\n",
    "    team_performace['BH'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['BHt'],team_performace['BHo'])]\n",
    "    team_performace['HO'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['HOt'],team_performace['HOo'])]\n",
    "    team_performace['TK'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['TKt'],team_performace['TKo'])]\n",
    "    team_performace['RB'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['RBt'],team_performace['RBo'])]\n",
    "    team_performace['IF'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['IFt'],team_performace['IFo'])]\n",
    "    team_performace['CL'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CLt'],team_performace['CLo'])]\n",
    "    team_performace['CG'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CGt'],team_performace['CGo'])]\n",
    "    team_performace['FF'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['FFt'],team_performace['FFo'])]\n",
    "    team_performace['FA'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['FAt'],team_performace['FAo'])]\n",
    "    team_performace['BR'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['BRt'],team_performace['BRo'])]\n",
    "    team_performace['CP'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CPt'],team_performace['CPo'])]\n",
    "    team_performace['UP'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['UPt'],team_performace['UPo'])]\n",
    "    team_performace['CM'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CMt'],team_performace['CMo'])]\n",
    "    team_performace['MI'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['MIt'],team_performace['MIo'])]\n",
    "    team_performace['1%'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['1%t'],team_performace['1%o'])]\n",
    "    team_performace['BO'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['BOt'],team_performace['BOo'])]\n",
    "    team_performace['GA'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['GAt'],team_performace['GAo'])]\n",
    "    team_performace['SC'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['SCt'],team_performace['SCo'])]\n",
    "    return team_performace\n",
    "\n",
    "def get_lineup(year,rnd,proxy=False):\n",
    "    '''\n",
    "    returns all available line-up for given year\n",
    "    year - current year you need to specify\n",
    "    rnd - current round where line-up has been released (could be improved into auto later)\n",
    "    proxy = True if on LAN\n",
    "    Pre-requisites: \n",
    "     1.TeamRef.csv - file which maps team names to AFL line-up abbreviated names\n",
    "     2.Fixture function is used\n",
    "\n",
    "    '''    \n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "\n",
    "    fixture = get_fixture(proxy)\n",
    "    fixture = fixture[fixture.Round==rnd]  #this limits to current round only\n",
    "    teams = pd.read_csv(get_drive()+'TeamRef.csv')\n",
    "\n",
    "    this_1 = pd.merge(fixture,teams,how=\"inner\",left_on=['HomeTeam'],right_on=['Team'])\n",
    "    this_2 = pd.merge(this_1,teams,how=\"inner\",left_on=['AwayTeam'],right_on=['Team'])\n",
    "    rounds = this_2.drop(['Team_x','Team_y'],1)\n",
    "    rounds['Game'] = [x + '-v-' +y for x,y in zip(rounds.AFL_Team_Nm_x,rounds.AFL_Team_Nm_y)]\n",
    "    rounds = rounds.drop(['AFL_Team_Nm_x','AFL_Team_Nm_y'],1)\n",
    "\n",
    "\n",
    "    # now get available line-up for player ref working\n",
    "\n",
    "    #rounds = rounds[rounds.Round<=max_round]    # needs updating, just available\n",
    "\n",
    "    lineup=pd.DataFrame()\n",
    "    for gm,rnd in zip(rounds['Game'],rounds['Round']):\n",
    "        url='http://www.afl.com.au/match-centre/'+str(year)+'/'+str(rnd)+'/'+gm\n",
    "        \n",
    "        sauce = urllib.request.urlopen(url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        plrs=[]\n",
    "        for x in soup.find_all('div',class_ ='lineup'):\n",
    "            for t in x.find_all('div',class_ ='text-inouts'):\n",
    "                team=''\n",
    "                for tm in t.find_all('h4'):\n",
    "                    team=tm.text\n",
    "\n",
    "                for p in t.find_all('div',class_ ='posGroup'):\n",
    "                    position=''\n",
    "                    for pos in p.find_all('p',class_ ='pos'):\n",
    "                        position =pos.text.strip()\n",
    "                    for player in p.find_all('li'):\n",
    "                        if position in ['B','HB','C','HF','F','Fol','I/C']:\n",
    "                            tms.append(team)\n",
    "                            plrs.append(player.text.strip().strip(','))\n",
    "\n",
    "        d = pd.DataFrame()\n",
    "        d['Team'] = tms\n",
    "        d['Player'] = plrs\n",
    "        lineup=pd.concat([lineup,d])\n",
    "    lineup['Team']=[fix_team_name(x) for x in lineup['Team']]\n",
    "    return lineup\n",
    "\n",
    "def get_player_base(proxy):\n",
    "    '''\n",
    "    !!! run only when need to update for new players !!!\n",
    "    returns a dataframe of player base table to enable to skip older players\n",
    "    e.g. players[players.DoB>'1975-01-01']  this gives 2.5k player subset\n",
    "    \n",
    "    typical use - to create Players.csv file in AFL directory - !!! pre-requisite for getting player performance\n",
    "\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    players = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days'])\n",
    "\n",
    "    # get player urls\n",
    "    links = []\n",
    "    for c in ascii_uppercase :\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/players'+c+'_idx.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "        for url in soup.find_all('a',href=True):\n",
    "            links.append('https://afltables.com/afl/stats/'+url['href'])\n",
    "    # now remove non-player links - ones that contain 'idx'\n",
    "    links = [item for item in links if 'players' in item and 'idx' not in item and 'afl_index' not in item]        \n",
    "\n",
    "    for cur_url in links:\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        #Name\n",
    "        x = soup.find_all('h1')\n",
    "        name = x[0].text\n",
    "\n",
    "        #DoB\n",
    "        found_dob=False\n",
    "\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Born:':\n",
    "                dob = x.next_sibling\n",
    "                found_dob=True\n",
    "                break\n",
    "        if found_dob:\n",
    "            dob=parser.parse(dob[0:11],dayfirst=True)\n",
    "        else:\n",
    "            dob = datetime.datetime(1900, 1, 1, 0, 0)\n",
    "\n",
    "        #Debut\n",
    "        found_debut = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Debut:':\n",
    "                debut = x.next_sibling\n",
    "                found_debut=True\n",
    "                break\n",
    "        if found_debut:\n",
    "            debut =debut.split()\n",
    "            debut1 = ''.join(c for c in debut[0] if c.isdigit())\n",
    "            if len(debut)>1:\n",
    "                debut2 = ''.join(c for c in debut[1] if c.isdigit())\n",
    "                debut = int(debut1)+int(debut2)/365\n",
    "            else:\n",
    "                debut = int(debut1)\n",
    "        else:\n",
    "            debut = 100\n",
    "        #age last played\n",
    "        found_last = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Last:':\n",
    "                age_last = x.next_sibling\n",
    "                found_last=True\n",
    "                break\n",
    "        if found_last:\n",
    "            age_last =age_last.split()\n",
    "            a1 = ''.join(c for c in age_last[0] if c.isdigit())\n",
    "            if len(age_last)>1:\n",
    "                a2 = ''.join(c for c in age_last[1] if c.isdigit())\n",
    "                age_last = int(a1)*365.25+int(a2) #in days\n",
    "            else:\n",
    "                age_last = int(a1)*365.25\n",
    "        else:\n",
    "            age_last = 40*365.25\n",
    "        today = datetime.datetime.today()\n",
    "        last_played_date = dob + datetime.timedelta(days=age_last)\n",
    "        since_last_game=today-last_played_date\n",
    "        df = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days','Last_Played_Date'])\n",
    "        df.loc[0]=[name,dob,cur_url,debut,age_last,last_played_date]\n",
    "        players = pd.concat([players,df])\n",
    "        print(name)\n",
    "    return players\n",
    "\n",
    "\n",
    "\n",
    "def get_player_perf(DoB_min='1975-01-01',proxy=False):\n",
    "    '''\n",
    "    Use this only once per complete round and save into CSV as it takes a while to run\n",
    "    this function returns a dataframe of player performance history\n",
    "    Entire player history is returned\n",
    "    DoB_min is limiting factor to get only player born after the date - for performance reasons\n",
    "    change the default if you need to go more back into older players or in reverse\n",
    "    Pre-requisite: Players.csv file exists in the AFL directory\n",
    "    set proxy=True when on office LAN\n",
    "    \n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "    players = pd.read_csv(get_drive()+'Players.csv')\n",
    "    players =players[players['DoB']>DoB_min]\n",
    "\n",
    "    player_stats = pd.DataFrame(columns=['Url','Team','Year'])\n",
    "\n",
    "    for cur_url in players.Url:\n",
    "        print(cur_url)\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        found=False\n",
    "        dfs=[]\n",
    "        for table in soup.find_all('table'):\n",
    "            #t1=tables[7]\n",
    "            t=table.find('tbody')\n",
    "            res = []\n",
    "            row = []\n",
    "            rows = t.find_all('tr')\n",
    "            for tr in rows:\n",
    "                for td in tr.find_all('td'):\n",
    "                    row.append(td.text)\n",
    "                res.append(row)\n",
    "                row = []\n",
    "            df=pd.DataFrame(data=res)\n",
    "\n",
    "            if len(df.columns)==28: # found first game\n",
    "                    found = True\n",
    "            if found:\n",
    "                h=table.find('thead')\n",
    "                h1 = h.find('tr')\n",
    "                h2 = h1.find('th')\n",
    "                header =h2.text\n",
    "                team_year = header.split('-')\n",
    "                team = team_year[0].strip()\n",
    "                year = team_year[1].strip()\n",
    "                df['Url']=cur_url\n",
    "                df['Team']=team\n",
    "                df['Year']=year\n",
    "                player_stats = pd.concat([player_stats,df])\n",
    "    player_stats = player_stats.rename(columns={0:'GameNo',1:'Opponent',2:'Round',3:'Result',4:'Jersey',5:'KI',6:'MK',7:'HB',8:'DI',9:'GL',10:'BH',11:'HO',12:'TK',13:'RB',14:'IF',15:'CL',16:'CG',17:'FF',18:'FA',19:'BR',20:'CP',21:'UP',22:'CM',23:'MI',24:'1%',25:'BO',26:'GA',27:'%P'})\n",
    "    player_stats['Round']=[fix_round(x) for x in player_stats['Round']]\n",
    "\n",
    "\n",
    "    games_set = get_games(proxy=False)\n",
    "\n",
    "\n",
    "\n",
    "    #create one game row for each team\n",
    "    gamesH = games_set.drop(['AwayTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesA = games_set.drop(['HomeTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesH=gamesH.rename(columns={'HomeTeam':'Team'})\n",
    "    gamesA=gamesA.rename(columns={'AwayTeam':'Team'})\n",
    "    gamesAH=pd.concat([gamesH,gamesA])\n",
    "    gamesAH['Year'] = [str(x) for x in gamesAH['Year']]\n",
    "    # get date and game id for each player record\n",
    "    player_stats=pd.merge(player_stats,gamesAH,how='inner',on=['Team','Year','Round'])\n",
    "    player_stats=player_stats.drop_duplicates(subset=['Url','Year','Round'],keep='first')\n",
    "    \n",
    "    return player_stats\n",
    "\n",
    "def get_pastXthis_opponent(x,team,opponent,dt,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, opponent, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    #last 3 against this team\n",
    "    tp = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Opponent']==opponent) ]  # later row.Team\n",
    "    tp = tp.sort_values(by=['Date'],ascending=False)\n",
    "    tp = tp.head(x)\n",
    "    tp = tp.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "\n",
    "    tp_avg = tp.groupby(by='Team').aggregate('mean')\n",
    "    tp_avg.columns = [str(col) + '_lstXopp' for col in tp_avg.columns]\n",
    "    if tp_avg.shape[0]==0:\n",
    "        print('empty row generated for ', dt,' team:',team, ' vs.', opponent)\n",
    "    return tp_avg\n",
    "\n",
    "def get_pastXground(x,team,dt,venue,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date and venue of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    tp2 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Venue'] == venue)] \n",
    "    tp2 = tp2.sort_values(by=['Date'],ascending=False)\n",
    "    tp2 = tp2.head(x)\n",
    "    tp2 = tp2.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp2_avg = tp2.groupby(by='Team').aggregate('mean')\n",
    "    tp2_avg.columns = [str(col) + '_lstXgrd' for col in tp2_avg.columns]\n",
    "    if tp2_avg.shape[0]==0:\n",
    "        print('empty row generated for ',dt,' at ', venue,' team:',team)\n",
    "    return tp2_avg\n",
    "\n",
    "def get_pastX(x,team,dt,team_performaceDF,print_missing=False):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tp1 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt)] \n",
    "    tp1 = tp1.sort_values(by=['Date'],ascending=False)\n",
    "    tp1 = tp1.head(x)\n",
    "    tp1 = tp1.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp1_avg = tp1.groupby(by='Team').aggregate('mean')\n",
    "    tp1_avg.columns = [str(col) + '_lstX' for col in tp1_avg.columns]\n",
    "    if tp1_avg.shape[0]==0 and print_missing:\n",
    "        print('empty row generated for ', dt,' team:',team)\n",
    "    return tp1_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 September 2018 Adding a combined function to get dataset for training or scoring\n",
    "\n",
    "\n",
    "def get_drive():\n",
    "    '''\n",
    "    this is to automate switching between home PC and laptop\n",
    "    it returns J:\\\\AFL\\\\ or D:\\\\AFL\\\\ depending if D:\\ is available\n",
    "    \n",
    "    No parameters required\n",
    "    '''\n",
    "    \n",
    "    import win32api\n",
    "    drives = win32api.GetLogicalDriveStrings()\n",
    "    drives = drives.split('\\000')[:-1]\n",
    "    if 'D:\\\\' in drives:\n",
    "        drive = 'D:\\\\AFL\\\\'\n",
    "    else:\n",
    "        drive = 'J:\\\\AFL\\\\'\n",
    "    return drive\n",
    "\n",
    "\n",
    "def get_proxy(proxy):\n",
    "        if proxy:\n",
    "            from os import environ\n",
    "            #pwd = input('Please enter your LAN Pwd')\n",
    "            environ[\"http_proxy\"]=\"http://c819325:sWeater78-@http-gw.tcif.telstra.com.au:8080\"\n",
    "            environ[\"https_proxy\"]=environ.get(\"http_proxy\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fix_round(round_in):\n",
    "    '''\n",
    "    this function convert Round values into sequential integers\n",
    "    '''\n",
    "    if round_in=='QF':\n",
    "        rnd='25'\n",
    "    elif round_in=='EF':\n",
    "        rnd='26'\n",
    "    elif round_in=='SF':\n",
    "        rnd='27'\n",
    "    elif round_in=='PF':\n",
    "        rnd='28'\n",
    "    elif round_in=='GF':\n",
    "        rnd='29'\n",
    "    elif round_in[0]=='R':\n",
    "        rnd=round_in[1:]\n",
    "    else:\n",
    "        rnd=round_in\n",
    "    return int(rnd)\n",
    "\n",
    "def fix_team_name(name):\n",
    "    '''\n",
    "    this function converts any team name to a consistent\n",
    "    set of  names which are usable for joins\n",
    "    '''\n",
    "    if 'Crows' in name:\n",
    "        team_name='Adelaide'\n",
    "    elif name.strip()=='Adelaide Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='AD':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='BL':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='Lions':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='CA':\n",
    "        team_name='Carlton'\n",
    "    elif name=='Blues':\n",
    "        team_name='Carlton'\n",
    "    elif name=='CW':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='Magpies':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='ES':\n",
    "        team_name='Essendon'\n",
    "    elif name=='Bombers':\n",
    "        team_name='Essendon'\n",
    "    elif name=='FR':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='Dockers':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='GE':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Geelong Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='GC':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Gold Coast Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='GWS Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GWS':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW Sydney':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='HW':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='Hawks':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='ME':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Demons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Deamons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='KA':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='NM':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='Kangaroos':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='PA':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='Power':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='RI':\n",
    "        team_name='Richmond'\n",
    "    elif name=='Tigers':\n",
    "        team_name='Richmond'\n",
    "    elif name=='SK':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='Saints':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='SY':\n",
    "        team_name='Sydney'\n",
    "    elif 'Swans' in name:\n",
    "        team_name='Sydney'\n",
    "    elif name=='WC':\n",
    "        team_name='West Coast'\n",
    "    elif name=='West Coast Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='WB':\n",
    "        team_name='Western Bulldogs'\n",
    "    elif name=='Bulldogs':\n",
    "        team_name='Western Bulldogs'\n",
    "    else:\n",
    "        team_name=name\n",
    "    return team_name\n",
    "\n",
    "def fix_venue(name):\n",
    "    if name=='AAMI':\n",
    "        ground = 'Olympic Park'\n",
    "    elif name=='ANZ':\n",
    "        ground = 'Stadium Australia'\n",
    "    elif name=='Football Park':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Adelaide':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Aurora':\n",
    "        ground = 'York Park'\n",
    "    elif name=='Blacktown':\n",
    "        ground='Blacktown'\n",
    "    elif name=='Blundstone Arena':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name=='Blundstone':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name==\"Cazaly's\":\n",
    "        ground= \"Cazaly's Stadium\"\n",
    "    elif name=='Domain':\n",
    "        ground='Subiaco'\n",
    "    elif name=='Etihad Stadium':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='Etihad':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='GMHBA Stadium':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='GMHBA':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='Gabba':\n",
    "        ground = 'Gabba'\n",
    "    elif name=='Jiangwan':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='Jiangwan Stadium, China':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='M.C.G':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='MCG':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='Mars Stadium, Ballarat':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Mars':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Metricon Stadium':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Metricon':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Perth':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='Subiaco':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='SCG':\n",
    "        ground='S.C.G.'\n",
    "    elif name=='Spotless Stadium':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='Spotless':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='UNSW Canberra Oval':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='StarTrack':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='Treager Park, Alice Springs':\n",
    "        ground='Traeger Park'\n",
    "    elif name=='TIO Stadium, Darwin':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='TIO':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='University of Tasmania Stadium':\n",
    "        ground='York Park'\n",
    "    elif name=='UTAS':\n",
    "        ground='York Park'\n",
    "    elif name=='Westpac':\n",
    "        ground='Wellington'\n",
    "    else:\n",
    "        ground=name\n",
    "    return ground\n",
    "\n",
    "def get_ladder(seas_from,seas_to,proxy=False):\n",
    "    '''\n",
    "    this is just to get the ladder history\n",
    "\n",
    "    Input required - update season from and to in the function call at the bottom\n",
    "    this function returns a dataframe for AFL ladder position history\n",
    "    seas_from - season to start from\n",
    "    seas_to - season end - inclusive\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    ladder = pd.DataFrame(columns=['Team','Games','Points','Percentage','Round','Position','Season'])\n",
    "    for season in range(seas_from-1,seas_to+1): \n",
    "        cur_url = 'http://afltables.com/afl/seas/'+str(season)+'.html'\n",
    "        dfs = pd.read_html(cur_url)\n",
    "\n",
    "        for df in dfs:\n",
    "            if df.columns.nlevels>1:\n",
    "                break\n",
    "            if len(df)>1 and 'Ladder' in df[0][0] and 'Rd' in df[0][0] and len(df.columns)>2:\n",
    "                rnd = df[0][0][3:5]\n",
    "                ldr = df.copy() \n",
    "                ldr = ldr.drop(0,0)\n",
    "                ldr.columns = ['Team','Games','Points','Percentage']\n",
    "                ldr['Round']=rnd\n",
    "                ldr['Position']=ldr.index\n",
    "                ldr['Season']=season\n",
    "                ladder = pd.concat([ladder,ldr])\n",
    "    ladder['Team'] = [fix_team_name(x) for x in ladder['Team']]\n",
    "    \n",
    "    # repeat last round for last and until 29\n",
    "    ladder_f = ladder.copy()\n",
    "    ladder_f.drop_duplicates(subset=['Team','Season'], keep='last', inplace=True)\n",
    "\n",
    "    # get last round for each season\n",
    "    ladder_y = ladder_f.copy()\n",
    "    ladder_y.drop_duplicates(subset=['Season'], keep='last', inplace=True)\n",
    "    ladder_y=ladder_y.drop(['Team','Games','Points','Percentage','Position'],1)\n",
    "    rnd=[]\n",
    "    seas=[]\n",
    "    for index, row in ladder_y.iterrows():\n",
    "        st = int(row.Round)\n",
    "        #print(type(st))\n",
    "        for i in range(st+1,30):\n",
    "            rnd.append(i)\n",
    "            seas.append(row.Season)\n",
    "    ldr = pd.DataFrame()\n",
    "    ldr['Season'] = seas\n",
    "    ldr['Round'] = rnd\n",
    "    #ldr = pd.merge(ladder_f.drop(['Round'],1),ldr,how='inner',on=['Season'])\n",
    "    ladder = pd.concat([ladder,ldr],sort=False)\n",
    "    ladder = ladder.sort_values(by=['Team','Season'],axis=0)\n",
    "    ladder['PosOld']=ladder.Position.shift(1)  #previous ladder position taken\n",
    "    ladder = ladder.drop(['Position'],1)\n",
    "    ladder['Round']= [int(x) for x in ladder['Round']]\n",
    "    ladder=ladder.dropna(axis=0)\n",
    "    ladder['PosOld']= [int(x) for x in ladder['PosOld']]  \n",
    "    return ladder\n",
    "\n",
    "def get_fixture(proxy=False):\n",
    "    '''\n",
    "    this is to get AFL fixture from theroar.com.au\n",
    "    set proxy=True if you are on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    url='https://www.theroar.com.au/afl-draw/'\n",
    "    sauce = urllib.request.urlopen(url)\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "    fixture = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "\n",
    "    for x in soup.find_all('tbody'):\n",
    "        rnd_counter = 0\n",
    "\n",
    "        for y in x.find_all('tr'):\n",
    "\n",
    "            if y.find_all('strong'):\n",
    "                rnd_counter +=1\n",
    "\n",
    "            else:\n",
    "                if not y.find_all('h3') and 'Byes' not in y.text and 'TBC' not in y.text:\n",
    "                    dt,teams,venue,tm = y.text.strip().split('\\n')\n",
    "                    if dt == 'Sar Apr 21':\n",
    "                        dt = 'Sat Apr 21'\n",
    "\n",
    "                    dt = parser.parse(dt)\n",
    "                    if teams == 'North Melbourne Carlton':\n",
    "                            hm_team = 'North Melbourne'\n",
    "                            aw_team = 'Carlton'\n",
    "                    else:\n",
    "                        hm_team, aw_team = teams.split(' vs ')\n",
    "\n",
    "                    #print(rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue))\n",
    "                    df = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "                    df.loc[0]=[rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue)]\n",
    "                    fixture = pd.concat([fixture,df])\n",
    "    return fixture\n",
    "\n",
    "def get_odds_history(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this function gets odds history from footywire.com\n",
    "    min season from is 2010- so it will make the min date 2010 if less than that\n",
    "    set proxy=True if on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    if season_from<2010:\n",
    "        season_from=2010\n",
    "    odds_history=pd.DataFrame()\n",
    "    for season in range(season_from,season_to+1):\n",
    "        print('Getting odds for season',season,'...')\n",
    "        sauce = urllib.request.urlopen('https://www.footywire.com/afl/footy/afl_betting?year='+str(season))\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "\n",
    "        for x in soup.find_all('div',class_ ='datadiv'):\n",
    "            date=[]\n",
    "            venue=[]\n",
    "            team_HM=[]\n",
    "            odds_HM=[]\n",
    "            team_AW=[]\n",
    "            odds_AW=[]\n",
    "            counter =0\n",
    "\n",
    "            home_team_cursor = True\n",
    "            for y in x.find_all('tr'):\n",
    "\n",
    "                for z in y.find_all('td',class_='data'):\n",
    "                    counter = counter+1\n",
    "                    if z.has_attr('height'):\n",
    "                        counter = 0\n",
    "                        #print('new game ',z.text)\n",
    "                        date.append(z.text)\n",
    "                    elif z.has_attr('rowspan'):\n",
    "                        #print('venue ', z.text)\n",
    "                        venue.append(z.text)\n",
    "                    elif not z.has_attr('align'):\n",
    "                        if counter == 2:\n",
    "                            #print('Home team: ', z.text)\n",
    "                            team_HM.append(z.text)\n",
    "                            home_team_cursor=True    \n",
    "                        else:\n",
    "                            #print('Away team: ', z.text)\n",
    "                            counter = 0\n",
    "                            team_AW.append(z.text)\n",
    "                            home_team_cursor=False\n",
    "                    elif counter ==3 and not home_team_cursor:\n",
    "                        #print('away team odds: ',z.text)\n",
    "                        odds_AW.append(z.text)\n",
    "                    elif counter==5 and home_team_cursor:\n",
    "                        #print('home team odds: ',z.text)\n",
    "                        odds_HM.append(z.text)\n",
    "        odds = pd.DataFrame()\n",
    "        odds['Date']=[parser.parse(x,dayfirst=True) for x in date]\n",
    "        odds['Venue']=[fix_venue(x) for x in venue]\n",
    "        odds['HomeTeam']=[fix_team_name(x) for x in team_HM]\n",
    "        odds['OddsHome']=[x for x in odds_HM]\n",
    "        odds['AwayTeam']=[fix_team_name(x) for x in team_AW]\n",
    "        odds['OddsAway']=[x for x in odds_AW]\n",
    "        odds_history = pd.concat([odds_history,odds])  \n",
    "    odds = odds.drop_duplicates(subset=['Date','HomeTeam','AwayTeam'],keep='last')\n",
    "    return odds_history\n",
    "\n",
    "def get_games(proxy=False):\n",
    "    \n",
    "    '''\n",
    "    this function gets past games history\n",
    "    and gets attendance where it is available\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "        \n",
    "    col_specification =[(7, 15), (16, 33), (51, 68), (87, 116),(117,128)]\n",
    "    attend = pd.read_fwf('https://afltables.com/afl/stats/biglists/bg7.txt', \n",
    "                         colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    attend.columns = ['Attendance', 'HomeTeam', 'AwayTeam', 'Venue','Date']\n",
    "    attend['Date']  = pd.to_datetime(attend['Date'],dayfirst=True)\n",
    "    attend['Attendance'] = attend.Attendance.str.replace(r\"[\\*]\",'')\n",
    "    col_specification =[(0, 5), (7, 18), (24, 27), (29, 46),(47,63), (64,81),(82,99),(100,117)]\n",
    "    games= pd.read_fwf('http://afltables.com/afl/stats/biglists/bg3.txt', \n",
    "                       colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    games.columns = ['GameID', 'Date', 'Round', 'HomeTeam', 'ScoreHm','AwayTeam','ScoreAw','Venue']\n",
    "    games = pd.merge(games,attend,how='left',on=['Venue','Date','HomeTeam','AwayTeam'])\n",
    "\n",
    "    #fix rounds in games\n",
    "    games['Round'] = [fix_round(x) for x in games['Round']]\n",
    "    \n",
    "    games['Year']=games['Date'].map(lambda x: x.year)\n",
    "\n",
    "    #fix North Melb in games\n",
    "    games['HomeTeam'] = [fix_team_name(x) for x in games['HomeTeam']]\n",
    "    games['AwayTeam'] = [fix_team_name(x) for x in games['AwayTeam']]\n",
    "\n",
    "    # get result\n",
    "    games['H'] = [int(x.split('.')[2]) for x in games['ScoreHm']]\n",
    "    games['A'] = [int(x.split('.')[2]) for x in games['ScoreAw']]\n",
    "    games = games.drop(['ScoreHm','ScoreAw'],1)\n",
    "    games['Result'] = [round((x[0] /(x[0] +x[1])),3) for x in zip(games['H'],games['A'])]\n",
    "    #games = games.drop(['H','A'],1)\n",
    "    games['ResultWL'] = [1 if x>=0.5 else 0 for x in games.Result]\n",
    "    games['Venue']=[fix_venue(x) for x in games['Venue']]\n",
    "    return games\n",
    "\n",
    "\n",
    "def get_team_performance_hist(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this is to get the team performance history\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BHt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CGt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BRt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CMt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%t'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    #added Score metric SC\n",
    "    team_performace['SCt'] = [g*6+b for g,b in zip(team_performace['GLt'],team_performace['BHt'])]\n",
    "    # this version change - getting opponent's stats \"o\" in column name is for \"opposition\"\n",
    "    team_performace['KIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['KI']]\n",
    "    team_performace['MKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MK']]\n",
    "    team_performace['HBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HB']]\n",
    "    team_performace['DIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['DI']]\n",
    "    team_performace['GLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GL']]\n",
    "    team_performace['BHo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BH']]\n",
    "    team_performace['HOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HO']]\n",
    "    team_performace['TKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['TK']]\n",
    "    team_performace['RBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['RB']]\n",
    "    team_performace['IFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['IF']]\n",
    "    team_performace['CLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CL']]\n",
    "    team_performace['CGo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CG']]\n",
    "    team_performace['FFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FF']]\n",
    "    team_performace['FAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FA']]\n",
    "    team_performace['BRo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BR']]\n",
    "    team_performace['CPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CP']]\n",
    "    team_performace['UPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['UP']]\n",
    "    team_performace['CMo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CM']]\n",
    "    team_performace['MIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MI']]\n",
    "    team_performace['1%o'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['1%']]\n",
    "    team_performace['BOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BO']]\n",
    "    team_performace['GAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GA']]\n",
    "    team_performace['SCo'] = [g*6+b for g,b in zip(team_performace['GLo'],team_performace['BHo'])]\n",
    "    #added Score metric SC\n",
    "    \n",
    "    #difference metric\n",
    "    team_performace['KI'] = [t-o for t,o in zip(team_performace['KIt'],team_performace['KIo'])]\n",
    "    team_performace['MK'] = [t-o for t,o in zip(team_performace['MKt'],team_performace['MKo'])]\n",
    "    team_performace['HB'] = [t-o for t,o in zip(team_performace['HBt'],team_performace['HBo'])]\n",
    "    team_performace['DI'] = [t-o for t,o in zip(team_performace['DIt'],team_performace['DIo'])]\n",
    "    team_performace['GL'] = [t-o for t,o in zip(team_performace['GLt'],team_performace['GLo'])]\n",
    "    team_performace['BH'] = [t-o for t,o in zip(team_performace['BHt'],team_performace['BHo'])]\n",
    "    team_performace['HO'] = [t-o for t,o in zip(team_performace['HOt'],team_performace['HOo'])]\n",
    "    team_performace['TK'] = [t-o for t,o in zip(team_performace['TKt'],team_performace['TKo'])]\n",
    "    team_performace['RB'] = [t-o for t,o in zip(team_performace['RBt'],team_performace['RBo'])]\n",
    "    team_performace['IF'] = [t-o for t,o in zip(team_performace['IFt'],team_performace['IFo'])]\n",
    "    team_performace['CL'] = [t-o for t,o in zip(team_performace['CLt'],team_performace['CLo'])]\n",
    "    team_performace['CG'] = [t-o for t,o in zip(team_performace['CGt'],team_performace['CGo'])]\n",
    "    team_performace['FF'] = [t-o for t,o in zip(team_performace['FFt'],team_performace['FFo'])]\n",
    "    team_performace['FA'] = [t-o for t,o in zip(team_performace['FAt'],team_performace['FAo'])]\n",
    "    team_performace['BR'] = [t-o for t,o in zip(team_performace['BRt'],team_performace['BRo'])]\n",
    "    team_performace['CP'] = [t-o for t,o in zip(team_performace['CPt'],team_performace['CPo'])]\n",
    "    team_performace['UP'] = [t-o for t,o in zip(team_performace['UPt'],team_performace['UPo'])]\n",
    "    team_performace['CM'] = [t-o for t,o in zip(team_performace['CMt'],team_performace['CMo'])]\n",
    "    team_performace['MI'] = [t-o for t,o in zip(team_performace['MIt'],team_performace['MIo'])]\n",
    "    team_performace['1%'] = [t-o for t,o in zip(team_performace['1%t'],team_performace['1%o'])]\n",
    "    team_performace['BO'] = [t-o for t,o in zip(team_performace['BOt'],team_performace['BOo'])]\n",
    "    team_performace['GA'] = [t-o for t,o in zip(team_performace['GAt'],team_performace['GAo'])]\n",
    "    team_performace['SC'] = [t-o for t,o in zip(team_performace['SCt'],team_performace['SCo'])]\n",
    "    return team_performace\n",
    "\n",
    "def get_team_performance_hist_rel(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this relative version of team performance history\n",
    "    main metric is expressed as team's relative advantage over the opponent\n",
    "    e.g. if team goals is 12 and opponent goals is 6\n",
    "    the main GL metric shows (12-6)/(12+6) = 0.333\n",
    "    if both team and opponent metrics are zero then combined one =0\n",
    "    so values range from -1 to +1\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BHt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CGt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BRt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CMt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%t'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    #added Score metric SC\n",
    "    team_performace['SCt'] = [g*6+b for g,b in zip(team_performace['GLt'],team_performace['BHt'])]\n",
    "    # this version change - getting opponent's stats \"o\" in column name is for \"opposition\"\n",
    "    team_performace['KIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['KI']]\n",
    "    team_performace['MKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MK']]\n",
    "    team_performace['HBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HB']]\n",
    "    team_performace['DIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['DI']]\n",
    "    team_performace['GLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GL']]\n",
    "    team_performace['BHo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BH']]\n",
    "    team_performace['HOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HO']]\n",
    "    team_performace['TKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['TK']]\n",
    "    team_performace['RBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['RB']]\n",
    "    team_performace['IFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['IF']]\n",
    "    team_performace['CLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CL']]\n",
    "    team_performace['CGo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CG']]\n",
    "    team_performace['FFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FF']]\n",
    "    team_performace['FAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FA']]\n",
    "    team_performace['BRo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BR']]\n",
    "    team_performace['CPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CP']]\n",
    "    team_performace['UPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['UP']]\n",
    "    team_performace['CMo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CM']]\n",
    "    team_performace['MIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MI']]\n",
    "    team_performace['1%o'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['1%']]\n",
    "    team_performace['BOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BO']]\n",
    "    team_performace['GAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GA']]\n",
    "    team_performace['SCo'] = [g*6+b for g,b in zip(team_performace['GLo'],team_performace['BHo'])]\n",
    "    #added Score metric SC\n",
    "    \n",
    "    #difference metric - now relative version ranging from -1 to +1 where 0 is even performance\n",
    "    team_performace['KI'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['KIt'],team_performace['KIo'])]\n",
    "    team_performace['MK'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['MKt'],team_performace['MKo'])]\n",
    "    team_performace['HB'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['HBt'],team_performace['HBo'])]\n",
    "    team_performace['DI'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['DIt'],team_performace['DIo'])]\n",
    "    team_performace['GL'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['GLt'],team_performace['GLo'])]\n",
    "    team_performace['BH'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['BHt'],team_performace['BHo'])]\n",
    "    team_performace['HO'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['HOt'],team_performace['HOo'])]\n",
    "    team_performace['TK'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['TKt'],team_performace['TKo'])]\n",
    "    team_performace['RB'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['RBt'],team_performace['RBo'])]\n",
    "    team_performace['IF'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['IFt'],team_performace['IFo'])]\n",
    "    team_performace['CL'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CLt'],team_performace['CLo'])]\n",
    "    team_performace['CG'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CGt'],team_performace['CGo'])]\n",
    "    team_performace['FF'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['FFt'],team_performace['FFo'])]\n",
    "    team_performace['FA'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['FAt'],team_performace['FAo'])]\n",
    "    team_performace['BR'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['BRt'],team_performace['BRo'])]\n",
    "    team_performace['CP'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CPt'],team_performace['CPo'])]\n",
    "    team_performace['UP'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['UPt'],team_performace['UPo'])]\n",
    "    team_performace['CM'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CMt'],team_performace['CMo'])]\n",
    "    team_performace['MI'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['MIt'],team_performace['MIo'])]\n",
    "    team_performace['1%'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['1%t'],team_performace['1%o'])]\n",
    "    team_performace['BO'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['BOt'],team_performace['BOo'])]\n",
    "    team_performace['GA'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['GAt'],team_performace['GAo'])]\n",
    "    team_performace['SC'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['SCt'],team_performace['SCo'])]\n",
    "    return team_performace\n",
    "\n",
    "def get_lineup(year,rnd,proxy=False):\n",
    "    '''\n",
    "    returns all available line-up for given year\n",
    "    year - current year you need to specify\n",
    "    rnd - current round where line-up has been released (could be improved into auto later)\n",
    "    proxy = True if on LAN\n",
    "    Pre-requisites: \n",
    "     1.TeamRef.csv - file which maps team names to AFL line-up abbreviated names\n",
    "     2.Fixture function is used\n",
    "\n",
    "    '''    \n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "\n",
    "    fixture = get_fixture(proxy)\n",
    "    fixture = fixture[fixture.Round==rnd]  #this limits to current round only\n",
    "    teams = pd.read_csv(get_drive()+'TeamRef.csv')\n",
    "\n",
    "    this_1 = pd.merge(fixture,teams,how=\"inner\",left_on=['HomeTeam'],right_on=['Team'])\n",
    "    this_2 = pd.merge(this_1,teams,how=\"inner\",left_on=['AwayTeam'],right_on=['Team'])\n",
    "    rounds = this_2.drop(['Team_x','Team_y'],1)\n",
    "    rounds['Game'] = [x + '-v-' +y for x,y in zip(rounds.AFL_Team_Nm_x,rounds.AFL_Team_Nm_y)]\n",
    "    rounds = rounds.drop(['AFL_Team_Nm_x','AFL_Team_Nm_y'],1)\n",
    "\n",
    "\n",
    "    # now get available line-up for player ref working\n",
    "\n",
    "    #rounds = rounds[rounds.Round<=max_round]    # needs updating, just available\n",
    "\n",
    "    lineup=pd.DataFrame()\n",
    "    for gm,rnd in zip(rounds['Game'],rounds['Round']):\n",
    "        url='http://www.afl.com.au/match-centre/'+str(year)+'/'+str(rnd)+'/'+gm\n",
    "        \n",
    "        sauce = urllib.request.urlopen(url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        plrs=[]\n",
    "        for x in soup.find_all('div',class_ ='lineup'):\n",
    "            for t in x.find_all('div',class_ ='text-inouts'):\n",
    "                team=''\n",
    "                for tm in t.find_all('h4'):\n",
    "                    team=tm.text\n",
    "\n",
    "                for p in t.find_all('div',class_ ='posGroup'):\n",
    "                    position=''\n",
    "                    for pos in p.find_all('p',class_ ='pos'):\n",
    "                        position =pos.text.strip()\n",
    "                    for player in p.find_all('li'):\n",
    "                        if position in ['B','HB','C','HF','F','Fol','I/C']:\n",
    "                            tms.append(team)\n",
    "                            plrs.append(player.text.strip().strip(','))\n",
    "\n",
    "        d = pd.DataFrame()\n",
    "        d['Team'] = tms\n",
    "        d['Player'] = plrs\n",
    "        lineup=pd.concat([lineup,d])\n",
    "    lineup['Team']=[fix_team_name(x) for x in lineup['Team']]\n",
    "    return lineup\n",
    "\n",
    "def get_player_base(proxy):\n",
    "    '''\n",
    "    !!! run only when need to update for new players !!!\n",
    "    returns a dataframe of player base table to enable to skip older players\n",
    "    e.g. players[players.DoB>'1975-01-01']  this gives 2.5k player subset\n",
    "    \n",
    "    typical use - to create Players.csv file in AFL directory - !!! pre-requisite for getting player performance\n",
    "\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    players = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days'])\n",
    "\n",
    "    # get player urls\n",
    "    links = []\n",
    "    for c in ascii_uppercase :\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/players'+c+'_idx.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "        for url in soup.find_all('a',href=True):\n",
    "            links.append('https://afltables.com/afl/stats/'+url['href'])\n",
    "    # now remove non-player links - ones that contain 'idx'\n",
    "    links = [item for item in links if 'players' in item and 'idx' not in item and 'afl_index' not in item]        \n",
    "\n",
    "    for cur_url in links:\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        #Name\n",
    "        x = soup.find_all('h1')\n",
    "        name = x[0].text\n",
    "\n",
    "        #DoB\n",
    "        found_dob=False\n",
    "\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Born:':\n",
    "                dob = x.next_sibling\n",
    "                found_dob=True\n",
    "                break\n",
    "        if found_dob:\n",
    "            dob=parser.parse(dob[0:11],dayfirst=True)\n",
    "        else:\n",
    "            dob = datetime.datetime(1900, 1, 1, 0, 0)\n",
    "\n",
    "        #Debut\n",
    "        found_debut = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Debut:':\n",
    "                debut = x.next_sibling\n",
    "                found_debut=True\n",
    "                break\n",
    "        if found_debut:\n",
    "            debut =debut.split()\n",
    "            debut1 = ''.join(c for c in debut[0] if c.isdigit())\n",
    "            if len(debut)>1:\n",
    "                debut2 = ''.join(c for c in debut[1] if c.isdigit())\n",
    "                debut = int(debut1)+int(debut2)/365\n",
    "            else:\n",
    "                debut = int(debut1)\n",
    "        else:\n",
    "            debut = 100\n",
    "        #age last played\n",
    "        found_last = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Last:':\n",
    "                age_last = x.next_sibling\n",
    "                found_last=True\n",
    "                break\n",
    "        if found_last:\n",
    "            age_last =age_last.split()\n",
    "            a1 = ''.join(c for c in age_last[0] if c.isdigit())\n",
    "            if len(age_last)>1:\n",
    "                a2 = ''.join(c for c in age_last[1] if c.isdigit())\n",
    "                age_last = int(a1)*365.25+int(a2) #in days\n",
    "            else:\n",
    "                age_last = int(a1)*365.25\n",
    "        else:\n",
    "            age_last = 40*365.25\n",
    "        today = datetime.datetime.today()\n",
    "        last_played_date = dob + datetime.timedelta(days=age_last)\n",
    "        since_last_game=today-last_played_date\n",
    "        df = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days','Last_Played_Date'])\n",
    "        df.loc[0]=[name,dob,cur_url,debut,age_last,last_played_date]\n",
    "        players = pd.concat([players,df])\n",
    "        print(name)\n",
    "    return players\n",
    "\n",
    "\n",
    "\n",
    "def get_player_perf(DoB_min='1975-01-01',proxy=False):\n",
    "    '''\n",
    "    Use this only once per complete round and save into CSV as it takes a while to run\n",
    "    this function returns a dataframe of player performance history\n",
    "    Entire player history is returned\n",
    "    DoB_min is limiting factor to get only player born after the date - for performance reasons\n",
    "    change the default if you need to go more back into older players or in reverse\n",
    "    Pre-requisite: Players.csv file exists in the AFL directory\n",
    "    set proxy=True when on office LAN\n",
    "    \n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "    players = pd.read_csv(get_drive()+'Players.csv')\n",
    "    players =players[players['DoB']>DoB_min]\n",
    "\n",
    "    player_stats = pd.DataFrame(columns=['Url','Team','Year'])\n",
    "\n",
    "    for cur_url in players.Url:\n",
    "        print(cur_url)\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        found=False\n",
    "        dfs=[]\n",
    "        for table in soup.find_all('table'):\n",
    "            #t1=tables[7]\n",
    "            t=table.find('tbody')\n",
    "            res = []\n",
    "            row = []\n",
    "            rows = t.find_all('tr')\n",
    "            for tr in rows:\n",
    "                for td in tr.find_all('td'):\n",
    "                    row.append(td.text)\n",
    "                res.append(row)\n",
    "                row = []\n",
    "            df=pd.DataFrame(data=res)\n",
    "\n",
    "            if len(df.columns)==28: # found first game\n",
    "                    found = True\n",
    "            if found:\n",
    "                h=table.find('thead')\n",
    "                h1 = h.find('tr')\n",
    "                h2 = h1.find('th')\n",
    "                header =h2.text\n",
    "                team_year = header.split('-')\n",
    "                team = team_year[0].strip()\n",
    "                year = team_year[1].strip()\n",
    "                df['Url']=cur_url\n",
    "                df['Team']=team\n",
    "                df['Year']=year\n",
    "                player_stats = pd.concat([player_stats,df])\n",
    "    player_stats = player_stats.rename(columns={0:'GameNo',1:'Opponent',2:'Round',3:'Result',4:'Jersey',5:'KI',6:'MK',7:'HB',8:'DI',9:'GL',10:'BH',11:'HO',12:'TK',13:'RB',14:'IF',15:'CL',16:'CG',17:'FF',18:'FA',19:'BR',20:'CP',21:'UP',22:'CM',23:'MI',24:'1%',25:'BO',26:'GA',27:'%P'})\n",
    "    player_stats['Round']=[fix_round(x) for x in player_stats['Round']]\n",
    "\n",
    "\n",
    "    games_set = get_games(proxy=False)\n",
    "\n",
    "\n",
    "\n",
    "    #create one game row for each team\n",
    "    gamesH = games_set.drop(['AwayTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesA = games_set.drop(['HomeTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesH=gamesH.rename(columns={'HomeTeam':'Team'})\n",
    "    gamesA=gamesA.rename(columns={'AwayTeam':'Team'})\n",
    "    gamesAH=pd.concat([gamesH,gamesA])\n",
    "    gamesAH['Year'] = [str(x) for x in gamesAH['Year']]\n",
    "    # get date and game id for each player record\n",
    "    player_stats=pd.merge(player_stats,gamesAH,how='inner',on=['Team','Year','Round'])\n",
    "    player_stats=player_stats.drop_duplicates(subset=['Url','Year','Round'],keep='first')\n",
    "    \n",
    "    return player_stats\n",
    "\n",
    "def get_pastXthis_opponent(x,team,opponent,dt,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, opponent, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    #last 3 against this team\n",
    "    tp = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Opponent']==opponent) ]  # later row.Team\n",
    "    tp = tp.sort_values(by=['Date'],ascending=False)\n",
    "    tp = tp.head(x)\n",
    "    tp = tp.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "\n",
    "    tp_avg = tp.groupby(by='Team').aggregate('mean')\n",
    "    tp_avg.columns = [str(col) + '_lstXopp' for col in tp_avg.columns]\n",
    "    if tp_avg.shape[0]==0:\n",
    "        print('empty row generated for ', dt,' team:',team, ' vs.', opponent)\n",
    "    return tp_avg\n",
    "\n",
    "def get_pastXground(x,team,dt,venue,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date and venue of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    tp2 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Venue'] == venue)] \n",
    "    tp2 = tp2.sort_values(by=['Date'],ascending=False)\n",
    "    tp2 = tp2.head(x)\n",
    "    tp2 = tp2.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp2_avg = tp2.groupby(by='Team').aggregate('mean')\n",
    "    tp2_avg.columns = [str(col) + '_lstXgrd' for col in tp2_avg.columns]\n",
    "    if tp2_avg.shape[0]==0:\n",
    "        print('empty row generated for ',dt,' at ', venue,' team:',team)\n",
    "    return tp2_avg\n",
    "\n",
    "def get_pastX(x,team,dt,team_performaceDF,print_missing=False):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tp1 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt)] \n",
    "    tp1 = tp1.sort_values(by=['Date'],ascending=False)\n",
    "    tp1 = tp1.head(x)\n",
    "    tp1 = tp1.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp1_avg = tp1.groupby(by='Team').aggregate('mean')\n",
    "    tp1_avg.columns = [str(col) + '_lstX' for col in tp1_avg.columns]\n",
    "    if tp1_avg.shape[0]==0 and print_missing:\n",
    "        print('empty row generated for ', dt,' team:',team)\n",
    "    return tp1_avg\n",
    "\n",
    "\n",
    "\n",
    "#create functions to calculate adj.ladder points \n",
    "def adj_points_home(lst):\n",
    "    w1=5.0 # for winning against top4 team as of end of last season\n",
    "    w2=4.0 # for winning against top5-8 team as of end of last season\n",
    "    w3=3.0 # for winning against 9-13 team as of end of last season\n",
    "    w4=2.5 # for winning against 14-18 team as of end of last season\n",
    "    l1=0.5 # for a bottom team (>=12) losing against to top 4 team as of end of last season with close margin\n",
    "    l2=0.5 # for a bottom team (>=12) losing against to top 5-8 team as of end of last season with close margin\n",
    "\n",
    "    if lst['ResultWL'] >0.5:\n",
    "        if lst['PreseasonRankA']<=4:\n",
    "            return w1\n",
    "        elif lst['PreseasonRankA']<=8:\n",
    "            return w2\n",
    "        elif lst['PreseasonRankA']<=13:\n",
    "            return w3\n",
    "        else:\n",
    "            return w4   \n",
    "    else:\n",
    "        if lst['PreseasonRankH']>=12 and lst['PreseasonRankA']<=4 and lst['Result']>=0.42:\n",
    "            return l1\n",
    "        elif lst['PreseasonRankH']>=12 and lst['PreseasonRankA']<=8 and lst['Result']>=0.42:\n",
    "            return l2\n",
    "        else:\n",
    "            return 0\n",
    "def adj_points_away(lst):\n",
    "    w1=5.0 # for winning against top4 team as of end of last season\n",
    "    w2=4.0 # for winning against top5-8 team as of end of last season\n",
    "    w3=3.0 # for winning against 9-13 team as of end of last season\n",
    "    w4=2.5 # for winning against 14-18 team as of end of last season\n",
    "    l1=0.5 # for a bottom team (>=12) losing against to top 4 team as of end of last season with close margin\n",
    "    l2=0.5 # for a bottom team (>=12) losing against to top 5-8 team as of end of last season with close margin\n",
    "    if lst['ResultWL'] <0.5:\n",
    "        if lst['PreseasonRankH']<=4:\n",
    "            return w1\n",
    "        elif lst['PreseasonRankH']<=8:\n",
    "            return w2\n",
    "        elif lst['PreseasonRankH']<=13:\n",
    "            return w3\n",
    "        else:\n",
    "            return w4   \n",
    "    else:\n",
    "        if lst['PreseasonRankA']>=12 and lst['PreseasonRankH']<=4 and lst['Result']<=0.58:\n",
    "            return l1\n",
    "        elif lst['PreseasonRankA']>=12 and lst['PreseasonRankH']<=8 and lst['Result']<=0.58:\n",
    "            return l2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "# function to create a column with points for this team from either home or away column\n",
    "def adj_points_combo(lst):\n",
    "    if lst['HomeFlag'] ==1:\n",
    "        return lst['PointsHome']\n",
    "    else:\n",
    "        return lst['PointsAway']\n",
    "\n",
    "def get_pastXgames(x,team,dt,DF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date of current game, team stats dataframe to get games prior to this\n",
    "\n",
    "    '''\n",
    "    newDF = DF[(DF['Team']==team) & (DF['Date'] <dt)] \n",
    "    newDF = newDF.sort_values(by=['Date'],ascending=False)\n",
    "    newDF = newDF.head(x)\n",
    "    newDF = newDF.drop(['Round','GameID','Result','Date','Venue','H','A','ResultWL','PointsHome','PointsAway','PreseasonRankA','PreseasonRankH', 'HomeFlag','Year'],1)\n",
    "    newDF = newDF.groupby(by='Team',as_index=False).aggregate('sum')\n",
    "    if len(newDF)>0:\n",
    "        return newDF.iloc[0]['TeamPoints']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_game_base(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    This function returns does the following:\n",
    "    1. Applies adjusted ladder points\n",
    "    2. Create separate reacord for each team - home and away teams\n",
    "    \n",
    "    Output - 2 dataframes:\n",
    "    1. games_for_join - has more history beyond the train period (+ 3 seasons)\n",
    "    2. train_data - exact train period limited data\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    ladder = get_ladder(seas_from=season_from-3,seas_to=season_to,proxy=False)\n",
    "\n",
    "    # get latest ladder for each team for each season\n",
    "    ladder = ladder.sort_values(by=['Season','Team','Round'])\n",
    "    season_end = ladder.groupby(by=['Season','Team'],as_index=False).last()\n",
    "    season_end['Season']=[x+1 for x in season_end['Season']]  # enable a join from next seson\n",
    "    \n",
    "    games = get_games(proxy=False)\n",
    "\n",
    "    train_data = games[(games['Year']>=season_from-2) & (games['Year']<=season_to)]\n",
    "\n",
    "    # bring last year ladder at season end - Not including finals\n",
    "    games = pd.merge(games,season_end.drop(['Games','Percentage','Points','Round'],1),left_on=['HomeTeam','Year'], right_on=['Team','Season'],how='inner')\n",
    "    games = games.drop(['Season','Team'],1)\n",
    "    games = pd.merge(games,season_end.drop(['Games','Percentage','Points','Round'],1),left_on=['AwayTeam','Year'], right_on=['Team','Season'],how='inner')\n",
    "    games = games.drop(['Season','Team'],1)\n",
    "    games = games.rename(columns={\"PosOld_x\": \"PreseasonRankH\", \"PosOld_y\": \"PreseasonRankA\"})\n",
    "\n",
    "\n",
    "    #Final code to assign adjusted ladder points - best parameters are 5,4,3,2.5,0.5,0.5\n",
    "\n",
    "    #apply ladder points by rows of games dataframe\n",
    "    games['PointsHome'] = games.apply(adj_points_home, axis=1)\n",
    "    games['PointsAway'] = games.apply(adj_points_away, axis=1)\n",
    "\n",
    "    # create a table which makes 2 records out of 1 game for home and away team - this allows sequencing by team and look in the past\n",
    "    gm_H = games.copy()\n",
    "    gm_H['Team']=gm_H['HomeTeam']\n",
    "    gm_H['HomeFlag']=1\n",
    "    gm_H = gm_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    gm_A = games.copy()\n",
    "    gm_A['Team']=gm_A['AwayTeam']\n",
    "    gm_A['HomeFlag']=0\n",
    "    gm_A['ResultWL']=1-gm_A['ResultWL'] # reverse outcome\n",
    "    gm_A = gm_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_for_join = pd.concat([gm_H,gm_A])\n",
    "    del gm_H\n",
    "    del gm_A\n",
    "\n",
    "    games_for_join['TeamPoints'] = games_for_join.apply(adj_points_combo, axis=1)\n",
    "    return games_for_join,train_data\n",
    "\n",
    "def adj_ladder(train_data,games_for_join):\n",
    "    '''\n",
    "    This function iterates over train_data and \n",
    "    applies/calculates adjusted ladder\n",
    "    Second dataframe used is longer history version of\n",
    "    training_data\n",
    "    \n",
    "    '''\n",
    "    import pandas as pd \n",
    "    # iterate over training data\n",
    "    ladder_span = 21  # 21 proven to be the best performance\n",
    "    adj_ladder = pd.DataFrame()\n",
    "    for i,row in train_data.iterrows():\n",
    "        #gm=row['GameID']\n",
    "        tm = row['HomeTeam']\n",
    "        dt = row['Date']\n",
    "\n",
    "        new_row = pd.DataFrame(columns=['Date','HomeTeam','AdLadderHm','AdLadderAw'])\n",
    "        h= get_pastXgames(ladder_span,row.HomeTeam,row.Date,games_for_join)\n",
    "        a= get_pastXgames(ladder_span,row.AwayTeam,row.Date,games_for_join)\n",
    "        new_row.loc[0]=[dt,tm,h,a]\n",
    "        adj_ladder = pd.concat([ adj_ladder,new_row])    \n",
    "    return adj_ladder\n",
    "\n",
    "\n",
    "def rescale_stats(perf_data):\n",
    "    '''\n",
    "    This function rescales performance metrics\n",
    "    according to team sterangth difference\n",
    "    Scoring Metrics (Goals and behinds) are not adjusted\n",
    "    '''\n",
    "    # list of columns to scale is determined by subtraction of ones where no scaling is needed from total list of columns\n",
    "    # this allows new metrics to be added (unlikely)\n",
    "    column_list = perf_data.columns\n",
    "    column_list=column_list.drop(['Round', 'Opponent', 'Team', 'Year', 'Date', 'Venue', 'H', 'A', 'ResultWL',\n",
    "           'HomeFlag', 'AdjLadderDiff','GL','BH'])   #Goals and behinds are excluded as they make up the result\n",
    "    # scale factors\n",
    "    s1=1.3 #for more than 40 points\n",
    "    s2=1.1 #for 20-40 points\n",
    "    s3=1.05 #for 10-20 points\n",
    "\n",
    "    # no scale version: comment out when not in use !!!!!!!\n",
    "    #s1=1 #for more than 40 points\n",
    "    #s2=1 #for 20-40 points\n",
    "    #s3=1 #for 10-20 points\n",
    "\n",
    "    perf_data=perf_data.reset_index(drop=True)\n",
    "\n",
    "    for index, row in perf_data.iterrows():\n",
    "        row=row.copy()\n",
    "        ldr = row.AdjLadderDiff\n",
    "        if ldr <-40:\n",
    "            for column in column_list:\n",
    "                perf_data.loc[index, column] = row[column]*s1\n",
    "        elif ldr <-20:\n",
    "            for column in column_list:\n",
    "                perf_data.loc[index, column] = row[column]*s2\n",
    "        elif ldr <-10:\n",
    "            for column in column_list:\n",
    "                perf_data.loc[index, column] = row[column]*s3\n",
    "        elif ldr>40:\n",
    "            for column in column_list:\n",
    "                perf_data.loc[index, column] = row[column]/s1\n",
    "        elif ldr>20:\n",
    "            for column in column_list:\n",
    "                perf_data.loc[index, column] = row[column]/s2\n",
    "        elif ldr>10:\n",
    "            for column in column_list:\n",
    "                perf_data.loc[index, column] = row[column]/s3\n",
    "        else: # away team bump\n",
    "            if row.HomeFlag==0:\n",
    "                for column in column_list:\n",
    "                    perf_data.loc[index, column] = row[column]*s3\n",
    "        return perf_data\n",
    "\n",
    "\n",
    "def get_data(season_from,season_to,proxy=False,train_mode=True):\n",
    "    '''\n",
    "    This function creates a dataset with all necessary adjustments\n",
    "    the resulting set can be used for training or scoring\n",
    "    leave train_mode=True when creating training set\n",
    "    set train_mode=False when scoring/predicting\n",
    "    When scoring, you need to have a csv file in the folder\n",
    "    When scoring set season_from and season_to to the same season\n",
    "    containing Date,HomeTeam,AwayTeam,Venue (assuming Round is not used as variable !!!!!!!)\n",
    "    \n",
    "    '''\n",
    "    import pandas as pd\n",
    "\n",
    "    if not train_mode:\n",
    "        # use CSV\n",
    "        score_data = pd.read_csv('D:\\\\AFL\\\\ToScore.csv')\n",
    "\n",
    "        #clean names\n",
    "        score_data['HomeTeam'] = [fix_team_name(x) for x in score_data.HomeTeam]\n",
    "        score_data['AwayTeam'] = [fix_team_name(x) for x in score_data.AwayTeam]\n",
    "        score_data['Venue'] = [fix_venue(x) for x in score_data.Venue]\n",
    "        score_data['Year']=season_to\n",
    "        score_data['Date'] = pd.to_datetime(score_data['Date'])\n",
    "\n",
    "    games_for_join, train_data = get_game_base(season_from=season_from,season_to=season_to,proxy=False)\n",
    "    # at this point games_for_join has everything, and it is time to bring history - aka adjusted ladder\n",
    "\n",
    "    \n",
    "    \n",
    "    # bring adjusted ladder to main dataset\n",
    "    train_data=pd.merge(train_data,adj_ladder(train_data,games_for_join),how='inner',on=['Date','HomeTeam'])\n",
    "    train_data['AdjLadderDiff'] = train_data['AdLadderHm'] - train_data['AdLadderAw']\n",
    "\n",
    "    # get team performance to make adjustments on team strength\n",
    "    # relative version\n",
    "    team_perf = get_team_performance_hist_rel(season_from=season_from-2,season_to=season_to,proxy=False)\n",
    "    # absolute version:\n",
    "    #team_perf = get_team_performance_hist(season_from=season_from-2,season_to=season_to,proxy=False)\n",
    "\n",
    "\n",
    "    #bring adjusted ladder difference to use with metrics\n",
    "    #idea: if a team is playing gainst a weaker team their metrics should be scaled down\n",
    "\n",
    "\n",
    "    team_perfH = pd.merge(team_perf,train_data[['Date', 'HomeTeam','AdjLadderDiff']],\n",
    "                         left_on=['Date', 'Team'],right_on=['Date', 'HomeTeam'])\n",
    "    team_perfA = pd.merge(team_perf,train_data[['Date', 'AwayTeam','AdjLadderDiff']],\n",
    "                         left_on=['Date', 'Team'],right_on=['Date', 'AwayTeam'])\n",
    "\n",
    "    team_perfA['AdjLadderDiff'] = [-x for x in team_perfA['AdjLadderDiff']] #reverse for away team\n",
    "    team_perf1 = pd.concat([team_perfH,team_perfA],sort=False)\n",
    "    team_perf1 = team_perf1.drop(['HomeTeam','AwayTeam'],1)    \n",
    "\n",
    "    # now need to re-scale metrics according to team strength difference (except scoring ones)\n",
    "    team_perf1=rescale_stats(team_perf1)\n",
    "\n",
    "    #limit dataset to training period (was allowed earlier to grab adj ladder)\n",
    "    train_data = train_data[train_data['Year']>=season_from]\n",
    "\n",
    "    #switch starting point depending on mode\n",
    "    if train_mode:\n",
    "        data_to_use=train_data.copy()\n",
    "    else:\n",
    "        data_to_use=score_data.copy()\n",
    "\n",
    "    # this gets 2 df's for home and away team each for last X games against any oppponent\n",
    "    length=15 # how many past games to look at - 15 was obtained as the best option\n",
    "    hist_df_hm=pd.DataFrame()\n",
    "    hist_df_aw=pd.DataFrame()\n",
    "    for i, row in data_to_use.iterrows():\n",
    "            hist = get_pastX(dt=row.Date,x=length,team=row.HomeTeam,team_performaceDF=team_perf1)\n",
    "            hist['Team']=row.HomeTeam\n",
    "            hist['Date']=row.Date\n",
    "            hist['Opponent']=row.AwayTeam\n",
    "            hist_df_hm=pd.concat([hist_df_hm,hist])\n",
    "            hist = get_pastX(dt=row.Date,x=length,team=row.AwayTeam,team_performaceDF=team_perf1)\n",
    "            hist['Team']=row.AwayTeam\n",
    "            hist['Date']=row.Date\n",
    "            #hist['GameID']=row.GameID\n",
    "            hist_df_aw=pd.concat([hist_df_aw,hist])\n",
    "\n",
    "    hist_df_hm=hist_df_hm.reset_index(drop=True)\n",
    "    hist_df_aw=hist_df_aw.reset_index(drop=True)\n",
    "\n",
    "    #columns ignored from get_team_performance function - the absolute ones in this case - keep only differences\n",
    "    remove_list=['KIt', 'MKt', 'HBt', 'DIt', 'GLt','BHt', 'HOt', 'TKt', 'RBt', 'IFt','CLt',\n",
    "                 'CGt', 'FFt', 'FAt', 'BRt','CPt', 'UPt','CMt', 'MIt', '1%t',\n",
    "                 'BOt', 'GAt','SCt','KIo', 'MKo', 'HBo', 'DIo', 'GLo','BHo',\n",
    "                 'HOo', 'TKo', 'RBo', 'IFo','CLo', 'CGo', 'FFo', 'FAo', 'BRo',\n",
    "                 'CPo', 'UPo', 'CMo', 'MIo', '1%o','BOo', 'GAo','SCo']\n",
    "\n",
    "    #remove opposition metrics\n",
    "    hist_df_hm = hist_df_hm.drop([x+'_lstX' for x in remove_list],1)\n",
    "    hist_df_aw = hist_df_aw.drop([x+'_lstX' for x in remove_list],1)\n",
    "\n",
    "    # tweak to resolve a mistery of AdjLadderDiff disapperiang somethimes\n",
    "    if 'AdjLadderDiff_lstX' in hist_df_hm.columns:\n",
    "        hist_df_hm=hist_df_hm.drop(['AdjLadderDiff_lstX'],1)\n",
    "    if 'AdjLadderDiff_lstX' in hist_df_aw.columns:\n",
    "        hist_df_aw=hist_df_aw.drop(['AdjLadderDiff_lstX'],1)\n",
    "    \n",
    "    # now past metrics averages need to be brought together for each geame to calculate a difference\n",
    "    hist_df = pd.merge(hist_df_hm.drop(['H_lstX', 'A_lstX','ResultWL_lstX'],1),\n",
    "                       hist_df_aw.drop(['H_lstX', 'A_lstX','ResultWL_lstX'],1),\n",
    "                       how='inner',left_on=['Opponent','Date'], right_on=['Team','Date'])\n",
    "\n",
    "    hist_df = hist_df.drop(['Opponent','Team_y'],1)\n",
    "    hist_df = hist_df.rename(columns={'Team_x':'Team'})\n",
    "\n",
    "    #prepare to calculate differences\n",
    "    column_list =['KI_lstX', 'MK_lstX', 'HB_lstX', 'DI_lstX', 'GL_lstX',\n",
    "           'BH_lstX', 'HO_lstX', 'TK_lstX', 'RB_lstX', 'IF_lstX',\n",
    "           'CL_lstX', 'CG_lstX', 'FF_lstX', 'FA_lstX', 'BR_lstX',\n",
    "           'CP_lstX', 'UP_lstX', 'CM_lstX', 'MI_lstX', '1%_lstX',\n",
    "           'BO_lstX', 'GA_lstX','SC_lstX']\n",
    "    #calculate differences and drop original columns\n",
    "    for col in column_list:\n",
    "        hist_df[col] = [a-b for a,b in zip(hist_df[col+'_x'],hist_df[col+'_y'])]\n",
    "        hist_df = hist_df.drop(col+'_x',1)\n",
    "        hist_df = hist_df.drop(col+'_y',1)\n",
    "\n",
    "    # add to training set - strength adjusted past stats\n",
    "    train_data1= pd.merge(data_to_use,hist_df,left_on=['HomeTeam','Date'],right_on=['Team','Date'])\n",
    "    train_data1 = train_data1.drop(['Team'],1)\n",
    "    # this gets 2 df's for home and away team each for last X games at this GROUND\n",
    "    length=10 # how many past games to look at \n",
    "    hist_df_hm=pd.DataFrame()\n",
    "    hist_df_aw=pd.DataFrame()\n",
    "    for i, row in data_to_use.iterrows():\n",
    "            hist = get_pastXground(dt=row.Date,x=length,team=row.HomeTeam,venue=row.Venue,team_performaceDF=team_perf1)\n",
    "            hist['Team']=row.HomeTeam\n",
    "            hist['Date']=row.Date\n",
    "            hist['Opponent']=row.AwayTeam\n",
    "            #hist['GameID']=row.GameID\n",
    "            hist_df_hm=pd.concat([hist_df_hm,hist])\n",
    "            hist = get_pastXground(dt=row.Date,x=length,team=row.AwayTeam,venue=row.Venue,team_performaceDF=team_perf1)\n",
    "            hist['Team']=row.AwayTeam\n",
    "            hist['Date']=row.Date\n",
    "            #hist['GameID']=row.GameID\n",
    "            hist_df_aw=pd.concat([hist_df_aw,hist])\n",
    "\n",
    "    hist_df_hm=hist_df_hm.reset_index(drop=True)\n",
    "    hist_df_aw=hist_df_aw.reset_index(drop=True)\n",
    "\n",
    "    #remove opposition metrics\n",
    "    hist_df_hm = hist_df_hm.drop([x+'_lstXgrd' for x in remove_list],1)\n",
    "    hist_df_aw = hist_df_aw.drop([x+'_lstXgrd' for x in remove_list],1)\n",
    "\n",
    "    # tweak to resolve a mistery of AdjLadderDiff disapperiang somethimes\n",
    "    if 'AdjLadderDiff_lstXgrd' in hist_df_hm.columns:\n",
    "        hist_df_hm=hist_df_hm.drop(['AdjLadderDiff_lstXgrd'],1)\n",
    "    if 'AdjLadderDiff_lstXgrd' in hist_df_aw.columns:\n",
    "        hist_df_aw=hist_df_aw.drop(['AdjLadderDiff_lstXgrd'],1)\n",
    "   \n",
    "    \n",
    "    # now past metrics averages need to be brought together for each geame to calculate a difference\n",
    "    hist_df = pd.merge(hist_df_hm.drop(['H_lstXgrd', 'A_lstXgrd','ResultWL_lstXgrd'],1),\n",
    "                       hist_df_aw.drop(['H_lstXgrd', 'A_lstXgrd','ResultWL_lstXgrd'],1),\n",
    "                       how='inner',left_on=['Opponent','Date'], right_on=['Team','Date'])\n",
    "    hist_df = hist_df.drop(['Opponent','Team_y'],1)\n",
    "    hist_df = hist_df.rename(columns={'Team_x':'Team'})\n",
    "\n",
    "    #prepare to calculate differences\n",
    "    column_list =['KI_lstXgrd', 'MK_lstXgrd', 'HB_lstXgrd', 'DI_lstXgrd', 'GL_lstXgrd',\n",
    "           'BH_lstXgrd', 'HO_lstXgrd', 'TK_lstXgrd', 'RB_lstXgrd', 'IF_lstXgrd',\n",
    "           'CL_lstXgrd', 'CG_lstXgrd', 'FF_lstXgrd', 'FA_lstXgrd', 'BR_lstXgrd',\n",
    "           'CP_lstXgrd', 'UP_lstXgrd', 'CM_lstXgrd', 'MI_lstXgrd', '1%_lstXgrd',\n",
    "           'BO_lstXgrd', 'GA_lstXgrd','SC_lstXgrd']\n",
    "    #calculate differences and drop original columns\n",
    "    for col in column_list:\n",
    "        hist_df[col] = [a-b for a,b in zip(hist_df[col+'_x'],hist_df[col+'_y'])]\n",
    "        hist_df = hist_df.drop(col+'_x',1)\n",
    "        hist_df = hist_df.drop(col+'_y',1)\n",
    "\n",
    "    # add to training set - strength adjusted past stats\n",
    "    train_data2= pd.merge(train_data1,hist_df,how='left',left_on=['HomeTeam','Date'],right_on=['Team','Date'])\n",
    "    train_data2 = train_data2.drop(['Team'],1)\n",
    "    # This opponent\n",
    "    # this gets 2 df's for home and away team each for last X games with this opponent\n",
    "    length=5 # how many past games to look at hist_df_hm=pd.DataFrame()\n",
    "    hist_df_hm=pd.DataFrame()\n",
    "    hist_df_aw=pd.DataFrame()\n",
    "    for i, row in data_to_use.iterrows():\n",
    "            hist = get_pastXthis_opponent(dt=row.Date,x=length,team=row.HomeTeam,opponent=row.AwayTeam,team_performaceDF=team_perf1)\n",
    "            hist['Team']=row.HomeTeam\n",
    "            hist['Date']=row.Date\n",
    "            hist['Opponent']=row.AwayTeam\n",
    "            #hist['GameID']=row.GameID\n",
    "            hist_df_hm=pd.concat([hist_df_hm,hist])\n",
    "            hist = get_pastXthis_opponent(dt=row.Date,x=length,team=row.AwayTeam,opponent=row.HomeTeam,team_performaceDF=team_perf1)\n",
    "            hist['Team']=row.AwayTeam\n",
    "            hist['Date']=row.Date\n",
    "            #hist['GameID']=row.GameID\n",
    "            hist_df_aw=pd.concat([hist_df_aw,hist])\n",
    "\n",
    "    hist_df_hm=hist_df_hm.reset_index(drop=True)\n",
    "    hist_df_aw=hist_df_aw.reset_index(drop=True)\n",
    "\n",
    "    #remove opposition metrics\n",
    "    hist_df_hm = hist_df_hm.drop([x+'_lstXopp' for x in remove_list],1)\n",
    "    hist_df_aw = hist_df_aw.drop([x+'_lstXopp' for x in remove_list],1)\n",
    "\n",
    "    # tweak to resolve a mistery of AdjLadderDiff disapperiang somethimes\n",
    "    if 'AdjLadderDiff_lstXopp' in hist_df_hm.columns:\n",
    "        hist_df_hm=hist_df_hm.drop(['AdjLadderDiff_lstXopp'],1)\n",
    "    if 'AdjLadderDiff_lstXopp' in hist_df_aw.columns:\n",
    "        hist_df_aw=hist_df_aw.drop(['AdjLadderDiff_lstXopp'],1)\n",
    "   \n",
    "    \n",
    "    # now past metrics averages need to be brought together for each geame to calculate a difference\n",
    "    hist_df = pd.merge(hist_df_hm.drop(['H_lstXopp', 'A_lstXopp', 'ResultWL_lstXopp'],1),\n",
    "                       hist_df_aw.drop(['H_lstXopp', 'A_lstXopp', 'ResultWL_lstXopp'],1),\n",
    "                       how='inner',left_on=['Opponent','Date'], right_on=['Team','Date'])\n",
    "    hist_df = hist_df.drop(['Opponent','Team_y'],1)\n",
    "    hist_df = hist_df.rename(columns={'Team_x':'Team'})\n",
    "    #prepare to calculate differences\n",
    "    column_list =['KI_lstXopp', 'MK_lstXopp', 'HB_lstXopp', 'DI_lstXopp', 'GL_lstXopp',\n",
    "           'BH_lstXopp', 'HO_lstXopp', 'TK_lstXopp', 'RB_lstXopp', 'IF_lstXopp',\n",
    "           'CL_lstXopp', 'CG_lstXopp', 'FF_lstXopp', 'FA_lstXopp', 'BR_lstXopp',\n",
    "           'CP_lstXopp', 'UP_lstXopp', 'CM_lstXopp', 'MI_lstXopp', '1%_lstXopp',\n",
    "           'BO_lstXopp', 'GA_lstXopp','SC_lstXopp']\n",
    "    #calculate differences and drop original columns\n",
    "    for col in column_list:\n",
    "        hist_df[col] = [a-b for a,b in zip(hist_df[col+'_x'],hist_df[col+'_y'])]\n",
    "        hist_df = hist_df.drop(col+'_x',1)\n",
    "        hist_df = hist_df.drop(col+'_y',1)\n",
    "\n",
    "    # add to training set - strength adjusted past stats\n",
    "    train_data3= train_data2.merge(hist_df,how='left',left_on=['HomeTeam','Date'],right_on=['Team','Date'])\n",
    "    train_data3 = train_data3.drop(['Team'],1)\n",
    "    # now change na to 0.0\n",
    "    train_data3 = train_data3.fillna(0)\n",
    "\n",
    "    return train_data3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
