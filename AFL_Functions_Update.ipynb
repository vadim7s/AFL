{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original as of 28 Aug 2018\n",
    "\n",
    "def get_drive():\n",
    "    '''\n",
    "    this is to automate switching between home PC and laptop\n",
    "    it returns J:\\\\AFL\\\\ or D:\\\\AFL\\\\ depending if D:\\ is available\n",
    "    \n",
    "    No parameters required\n",
    "    '''\n",
    "    \n",
    "    import win32api\n",
    "    drives = win32api.GetLogicalDriveStrings()\n",
    "    drives = drives.split('\\000')[:-1]\n",
    "    if 'D:\\\\' in drives:\n",
    "        drive = 'D:\\\\AFL\\\\'\n",
    "    else:\n",
    "        drive = 'J:\\\\AFL\\\\'\n",
    "    return drive\n",
    "\n",
    "\n",
    "def get_proxy(proxy):\n",
    "        if proxy:\n",
    "            from os import environ\n",
    "            #pwd = input('Please enter your LAN Pwd')\n",
    "            environ[\"http_proxy\"]=\"http://c819325:sWeater78-@http-gw.tcif.telstra.com.au:8080\"\n",
    "            environ[\"https_proxy\"]=environ.get(\"http_proxy\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fix_round(round_in):\n",
    "    '''\n",
    "    this function convert Round values into sequential integers\n",
    "    '''\n",
    "    if round_in=='QF':\n",
    "        rnd='25'\n",
    "    elif round_in=='EF':\n",
    "        rnd='26'\n",
    "    elif round_in=='SF':\n",
    "        rnd='27'\n",
    "    elif round_in=='PF':\n",
    "        rnd='28'\n",
    "    elif round_in=='GF':\n",
    "        rnd='29'\n",
    "    elif round_in[0]=='R':\n",
    "        rnd=round_in[1:]\n",
    "    else:\n",
    "        rnd=round_in\n",
    "    return int(rnd)\n",
    "\n",
    "def fix_team_name(name):\n",
    "    '''\n",
    "    this function converts any team name to a consistent\n",
    "    set of  names which are usable for joins\n",
    "    '''\n",
    "    if 'Crows' in name:\n",
    "        team_name='Adelaide'\n",
    "    elif name.strip()=='Adelaide Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='AD':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='BL':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='Lions':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='CA':\n",
    "        team_name='Carlton'\n",
    "    elif name=='Blues':\n",
    "        team_name='Carlton'\n",
    "    elif name=='CW':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='Magpies':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='ES':\n",
    "        team_name='Essendon'\n",
    "    elif name=='Bombers':\n",
    "        team_name='Essendon'\n",
    "    elif name=='FR':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='Dockers':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='GE':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Geelong Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='GC':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Gold Coast Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='GWS Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GWS':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW Sydney':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='HW':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='Hawks':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='ME':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Demons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Deamons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='KA':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='NM':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='Kangaroos':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='PA':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='Power':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='RI':\n",
    "        team_name='Richmond'\n",
    "    elif name=='Tigers':\n",
    "        team_name='Richmond'\n",
    "    elif name=='SK':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='Saints':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='SY':\n",
    "        team_name='Sydney'\n",
    "    elif 'Swans' in name:\n",
    "        team_name='Sydney'\n",
    "    elif name=='WC':\n",
    "        team_name='West Coast'\n",
    "    elif name=='West Coast Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='WB':\n",
    "        team_name='Western Bulldogs'\n",
    "    elif name=='Bulldogs':\n",
    "        team_name='Western Bulldogs'\n",
    "    else:\n",
    "        team_name=name\n",
    "    return team_name\n",
    "\n",
    "def fix_venue(name):\n",
    "    if name=='AAMI':\n",
    "        ground = 'Olympic Park'\n",
    "    elif name=='ANZ':\n",
    "        ground = 'Stadium Australia'\n",
    "    elif name=='Adelaide':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Aurora':\n",
    "        ground = 'York Park'\n",
    "    elif name=='Blacktown':\n",
    "        ground='Blacktown'\n",
    "    elif name=='Blundstone Arena':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name=='Blundstone':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name==\"Cazaly's\":\n",
    "        ground= \"Cazaly's Stadium\"\n",
    "    elif name=='Domain':\n",
    "        ground='Subiaco'\n",
    "    elif name=='Etihad Stadium':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='Etihad':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='GMHBA Stadium':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='GMHBA':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='Gabba':\n",
    "        ground = 'Gabba'\n",
    "    elif name=='Jiangwan':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='Jiangwan Stadium, China':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='M.C.G':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='MCG':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='Mars Stadium, Ballarat':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Mars':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Metricon Stadium':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Metricon':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Perth':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='SCG':\n",
    "        ground='S.C.G.'\n",
    "    elif name=='Spotless Stadium':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='Spotless':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='UNSW Canberra Oval':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='StarTrack':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='Treager Park, Alice Springs':\n",
    "        ground='Traeger Park'\n",
    "    elif name=='TIO Stadium, Darwin':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='TIO':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='University of Tasmania Stadium':\n",
    "        ground='York Park'\n",
    "    elif name=='UTAS':\n",
    "        ground='York Park'\n",
    "    elif name=='Westpac':\n",
    "        ground='Wellington'\n",
    "    else:\n",
    "        ground=name\n",
    "    return ground\n",
    "\n",
    "def get_ladder(seas_from,seas_to,proxy=False):\n",
    "    '''\n",
    "    this is just to get the ladder history\n",
    "\n",
    "    Input required - update season from and to in the function call at the bottom\n",
    "    this function returns a dataframe for AFL ladder position history\n",
    "    seas_from - season to start from\n",
    "    seas_to - season end - inclusive\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    ladder = pd.DataFrame(columns=['Team','Games','Points','Percentage','Round','Position','Season'])\n",
    "    for season in range(seas_from-1,seas_to+1): \n",
    "        cur_url = 'http://afltables.com/afl/seas/'+str(season)+'.html'\n",
    "        dfs = pd.read_html(cur_url)\n",
    "\n",
    "        for df in dfs:\n",
    "            if df.columns.nlevels>1:\n",
    "                break\n",
    "            if len(df)>1 and 'Ladder' in df[0][0] and 'Rd' in df[0][0] and len(df.columns)>2:\n",
    "                rnd = df[0][0][3:5]\n",
    "                ldr = df.copy() \n",
    "                ldr = ldr.drop(0,0)\n",
    "                ldr.columns = ['Team','Games','Points','Percentage']\n",
    "                ldr['Round']=rnd\n",
    "                ldr['Position']=ldr.index\n",
    "                ldr['Season']=season\n",
    "                ladder = pd.concat([ladder,ldr])\n",
    "    ladder['Team'] = [fix_team_name(x) for x in ladder['Team']]\n",
    "    \n",
    "    # repeat last round for last and until 29\n",
    "    ladder_f = ladder.copy()\n",
    "    ladder_f.drop_duplicates(subset=['Team','Season'], keep='last', inplace=True)\n",
    "\n",
    "    # get last round for each season\n",
    "    ladder_y = ladder_f.copy()\n",
    "    ladder_y.drop_duplicates(subset=['Season'], keep='last', inplace=True)\n",
    "    ladder_y=ladder_y.drop(['Team','Games','Points','Percentage','Position'],1)\n",
    "    rnd=[]\n",
    "    seas=[]\n",
    "    for index, row in ladder_y.iterrows():\n",
    "        st = int(row.Round)\n",
    "        #print(type(st))\n",
    "        for i in range(st+1,30):\n",
    "            rnd.append(i)\n",
    "            seas.append(row.Season)\n",
    "    ldr = pd.DataFrame()\n",
    "    ldr['Season'] = seas\n",
    "    ldr['Round'] = rnd\n",
    "    #ldr = pd.merge(ladder_f.drop(['Round'],1),ldr,how='inner',on=['Season'])\n",
    "    ladder = pd.concat([ladder,ldr])\n",
    "    ladder = ladder.sort_values(by=['Team','Season'],axis=0)\n",
    "    ladder['PosOld']=ladder.Position.shift(1)  #previous ladder position taken\n",
    "    ladder = ladder.drop(['Position'],1)\n",
    "    ladder['Round']= [int(x) for x in ladder['Round']]\n",
    "    ladder=ladder.dropna(axis=0)\n",
    "    ladder['PosOld']= [int(x) for x in ladder['PosOld']]  \n",
    "    return ladder\n",
    "\n",
    "def get_fixture(proxy=False):\n",
    "    '''\n",
    "    this is to get AFL fixture from theroar.com.au\n",
    "    set proxy=True if you are on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    url='https://www.theroar.com.au/afl-draw/'\n",
    "    sauce = urllib.request.urlopen(url)\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "    fixture = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "\n",
    "    for x in soup.find_all('tbody'):\n",
    "        rnd_counter = 0\n",
    "\n",
    "        for y in x.find_all('tr'):\n",
    "\n",
    "            if y.find_all('strong'):\n",
    "                rnd_counter +=1\n",
    "\n",
    "            else:\n",
    "                if not y.find_all('h3') and 'Byes' not in y.text and 'TBC' not in y.text:\n",
    "                    dt,teams,venue,tm = y.text.strip().split('\\n')\n",
    "                    if dt == 'Sar Apr 21':\n",
    "                        dt = 'Sat Apr 21'\n",
    "\n",
    "                    dt = parser.parse(dt)\n",
    "                    if teams == 'North Melbourne Carlton':\n",
    "                            hm_team = 'North Melbourne'\n",
    "                            aw_team = 'Carlton'\n",
    "                    else:\n",
    "                        hm_team, aw_team = teams.split(' vs ')\n",
    "\n",
    "                    #print(rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue))\n",
    "                    df = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "                    df.loc[0]=[rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue)]\n",
    "                    fixture = pd.concat([fixture,df])\n",
    "    return fixture\n",
    "\n",
    "def get_odds_history(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this function gets odds history from footywire.com\n",
    "    min season from is 2010- so it will make the min date 2010 if less than that\n",
    "    set proxy=True if on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    if season_from<2010:\n",
    "        season_from=2010\n",
    "    odds_history=pd.DataFrame()\n",
    "    for season in range(season_from,season_to+1):\n",
    "        print('Getting odds for season',season,'...')\n",
    "        sauce = urllib.request.urlopen('https://www.footywire.com/afl/footy/afl_betting?year='+str(season))\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "\n",
    "        for x in soup.find_all('div',class_ ='datadiv'):\n",
    "            date=[]\n",
    "            venue=[]\n",
    "            team_HM=[]\n",
    "            odds_HM=[]\n",
    "            team_AW=[]\n",
    "            odds_AW=[]\n",
    "            counter =0\n",
    "\n",
    "            home_team_cursor = True\n",
    "            for y in x.find_all('tr'):\n",
    "\n",
    "                for z in y.find_all('td',class_='data'):\n",
    "                    counter = counter+1\n",
    "                    if z.has_attr('height'):\n",
    "                        counter = 0\n",
    "                        #print('new game ',z.text)\n",
    "                        date.append(z.text)\n",
    "                    elif z.has_attr('rowspan'):\n",
    "                        #print('venue ', z.text)\n",
    "                        venue.append(z.text)\n",
    "                    elif not z.has_attr('align'):\n",
    "                        if counter == 2:\n",
    "                            #print('Home team: ', z.text)\n",
    "                            team_HM.append(z.text)\n",
    "                            home_team_cursor=True    \n",
    "                        else:\n",
    "                            #print('Away team: ', z.text)\n",
    "                            counter = 0\n",
    "                            team_AW.append(z.text)\n",
    "                            home_team_cursor=False\n",
    "                    elif counter ==3 and not home_team_cursor:\n",
    "                        #print('away team odds: ',z.text)\n",
    "                        odds_AW.append(z.text)\n",
    "                    elif counter==5 and home_team_cursor:\n",
    "                        #print('home team odds: ',z.text)\n",
    "                        odds_HM.append(z.text)\n",
    "        odds = pd.DataFrame()\n",
    "        odds['Date']=[parser.parse(x,dayfirst=True) for x in date]\n",
    "        odds['Venue']=[fix_venue(x) for x in venue]\n",
    "        odds['HomeTeam']=[fix_team_name(x) for x in team_HM]\n",
    "        odds['OddsHome']=[x for x in odds_HM]\n",
    "        odds['AwayTeam']=[fix_team_name(x) for x in team_AW]\n",
    "        odds['OddsAway']=[x for x in odds_AW]\n",
    "        odds_history = pd.concat([odds_history,odds])  \n",
    "    odds = odds.drop_duplicates(subset=['Date','HomeTeam','AwayTeam'],keep='last')\n",
    "    return odds_history\n",
    "\n",
    "def get_games(proxy=False):\n",
    "    \n",
    "    '''\n",
    "    this function gets past games history\n",
    "    and gets attendance where it is available\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "        \n",
    "    col_specification =[(7, 15), (16, 33), (51, 68), (87, 116),(117,128)]\n",
    "    attend = pd.read_fwf('https://afltables.com/afl/stats/biglists/bg7.txt', \n",
    "                         colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    attend.columns = ['Attendance', 'HomeTeam', 'AwayTeam', 'Venue','Date']\n",
    "    attend['Date']  = pd.to_datetime(attend['Date'],dayfirst=True)\n",
    "    attend['Attendance'] = attend.Attendance.str.replace(r\"[\\*]\",'')\n",
    "    col_specification =[(0, 5), (7, 18), (24, 27), (29, 46),(47,63), (64,81),(82,99),(100,117)]\n",
    "    games= pd.read_fwf('http://afltables.com/afl/stats/biglists/bg3.txt', \n",
    "                       colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    games.columns = ['GameID', 'Date', 'Round', 'HomeTeam', 'ScoreHm','AwayTeam','ScoreAw','Venue']\n",
    "    games = pd.merge(games,attend,how='left',on=['Venue','Date','HomeTeam','AwayTeam'])\n",
    "\n",
    "    #fix rounds in games\n",
    "    games['Round'] = [fix_round(x) for x in games['Round']]\n",
    "    \n",
    "    games['Year']=games['Date'].map(lambda x: x.year)\n",
    "\n",
    "    #fix North Melb in games\n",
    "    games['HomeTeam'] = [fix_team_name(x) for x in games['HomeTeam']]\n",
    "    games['AwayTeam'] = [fix_team_name(x) for x in games['AwayTeam']]\n",
    "\n",
    "    # get result\n",
    "    games['H'] = [int(x.split('.')[2]) for x in games['ScoreHm']]\n",
    "    games['A'] = [int(x.split('.')[2]) for x in games['ScoreAw']]\n",
    "    games = games.drop(['ScoreHm','ScoreAw'],1)\n",
    "    games['Result'] = [round((x[0] /(x[0] +x[1])),3) for x in zip(games['H'],games['A'])]\n",
    "    #games = games.drop(['H','A'],1)\n",
    "    games['ResultWL'] = [1 if x>=0.5 else 0 for x in games.Result]\n",
    "    return games\n",
    "\n",
    "\n",
    "def get_team_performance_hist(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this is to get the team performance history\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BH'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CG'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BR'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CM'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    return team_performace\n",
    "\n",
    "\n",
    "def get_lineup(year,rnd,proxy=False):\n",
    "    '''\n",
    "    returns all available line-up for given year\n",
    "    year - current year you need to specify\n",
    "    rnd - current round where line-up has been released (could be improved into auto later)\n",
    "    proxy = True if on LAN\n",
    "    Pre-requisites: \n",
    "     1.TeamRef.csv - file which maps team names to AFL line-up abbreviated names\n",
    "     2.Fixture function is used\n",
    "\n",
    "    '''    \n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "\n",
    "    fixture = get_fixture(proxy)\n",
    "    fixture = fixture[fixture.Round==rnd]  #this limits to current round only\n",
    "    teams = pd.read_csv(get_drive()+'TeamRef.csv')\n",
    "\n",
    "    this_1 = pd.merge(fixture,teams,how=\"inner\",left_on=['HomeTeam'],right_on=['Team'])\n",
    "    this_2 = pd.merge(this_1,teams,how=\"inner\",left_on=['AwayTeam'],right_on=['Team'])\n",
    "    rounds = this_2.drop(['Team_x','Team_y'],1)\n",
    "    rounds['Game'] = [x + '-v-' +y for x,y in zip(rounds.AFL_Team_Nm_x,rounds.AFL_Team_Nm_y)]\n",
    "    rounds = rounds.drop(['AFL_Team_Nm_x','AFL_Team_Nm_y'],1)\n",
    "\n",
    "\n",
    "    # now get available line-up for player ref working\n",
    "\n",
    "    #rounds = rounds[rounds.Round<=max_round]    # needs updating, just available\n",
    "\n",
    "    lineup=pd.DataFrame()\n",
    "    for gm,rnd in zip(rounds['Game'],rounds['Round']):\n",
    "        url='http://www.afl.com.au/match-centre/'+str(year)+'/'+str(rnd)+'/'+gm\n",
    "        \n",
    "        sauce = urllib.request.urlopen(url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        plrs=[]\n",
    "        for x in soup.find_all('div',class_ ='lineup'):\n",
    "            for t in x.find_all('div',class_ ='text-inouts'):\n",
    "                team=''\n",
    "                for tm in t.find_all('h4'):\n",
    "                    team=tm.text\n",
    "\n",
    "                for p in t.find_all('div',class_ ='posGroup'):\n",
    "                    position=''\n",
    "                    for pos in p.find_all('p',class_ ='pos'):\n",
    "                        position =pos.text.strip()\n",
    "                    for player in p.find_all('li'):\n",
    "                        if position in ['B','HB','C','HF','F','Fol','I/C']:\n",
    "                            tms.append(team)\n",
    "                            plrs.append(player.text.strip().strip(','))\n",
    "\n",
    "        d = pd.DataFrame()\n",
    "        d['Team'] = tms\n",
    "        d['Player'] = plrs\n",
    "        lineup=pd.concat([lineup,d])\n",
    "    lineup['Team']=[fix_team_name(x) for x in lineup['Team']]\n",
    "    return lineup\n",
    "\n",
    "def get_player_base(proxy):\n",
    "    '''\n",
    "    !!! run only when need to update for new players !!!\n",
    "    returns a dataframe of player base table to enable to skip older players\n",
    "    e.g. players[players.DoB>'1975-01-01']  this gives 2.5k player subset\n",
    "    \n",
    "    typical use - to create Players.csv file in AFL directory - !!! pre-requisite for getting player performance\n",
    "\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    players = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days'])\n",
    "\n",
    "    # get player urls\n",
    "    links = []\n",
    "    for c in ascii_uppercase :\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/players'+c+'_idx.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "        for url in soup.find_all('a',href=True):\n",
    "            links.append('https://afltables.com/afl/stats/'+url['href'])\n",
    "    # now remove non-player links - ones that contain 'idx'\n",
    "    links = [item for item in links if 'players' in item and 'idx' not in item and 'afl_index' not in item]        \n",
    "\n",
    "    for cur_url in links:\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        #Name\n",
    "        x = soup.find_all('h1')\n",
    "        name = x[0].text\n",
    "\n",
    "        #DoB\n",
    "        found_dob=False\n",
    "\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Born:':\n",
    "                dob = x.next_sibling\n",
    "                found_dob=True\n",
    "                break\n",
    "        if found_dob:\n",
    "            dob=parser.parse(dob[0:11],dayfirst=True)\n",
    "        else:\n",
    "            dob = datetime.datetime(1900, 1, 1, 0, 0)\n",
    "\n",
    "        #Debut\n",
    "        found_debut = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Debut:':\n",
    "                debut = x.next_sibling\n",
    "                found_debut=True\n",
    "                break\n",
    "        if found_debut:\n",
    "            debut =debut.split()\n",
    "            debut1 = ''.join(c for c in debut[0] if c.isdigit())\n",
    "            if len(debut)>1:\n",
    "                debut2 = ''.join(c for c in debut[1] if c.isdigit())\n",
    "                debut = int(debut1)+int(debut2)/365\n",
    "            else:\n",
    "                debut = int(debut1)\n",
    "        else:\n",
    "            debut = 100\n",
    "        #age last played\n",
    "        found_last = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Last:':\n",
    "                age_last = x.next_sibling\n",
    "                found_last=True\n",
    "                break\n",
    "        if found_last:\n",
    "            age_last =age_last.split()\n",
    "            a1 = ''.join(c for c in age_last[0] if c.isdigit())\n",
    "            if len(age_last)>1:\n",
    "                a2 = ''.join(c for c in age_last[1] if c.isdigit())\n",
    "                age_last = int(a1)*365.25+int(a2) #in days\n",
    "            else:\n",
    "                age_last = int(a1)*365.25\n",
    "        else:\n",
    "            age_last = 40*365.25\n",
    "        today = datetime.datetime.today()\n",
    "        last_played_date = dob + datetime.timedelta(days=age_last)\n",
    "        since_last_game=today-last_played_date\n",
    "        df = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days','Last_Played_Date'])\n",
    "        df.loc[0]=[name,dob,cur_url,debut,age_last,last_played_date]\n",
    "        players = pd.concat([players,df])\n",
    "        print(name)\n",
    "    return players\n",
    "\n",
    "\n",
    "\n",
    "def get_player_perf(DoB_min='1975-01-01',proxy=False):\n",
    "    '''\n",
    "    Use this only once per complete round and save into CSV as it takes a while to run\n",
    "    this function returns a dataframe of player performance history\n",
    "    Entire player history is returned\n",
    "    DoB_min is limiting factor to get only player born after the date - for performance reasons\n",
    "    change the default if you need to go more back into older players or in reverse\n",
    "    Pre-requisite: Players.csv file exists in the AFL directory\n",
    "    set proxy=True when on office LAN\n",
    "    \n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "    players = pd.read_csv(get_drive()+'Players.csv')\n",
    "    players =players[players['DoB']>DoB_min]\n",
    "\n",
    "    player_stats = pd.DataFrame(columns=['Url','Team','Year'])\n",
    "\n",
    "    for cur_url in players.Url:\n",
    "        print(cur_url)\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        found=False\n",
    "        dfs=[]\n",
    "        for table in soup.find_all('table'):\n",
    "            #t1=tables[7]\n",
    "            t=table.find('tbody')\n",
    "            res = []\n",
    "            row = []\n",
    "            rows = t.find_all('tr')\n",
    "            for tr in rows:\n",
    "                for td in tr.find_all('td'):\n",
    "                    row.append(td.text)\n",
    "                res.append(row)\n",
    "                row = []\n",
    "            df=pd.DataFrame(data=res)\n",
    "\n",
    "            if len(df.columns)==28: # found first game\n",
    "                    found = True\n",
    "            if found:\n",
    "                h=table.find('thead')\n",
    "                h1 = h.find('tr')\n",
    "                h2 = h1.find('th')\n",
    "                header =h2.text\n",
    "                team_year = header.split('-')\n",
    "                team = team_year[0].strip()\n",
    "                year = team_year[1].strip()\n",
    "                df['Url']=cur_url\n",
    "                df['Team']=team\n",
    "                df['Year']=year\n",
    "                player_stats = pd.concat([player_stats,df])\n",
    "    player_stats = player_stats.rename(columns={0:'GameNo',1:'Opponent',2:'Round',3:'Result',4:'Jersey',5:'KI',6:'MK',7:'HB',8:'DI',9:'GL',10:'BH',11:'HO',12:'TK',13:'RB',14:'IF',15:'CL',16:'CG',17:'FF',18:'FA',19:'BR',20:'CP',21:'UP',22:'CM',23:'MI',24:'1%',25:'BO',26:'GA',27:'%P'})\n",
    "    player_stats['Round']=[fix_round(x) for x in player_stats['Round']]\n",
    "\n",
    "\n",
    "    games_set = get_games(proxy=False)\n",
    "\n",
    "\n",
    "\n",
    "    #create one game row for each team\n",
    "    gamesH = games_set.drop(['AwayTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesA = games_set.drop(['HomeTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesH=gamesH.rename(columns={'HomeTeam':'Team'})\n",
    "    gamesA=gamesA.rename(columns={'AwayTeam':'Team'})\n",
    "    gamesAH=pd.concat([gamesH,gamesA])\n",
    "    gamesAH['Year'] = [str(x) for x in gamesAH['Year']]\n",
    "    # get date and game id for each player record\n",
    "    player_stats=pd.merge(player_stats,gamesAH,how='inner',on=['Team','Year','Round'])\n",
    "    player_stats=player_stats.drop_duplicates(subset=['Url','Year','Round'],keep='first')\n",
    "    \n",
    "    return player_stats\n",
    "\n",
    "def get_pastXthis_opponent(x,team,opponent,dt,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, opponent, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    #last 3 against this team\n",
    "    tp = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Opponent']==opponent) ]  # later row.Team\n",
    "    tp = tp.sort_values(by=['Date'],ascending=False)\n",
    "    tp = tp.head(x)\n",
    "    tp = tp.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp_avg = tp.groupby(by='Team').aggregate('mean')\n",
    "    tp_avg.columns = [str(col) + '_lstXopp' for col in tp_avg.columns]\n",
    "    if tp_avg.shape[0]==0:\n",
    "        print('empty row generated for ', dt,' team:',team, ' vs.', opponent)\n",
    "    return tp_avg\n",
    "\n",
    "def get_pastXground(x,team,dt,venue,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date and venue of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    tp2 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Venue'] == venue)] \n",
    "    tp2 = tp2.sort_values(by=['Date'],ascending=False)\n",
    "    tp2 = tp2.head(x)\n",
    "    tp2 = tp2.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp2_avg = tp2.groupby(by='Team').aggregate('mean')\n",
    "    tp2_avg.columns = [str(col) + '_lstXgrd' for col in tp2_avg.columns]\n",
    "    if tp2_avg.shape[0]==0:\n",
    "        print('empty row generated for ',dt,' at ', venue,' team:',team)\n",
    "    return tp2_avg\n",
    "\n",
    "def get_pastX(x,team,dt,team_performaceDF,print_missing=False):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tp1 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt)] \n",
    "    tp1 = tp1.sort_values(by=['Date'],ascending=False)\n",
    "    tp1 = tp1.head(x)\n",
    "    tp1 = tp1.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp1_avg = tp1.groupby(by='Team').aggregate('mean')\n",
    "    tp1_avg.columns = [str(col) + '_lstX' for col in tp1_avg.columns]\n",
    "    if tp1_avg.shape[0]==0 and print_missing:\n",
    "        print('empty row generated for ', dt,' team:',team)\n",
    "    return tp1_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version after 27 Aug 2018 changes\n",
    "\n",
    "def get_drive():\n",
    "    '''\n",
    "    this is to automate switching between home PC and laptop\n",
    "    it returns J:\\\\AFL\\\\ or D:\\\\AFL\\\\ depending if D:\\ is available\n",
    "    \n",
    "    No parameters required\n",
    "    '''\n",
    "    \n",
    "    import win32api\n",
    "    drives = win32api.GetLogicalDriveStrings()\n",
    "    drives = drives.split('\\000')[:-1]\n",
    "    if 'D:\\\\' in drives:\n",
    "        drive = 'D:\\\\AFL\\\\'\n",
    "    else:\n",
    "        drive = 'J:\\\\AFL\\\\'\n",
    "    return drive\n",
    "\n",
    "\n",
    "def get_proxy(proxy):\n",
    "        if proxy:\n",
    "            from os import environ\n",
    "            #pwd = input('Please enter your LAN Pwd')\n",
    "            environ[\"http_proxy\"]=\"http://c819325:sWeater78-@http-gw.tcif.telstra.com.au:8080\"\n",
    "            environ[\"https_proxy\"]=environ.get(\"http_proxy\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fix_round(round_in):\n",
    "    '''\n",
    "    this function convert Round values into sequential integers\n",
    "    '''\n",
    "    if round_in=='QF':\n",
    "        rnd='25'\n",
    "    elif round_in=='EF':\n",
    "        rnd='26'\n",
    "    elif round_in=='SF':\n",
    "        rnd='27'\n",
    "    elif round_in=='PF':\n",
    "        rnd='28'\n",
    "    elif round_in=='GF':\n",
    "        rnd='29'\n",
    "    elif round_in[0]=='R':\n",
    "        rnd=round_in[1:]\n",
    "    else:\n",
    "        rnd=round_in\n",
    "    return int(rnd)\n",
    "\n",
    "def fix_team_name(name):\n",
    "    '''\n",
    "    this function converts any team name to a consistent\n",
    "    set of  names which are usable for joins\n",
    "    '''\n",
    "    if 'Crows' in name:\n",
    "        team_name='Adelaide'\n",
    "    elif name.strip()=='Adelaide Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='AD':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='BL':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='Lions':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='CA':\n",
    "        team_name='Carlton'\n",
    "    elif name=='Blues':\n",
    "        team_name='Carlton'\n",
    "    elif name=='CW':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='Magpies':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='ES':\n",
    "        team_name='Essendon'\n",
    "    elif name=='Bombers':\n",
    "        team_name='Essendon'\n",
    "    elif name=='FR':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='Dockers':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='GE':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Geelong Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='GC':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Gold Coast Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='GWS Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GWS':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW Sydney':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='HW':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='Hawks':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='ME':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Demons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Deamons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='KA':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='NM':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='Kangaroos':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='PA':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='Power':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='RI':\n",
    "        team_name='Richmond'\n",
    "    elif name=='Tigers':\n",
    "        team_name='Richmond'\n",
    "    elif name=='SK':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='Saints':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='SY':\n",
    "        team_name='Sydney'\n",
    "    elif 'Swans' in name:\n",
    "        team_name='Sydney'\n",
    "    elif name=='WC':\n",
    "        team_name='West Coast'\n",
    "    elif name=='West Coast Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='WB':\n",
    "        team_name='Western Bulldogs'\n",
    "    elif name=='Bulldogs':\n",
    "        team_name='Western Bulldogs'\n",
    "    else:\n",
    "        team_name=name\n",
    "    return team_name\n",
    "\n",
    "def fix_venue(name):\n",
    "    if name=='AAMI':\n",
    "        ground = 'Olympic Park'\n",
    "    elif name=='ANZ':\n",
    "        ground = 'Stadium Australia'\n",
    "    elif name=='Adelaide':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Aurora':\n",
    "        ground = 'York Park'\n",
    "    elif name=='Blacktown':\n",
    "        ground='Blacktown'\n",
    "    elif name=='Blundstone Arena':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name=='Blundstone':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name==\"Cazaly's\":\n",
    "        ground= \"Cazaly's Stadium\"\n",
    "    elif name=='Domain':\n",
    "        ground='Subiaco'\n",
    "    elif name=='Etihad Stadium':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='Etihad':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='GMHBA Stadium':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='GMHBA':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='Gabba':\n",
    "        ground = 'Gabba'\n",
    "    elif name=='Jiangwan':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='Jiangwan Stadium, China':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='M.C.G':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='MCG':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='Mars Stadium, Ballarat':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Mars':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Metricon Stadium':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Metricon':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Perth':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='SCG':\n",
    "        ground='S.C.G.'\n",
    "    elif name=='Spotless Stadium':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='Spotless':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='UNSW Canberra Oval':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='StarTrack':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='Treager Park, Alice Springs':\n",
    "        ground='Traeger Park'\n",
    "    elif name=='TIO Stadium, Darwin':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='TIO':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='University of Tasmania Stadium':\n",
    "        ground='York Park'\n",
    "    elif name=='UTAS':\n",
    "        ground='York Park'\n",
    "    elif name=='Westpac':\n",
    "        ground='Wellington'\n",
    "    else:\n",
    "        ground=name\n",
    "    return ground\n",
    "\n",
    "def get_ladder(seas_from,seas_to,proxy=False):\n",
    "    '''\n",
    "    this is just to get the ladder history\n",
    "\n",
    "    Input required - update season from and to in the function call at the bottom\n",
    "    this function returns a dataframe for AFL ladder position history\n",
    "    seas_from - season to start from\n",
    "    seas_to - season end - inclusive\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    ladder = pd.DataFrame(columns=['Team','Games','Points','Percentage','Round','Position','Season'])\n",
    "    for season in range(seas_from-1,seas_to+1): \n",
    "        cur_url = 'http://afltables.com/afl/seas/'+str(season)+'.html'\n",
    "        dfs = pd.read_html(cur_url)\n",
    "\n",
    "        for df in dfs:\n",
    "            if df.columns.nlevels>1:\n",
    "                break\n",
    "            if len(df)>1 and 'Ladder' in df[0][0] and 'Rd' in df[0][0] and len(df.columns)>2:\n",
    "                rnd = df[0][0][3:5]\n",
    "                ldr = df.copy() \n",
    "                ldr = ldr.drop(0,0)\n",
    "                ldr.columns = ['Team','Games','Points','Percentage']\n",
    "                ldr['Round']=rnd\n",
    "                ldr['Position']=ldr.index\n",
    "                ldr['Season']=season\n",
    "                ladder = pd.concat([ladder,ldr])\n",
    "    ladder['Team'] = [fix_team_name(x) for x in ladder['Team']]\n",
    "    \n",
    "    # repeat last round for last and until 29\n",
    "    ladder_f = ladder.copy()\n",
    "    ladder_f.drop_duplicates(subset=['Team','Season'], keep='last', inplace=True)\n",
    "\n",
    "    # get last round for each season\n",
    "    ladder_y = ladder_f.copy()\n",
    "    ladder_y.drop_duplicates(subset=['Season'], keep='last', inplace=True)\n",
    "    ladder_y=ladder_y.drop(['Team','Games','Points','Percentage','Position'],1)\n",
    "    rnd=[]\n",
    "    seas=[]\n",
    "    for index, row in ladder_y.iterrows():\n",
    "        st = int(row.Round)\n",
    "        #print(type(st))\n",
    "        for i in range(st+1,30):\n",
    "            rnd.append(i)\n",
    "            seas.append(row.Season)\n",
    "    ldr = pd.DataFrame()\n",
    "    ldr['Season'] = seas\n",
    "    ldr['Round'] = rnd\n",
    "    #ldr = pd.merge(ladder_f.drop(['Round'],1),ldr,how='inner',on=['Season'])\n",
    "    ladder = pd.concat([ladder,ldr],sort=False)\n",
    "    ladder = ladder.sort_values(by=['Team','Season'],axis=0)\n",
    "    ladder['PosOld']=ladder.Position.shift(1)  #previous ladder position taken\n",
    "    ladder = ladder.drop(['Position'],1)\n",
    "    ladder['Round']= [int(x) for x in ladder['Round']]\n",
    "    ladder=ladder.dropna(axis=0)\n",
    "    ladder['PosOld']= [int(x) for x in ladder['PosOld']]  \n",
    "    return ladder\n",
    "\n",
    "def get_fixture(proxy=False):\n",
    "    '''\n",
    "    this is to get AFL fixture from theroar.com.au\n",
    "    set proxy=True if you are on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    url='https://www.theroar.com.au/afl-draw/'\n",
    "    sauce = urllib.request.urlopen(url)\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "    fixture = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "\n",
    "    for x in soup.find_all('tbody'):\n",
    "        rnd_counter = 0\n",
    "\n",
    "        for y in x.find_all('tr'):\n",
    "\n",
    "            if y.find_all('strong'):\n",
    "                rnd_counter +=1\n",
    "\n",
    "            else:\n",
    "                if not y.find_all('h3') and 'Byes' not in y.text and 'TBC' not in y.text:\n",
    "                    dt,teams,venue,tm = y.text.strip().split('\\n')\n",
    "                    if dt == 'Sar Apr 21':\n",
    "                        dt = 'Sat Apr 21'\n",
    "\n",
    "                    dt = parser.parse(dt)\n",
    "                    if teams == 'North Melbourne Carlton':\n",
    "                            hm_team = 'North Melbourne'\n",
    "                            aw_team = 'Carlton'\n",
    "                    else:\n",
    "                        hm_team, aw_team = teams.split(' vs ')\n",
    "\n",
    "                    #print(rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue))\n",
    "                    df = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "                    df.loc[0]=[rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue)]\n",
    "                    fixture = pd.concat([fixture,df])\n",
    "    return fixture\n",
    "\n",
    "def get_odds_history(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this function gets odds history from footywire.com\n",
    "    min season from is 2010- so it will make the min date 2010 if less than that\n",
    "    set proxy=True if on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    if season_from<2010:\n",
    "        season_from=2010\n",
    "    odds_history=pd.DataFrame()\n",
    "    for season in range(season_from,season_to+1):\n",
    "        print('Getting odds for season',season,'...')\n",
    "        sauce = urllib.request.urlopen('https://www.footywire.com/afl/footy/afl_betting?year='+str(season))\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "\n",
    "        for x in soup.find_all('div',class_ ='datadiv'):\n",
    "            date=[]\n",
    "            venue=[]\n",
    "            team_HM=[]\n",
    "            odds_HM=[]\n",
    "            team_AW=[]\n",
    "            odds_AW=[]\n",
    "            counter =0\n",
    "\n",
    "            home_team_cursor = True\n",
    "            for y in x.find_all('tr'):\n",
    "\n",
    "                for z in y.find_all('td',class_='data'):\n",
    "                    counter = counter+1\n",
    "                    if z.has_attr('height'):\n",
    "                        counter = 0\n",
    "                        #print('new game ',z.text)\n",
    "                        date.append(z.text)\n",
    "                    elif z.has_attr('rowspan'):\n",
    "                        #print('venue ', z.text)\n",
    "                        venue.append(z.text)\n",
    "                    elif not z.has_attr('align'):\n",
    "                        if counter == 2:\n",
    "                            #print('Home team: ', z.text)\n",
    "                            team_HM.append(z.text)\n",
    "                            home_team_cursor=True    \n",
    "                        else:\n",
    "                            #print('Away team: ', z.text)\n",
    "                            counter = 0\n",
    "                            team_AW.append(z.text)\n",
    "                            home_team_cursor=False\n",
    "                    elif counter ==3 and not home_team_cursor:\n",
    "                        #print('away team odds: ',z.text)\n",
    "                        odds_AW.append(z.text)\n",
    "                    elif counter==5 and home_team_cursor:\n",
    "                        #print('home team odds: ',z.text)\n",
    "                        odds_HM.append(z.text)\n",
    "        odds = pd.DataFrame()\n",
    "        odds['Date']=[parser.parse(x,dayfirst=True) for x in date]\n",
    "        odds['Venue']=[fix_venue(x) for x in venue]\n",
    "        odds['HomeTeam']=[fix_team_name(x) for x in team_HM]\n",
    "        odds['OddsHome']=[x for x in odds_HM]\n",
    "        odds['AwayTeam']=[fix_team_name(x) for x in team_AW]\n",
    "        odds['OddsAway']=[x for x in odds_AW]\n",
    "        odds_history = pd.concat([odds_history,odds])  \n",
    "    odds = odds.drop_duplicates(subset=['Date','HomeTeam','AwayTeam'],keep='last')\n",
    "    return odds_history\n",
    "\n",
    "def get_games(proxy=False):\n",
    "    \n",
    "    '''\n",
    "    this function gets past games history\n",
    "    and gets attendance where it is available\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "        \n",
    "    col_specification =[(7, 15), (16, 33), (51, 68), (87, 116),(117,128)]\n",
    "    attend = pd.read_fwf('https://afltables.com/afl/stats/biglists/bg7.txt', \n",
    "                         colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    attend.columns = ['Attendance', 'HomeTeam', 'AwayTeam', 'Venue','Date']\n",
    "    attend['Date']  = pd.to_datetime(attend['Date'],dayfirst=True)\n",
    "    attend['Attendance'] = attend.Attendance.str.replace(r\"[\\*]\",'')\n",
    "    col_specification =[(0, 5), (7, 18), (24, 27), (29, 46),(47,63), (64,81),(82,99),(100,117)]\n",
    "    games= pd.read_fwf('http://afltables.com/afl/stats/biglists/bg3.txt', \n",
    "                       colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    games.columns = ['GameID', 'Date', 'Round', 'HomeTeam', 'ScoreHm','AwayTeam','ScoreAw','Venue']\n",
    "    games = pd.merge(games,attend,how='left',on=['Venue','Date','HomeTeam','AwayTeam'])\n",
    "\n",
    "    #fix rounds in games\n",
    "    games['Round'] = [fix_round(x) for x in games['Round']]\n",
    "    \n",
    "    games['Year']=games['Date'].map(lambda x: x.year)\n",
    "\n",
    "    #fix North Melb in games\n",
    "    games['HomeTeam'] = [fix_team_name(x) for x in games['HomeTeam']]\n",
    "    games['AwayTeam'] = [fix_team_name(x) for x in games['AwayTeam']]\n",
    "\n",
    "    # get result\n",
    "    games['H'] = [int(x.split('.')[2]) for x in games['ScoreHm']]\n",
    "    games['A'] = [int(x.split('.')[2]) for x in games['ScoreAw']]\n",
    "    games = games.drop(['ScoreHm','ScoreAw'],1)\n",
    "    games['Result'] = [round((x[0] /(x[0] +x[1])),3) for x in zip(games['H'],games['A'])]\n",
    "    #games = games.drop(['H','A'],1)\n",
    "    games['ResultWL'] = [1 if x>=0.5 else 0 for x in games.Result]\n",
    "    return games\n",
    "\n",
    "\n",
    "def get_team_performance_hist(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this is to get the team performance history\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BH'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CG'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BR'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CM'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    return team_performace\n",
    "\n",
    "\n",
    "def get_lineup(year,rnd,proxy=False):\n",
    "    '''\n",
    "    returns all available line-up for given year\n",
    "    year - current year you need to specify\n",
    "    rnd - current round where line-up has been released (could be improved into auto later)\n",
    "    proxy = True if on LAN\n",
    "    Pre-requisites: \n",
    "     1.TeamRef.csv - file which maps team names to AFL line-up abbreviated names\n",
    "     2.Fixture function is used\n",
    "\n",
    "    '''    \n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "\n",
    "    fixture = get_fixture(proxy)\n",
    "    fixture = fixture[fixture.Round==rnd]  #this limits to current round only\n",
    "    teams = pd.read_csv(get_drive()+'TeamRef.csv')\n",
    "\n",
    "    this_1 = pd.merge(fixture,teams,how=\"inner\",left_on=['HomeTeam'],right_on=['Team'])\n",
    "    this_2 = pd.merge(this_1,teams,how=\"inner\",left_on=['AwayTeam'],right_on=['Team'])\n",
    "    rounds = this_2.drop(['Team_x','Team_y'],1)\n",
    "    rounds['Game'] = [x + '-v-' +y for x,y in zip(rounds.AFL_Team_Nm_x,rounds.AFL_Team_Nm_y)]\n",
    "    rounds = rounds.drop(['AFL_Team_Nm_x','AFL_Team_Nm_y'],1)\n",
    "\n",
    "\n",
    "    # now get available line-up for player ref working\n",
    "\n",
    "    #rounds = rounds[rounds.Round<=max_round]    # needs updating, just available\n",
    "\n",
    "    lineup=pd.DataFrame()\n",
    "    for gm,rnd in zip(rounds['Game'],rounds['Round']):\n",
    "        url='http://www.afl.com.au/match-centre/'+str(year)+'/'+str(rnd)+'/'+gm\n",
    "        \n",
    "        sauce = urllib.request.urlopen(url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        plrs=[]\n",
    "        for x in soup.find_all('div',class_ ='lineup'):\n",
    "            for t in x.find_all('div',class_ ='text-inouts'):\n",
    "                team=''\n",
    "                for tm in t.find_all('h4'):\n",
    "                    team=tm.text\n",
    "\n",
    "                for p in t.find_all('div',class_ ='posGroup'):\n",
    "                    position=''\n",
    "                    for pos in p.find_all('p',class_ ='pos'):\n",
    "                        position =pos.text.strip()\n",
    "                    for player in p.find_all('li'):\n",
    "                        if position in ['B','HB','C','HF','F','Fol','I/C']:\n",
    "                            tms.append(team)\n",
    "                            plrs.append(player.text.strip().strip(','))\n",
    "\n",
    "        d = pd.DataFrame()\n",
    "        d['Team'] = tms\n",
    "        d['Player'] = plrs\n",
    "        lineup=pd.concat([lineup,d])\n",
    "    lineup['Team']=[fix_team_name(x) for x in lineup['Team']]\n",
    "    return lineup\n",
    "\n",
    "def get_player_base(proxy):\n",
    "    '''\n",
    "    !!! run only when need to update for new players !!!\n",
    "    returns a dataframe of player base table to enable to skip older players\n",
    "    e.g. players[players.DoB>'1975-01-01']  this gives 2.5k player subset\n",
    "    \n",
    "    typical use - to create Players.csv file in AFL directory - !!! pre-requisite for getting player performance\n",
    "\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    players = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days'])\n",
    "\n",
    "    # get player urls\n",
    "    links = []\n",
    "    for c in ascii_uppercase :\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/players'+c+'_idx.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "        for url in soup.find_all('a',href=True):\n",
    "            links.append('https://afltables.com/afl/stats/'+url['href'])\n",
    "    # now remove non-player links - ones that contain 'idx'\n",
    "    links = [item for item in links if 'players' in item and 'idx' not in item and 'afl_index' not in item]        \n",
    "\n",
    "    for cur_url in links:\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        #Name\n",
    "        x = soup.find_all('h1')\n",
    "        name = x[0].text\n",
    "\n",
    "        #DoB\n",
    "        found_dob=False\n",
    "\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Born:':\n",
    "                dob = x.next_sibling\n",
    "                found_dob=True\n",
    "                break\n",
    "        if found_dob:\n",
    "            dob=parser.parse(dob[0:11],dayfirst=True)\n",
    "        else:\n",
    "            dob = datetime.datetime(1900, 1, 1, 0, 0)\n",
    "\n",
    "        #Debut\n",
    "        found_debut = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Debut:':\n",
    "                debut = x.next_sibling\n",
    "                found_debut=True\n",
    "                break\n",
    "        if found_debut:\n",
    "            debut =debut.split()\n",
    "            debut1 = ''.join(c for c in debut[0] if c.isdigit())\n",
    "            if len(debut)>1:\n",
    "                debut2 = ''.join(c for c in debut[1] if c.isdigit())\n",
    "                debut = int(debut1)+int(debut2)/365\n",
    "            else:\n",
    "                debut = int(debut1)\n",
    "        else:\n",
    "            debut = 100\n",
    "        #age last played\n",
    "        found_last = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Last:':\n",
    "                age_last = x.next_sibling\n",
    "                found_last=True\n",
    "                break\n",
    "        if found_last:\n",
    "            age_last =age_last.split()\n",
    "            a1 = ''.join(c for c in age_last[0] if c.isdigit())\n",
    "            if len(age_last)>1:\n",
    "                a2 = ''.join(c for c in age_last[1] if c.isdigit())\n",
    "                age_last = int(a1)*365.25+int(a2) #in days\n",
    "            else:\n",
    "                age_last = int(a1)*365.25\n",
    "        else:\n",
    "            age_last = 40*365.25\n",
    "        today = datetime.datetime.today()\n",
    "        last_played_date = dob + datetime.timedelta(days=age_last)\n",
    "        since_last_game=today-last_played_date\n",
    "        df = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days','Last_Played_Date'])\n",
    "        df.loc[0]=[name,dob,cur_url,debut,age_last,last_played_date]\n",
    "        players = pd.concat([players,df])\n",
    "        print(name)\n",
    "    return players\n",
    "\n",
    "\n",
    "\n",
    "def get_player_perf(DoB_min='1975-01-01',proxy=False):\n",
    "    '''\n",
    "    Use this only once per complete round and save into CSV as it takes a while to run\n",
    "    this function returns a dataframe of player performance history\n",
    "    Entire player history is returned\n",
    "    DoB_min is limiting factor to get only player born after the date - for performance reasons\n",
    "    change the default if you need to go more back into older players or in reverse\n",
    "    Pre-requisite: Players.csv file exists in the AFL directory\n",
    "    set proxy=True when on office LAN\n",
    "    \n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "    players = pd.read_csv(get_drive()+'Players.csv')\n",
    "    players =players[players['DoB']>DoB_min]\n",
    "\n",
    "    player_stats = pd.DataFrame(columns=['Url','Team','Year'])\n",
    "\n",
    "    for cur_url in players.Url:\n",
    "        print(cur_url)\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        found=False\n",
    "        dfs=[]\n",
    "        for table in soup.find_all('table'):\n",
    "            #t1=tables[7]\n",
    "            t=table.find('tbody')\n",
    "            res = []\n",
    "            row = []\n",
    "            rows = t.find_all('tr')\n",
    "            for tr in rows:\n",
    "                for td in tr.find_all('td'):\n",
    "                    row.append(td.text)\n",
    "                res.append(row)\n",
    "                row = []\n",
    "            df=pd.DataFrame(data=res)\n",
    "\n",
    "            if len(df.columns)==28: # found first game\n",
    "                    found = True\n",
    "            if found:\n",
    "                h=table.find('thead')\n",
    "                h1 = h.find('tr')\n",
    "                h2 = h1.find('th')\n",
    "                header =h2.text\n",
    "                team_year = header.split('-')\n",
    "                team = team_year[0].strip()\n",
    "                year = team_year[1].strip()\n",
    "                df['Url']=cur_url\n",
    "                df['Team']=team\n",
    "                df['Year']=year\n",
    "                player_stats = pd.concat([player_stats,df])\n",
    "    player_stats = player_stats.rename(columns={0:'GameNo',1:'Opponent',2:'Round',3:'Result',4:'Jersey',5:'KI',6:'MK',7:'HB',8:'DI',9:'GL',10:'BH',11:'HO',12:'TK',13:'RB',14:'IF',15:'CL',16:'CG',17:'FF',18:'FA',19:'BR',20:'CP',21:'UP',22:'CM',23:'MI',24:'1%',25:'BO',26:'GA',27:'%P'})\n",
    "    player_stats['Round']=[fix_round(x) for x in player_stats['Round']]\n",
    "\n",
    "\n",
    "    games_set = get_games(proxy=False)\n",
    "\n",
    "\n",
    "\n",
    "    #create one game row for each team\n",
    "    gamesH = games_set.drop(['AwayTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesA = games_set.drop(['HomeTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesH=gamesH.rename(columns={'HomeTeam':'Team'})\n",
    "    gamesA=gamesA.rename(columns={'AwayTeam':'Team'})\n",
    "    gamesAH=pd.concat([gamesH,gamesA])\n",
    "    gamesAH['Year'] = [str(x) for x in gamesAH['Year']]\n",
    "    # get date and game id for each player record\n",
    "    player_stats=pd.merge(player_stats,gamesAH,how='inner',on=['Team','Year','Round'])\n",
    "    player_stats=player_stats.drop_duplicates(subset=['Url','Year','Round'],keep='first')\n",
    "    \n",
    "    return player_stats\n",
    "\n",
    "def get_pastXthis_opponent(x,team,opponent,dt,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, opponent, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    #last 3 against this team\n",
    "    tp = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Opponent']==opponent) ]  # later row.Team\n",
    "    tp = tp.sort_values(by=['Date'],ascending=False)\n",
    "    tp = tp.head(x)\n",
    "    tp = tp.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp_avg = tp.groupby(by='Team').aggregate('mean')\n",
    "    tp_avg.columns = [str(col) + '_lstXopp' for col in tp_avg.columns]\n",
    "    if tp_avg.shape[0]==0:\n",
    "        print('empty row generated for ', dt,' team:',team, ' vs.', opponent)\n",
    "    return tp_avg\n",
    "\n",
    "def get_pastXground(x,team,dt,venue,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date and venue of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    tp2 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Venue'] == venue)] \n",
    "    tp2 = tp2.sort_values(by=['Date'],ascending=False)\n",
    "    tp2 = tp2.head(x)\n",
    "    tp2 = tp2.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp2_avg = tp2.groupby(by='Team').aggregate('mean')\n",
    "    tp2_avg.columns = [str(col) + '_lstXgrd' for col in tp2_avg.columns]\n",
    "    if tp2_avg.shape[0]==0:\n",
    "        print('empty row generated for ',dt,' at ', venue,' team:',team)\n",
    "    return tp2_avg\n",
    "\n",
    "def get_pastX(x,team,dt,team_performaceDF,print_missing=False):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tp1 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt)] \n",
    "    tp1 = tp1.sort_values(by=['Date'],ascending=False)\n",
    "    tp1 = tp1.head(x)\n",
    "    tp1 = tp1.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp1_avg = tp1.groupby(by='Team').aggregate('mean')\n",
    "    tp1_avg.columns = [str(col) + '_lstX' for col in tp1_avg.columns]\n",
    "    if tp1_avg.shape[0]==0 and print_missing:\n",
    "        print('empty row generated for ', dt,' team:',team)\n",
    "    return tp1_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version after 28 Aug 2018 changes\n",
    "# get past X functions calculate Margin/Result\n",
    "\n",
    "def get_drive():\n",
    "    '''\n",
    "    this is to automate switching between home PC and laptop\n",
    "    it returns J:\\\\AFL\\\\ or D:\\\\AFL\\\\ depending if D:\\ is available\n",
    "    \n",
    "    No parameters required\n",
    "    '''\n",
    "    \n",
    "    import win32api\n",
    "    drives = win32api.GetLogicalDriveStrings()\n",
    "    drives = drives.split('\\000')[:-1]\n",
    "    if 'D:\\\\' in drives:\n",
    "        drive = 'D:\\\\AFL\\\\'\n",
    "    else:\n",
    "        drive = 'J:\\\\AFL\\\\'\n",
    "    return drive\n",
    "\n",
    "\n",
    "def get_proxy(proxy):\n",
    "        if proxy:\n",
    "            from os import environ\n",
    "            #pwd = input('Please enter your LAN Pwd')\n",
    "            environ[\"http_proxy\"]=\"http://c819325:sWeater78-@http-gw.tcif.telstra.com.au:8080\"\n",
    "            environ[\"https_proxy\"]=environ.get(\"http_proxy\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fix_round(round_in):\n",
    "    '''\n",
    "    this function convert Round values into sequential integers\n",
    "    '''\n",
    "    if round_in=='QF':\n",
    "        rnd='25'\n",
    "    elif round_in=='EF':\n",
    "        rnd='26'\n",
    "    elif round_in=='SF':\n",
    "        rnd='27'\n",
    "    elif round_in=='PF':\n",
    "        rnd='28'\n",
    "    elif round_in=='GF':\n",
    "        rnd='29'\n",
    "    elif round_in[0]=='R':\n",
    "        rnd=round_in[1:]\n",
    "    else:\n",
    "        rnd=round_in\n",
    "    return int(rnd)\n",
    "\n",
    "def fix_team_name(name):\n",
    "    '''\n",
    "    this function converts any team name to a consistent\n",
    "    set of  names which are usable for joins\n",
    "    '''\n",
    "    if 'Crows' in name:\n",
    "        team_name='Adelaide'\n",
    "    elif name.strip()=='Adelaide Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='AD':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='BL':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='Lions':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='CA':\n",
    "        team_name='Carlton'\n",
    "    elif name=='Blues':\n",
    "        team_name='Carlton'\n",
    "    elif name=='CW':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='Magpies':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='ES':\n",
    "        team_name='Essendon'\n",
    "    elif name=='Bombers':\n",
    "        team_name='Essendon'\n",
    "    elif name=='FR':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='Dockers':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='GE':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Geelong Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='GC':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Gold Coast Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='GWS Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GWS':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW Sydney':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='HW':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='Hawks':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='ME':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Demons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Deamons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='KA':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='NM':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='Kangaroos':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='PA':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='Power':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='RI':\n",
    "        team_name='Richmond'\n",
    "    elif name=='Tigers':\n",
    "        team_name='Richmond'\n",
    "    elif name=='SK':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='Saints':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='SY':\n",
    "        team_name='Sydney'\n",
    "    elif 'Swans' in name:\n",
    "        team_name='Sydney'\n",
    "    elif name=='WC':\n",
    "        team_name='West Coast'\n",
    "    elif name=='West Coast Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='WB':\n",
    "        team_name='Western Bulldogs'\n",
    "    elif name=='Bulldogs':\n",
    "        team_name='Western Bulldogs'\n",
    "    else:\n",
    "        team_name=name\n",
    "    return team_name\n",
    "\n",
    "def fix_venue(name):\n",
    "    if name=='AAMI':\n",
    "        ground = 'Olympic Park'\n",
    "    elif name=='ANZ':\n",
    "        ground = 'Stadium Australia'\n",
    "    elif name=='Adelaide':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Aurora':\n",
    "        ground = 'York Park'\n",
    "    elif name=='Blacktown':\n",
    "        ground='Blacktown'\n",
    "    elif name=='Blundstone Arena':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name=='Blundstone':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name==\"Cazaly's\":\n",
    "        ground= \"Cazaly's Stadium\"\n",
    "    elif name=='Domain':\n",
    "        ground='Subiaco'\n",
    "    elif name=='Etihad Stadium':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='Etihad':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='GMHBA Stadium':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='GMHBA':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='Gabba':\n",
    "        ground = 'Gabba'\n",
    "    elif name=='Jiangwan':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='Jiangwan Stadium, China':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='M.C.G':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='MCG':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='Mars Stadium, Ballarat':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Mars':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Metricon Stadium':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Metricon':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Perth':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='SCG':\n",
    "        ground='S.C.G.'\n",
    "    elif name=='Spotless Stadium':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='Spotless':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='UNSW Canberra Oval':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='StarTrack':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='Treager Park, Alice Springs':\n",
    "        ground='Traeger Park'\n",
    "    elif name=='TIO Stadium, Darwin':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='TIO':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='University of Tasmania Stadium':\n",
    "        ground='York Park'\n",
    "    elif name=='UTAS':\n",
    "        ground='York Park'\n",
    "    elif name=='Westpac':\n",
    "        ground='Wellington'\n",
    "    else:\n",
    "        ground=name\n",
    "    return ground\n",
    "\n",
    "def get_ladder(seas_from,seas_to,proxy=False):\n",
    "    '''\n",
    "    this is just to get the ladder history\n",
    "\n",
    "    Input required - update season from and to in the function call at the bottom\n",
    "    this function returns a dataframe for AFL ladder position history\n",
    "    seas_from - season to start from\n",
    "    seas_to - season end - inclusive\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    ladder = pd.DataFrame(columns=['Team','Games','Points','Percentage','Round','Position','Season'])\n",
    "    for season in range(seas_from-1,seas_to+1): \n",
    "        cur_url = 'http://afltables.com/afl/seas/'+str(season)+'.html'\n",
    "        dfs = pd.read_html(cur_url)\n",
    "\n",
    "        for df in dfs:\n",
    "            if df.columns.nlevels>1:\n",
    "                break\n",
    "            if len(df)>1 and 'Ladder' in df[0][0] and 'Rd' in df[0][0] and len(df.columns)>2:\n",
    "                rnd = df[0][0][3:5]\n",
    "                ldr = df.copy() \n",
    "                ldr = ldr.drop(0,0)\n",
    "                ldr.columns = ['Team','Games','Points','Percentage']\n",
    "                ldr['Round']=rnd\n",
    "                ldr['Position']=ldr.index\n",
    "                ldr['Season']=season\n",
    "                ladder = pd.concat([ladder,ldr])\n",
    "    ladder['Team'] = [fix_team_name(x) for x in ladder['Team']]\n",
    "    \n",
    "    # repeat last round for last and until 29\n",
    "    ladder_f = ladder.copy()\n",
    "    ladder_f.drop_duplicates(subset=['Team','Season'], keep='last', inplace=True)\n",
    "\n",
    "    # get last round for each season\n",
    "    ladder_y = ladder_f.copy()\n",
    "    ladder_y.drop_duplicates(subset=['Season'], keep='last', inplace=True)\n",
    "    ladder_y=ladder_y.drop(['Team','Games','Points','Percentage','Position'],1)\n",
    "    rnd=[]\n",
    "    seas=[]\n",
    "    for index, row in ladder_y.iterrows():\n",
    "        st = int(row.Round)\n",
    "        #print(type(st))\n",
    "        for i in range(st+1,30):\n",
    "            rnd.append(i)\n",
    "            seas.append(row.Season)\n",
    "    ldr = pd.DataFrame()\n",
    "    ldr['Season'] = seas\n",
    "    ldr['Round'] = rnd\n",
    "    #ldr = pd.merge(ladder_f.drop(['Round'],1),ldr,how='inner',on=['Season'])\n",
    "    ladder = pd.concat([ladder,ldr],sort=False)\n",
    "    ladder = ladder.sort_values(by=['Team','Season'],axis=0)\n",
    "    ladder['PosOld']=ladder.Position.shift(1)  #previous ladder position taken\n",
    "    ladder = ladder.drop(['Position'],1)\n",
    "    ladder['Round']= [int(x) for x in ladder['Round']]\n",
    "    ladder=ladder.dropna(axis=0)\n",
    "    ladder['PosOld']= [int(x) for x in ladder['PosOld']]  \n",
    "    return ladder\n",
    "\n",
    "def get_fixture(proxy=False):\n",
    "    '''\n",
    "    this is to get AFL fixture from theroar.com.au\n",
    "    set proxy=True if you are on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    url='https://www.theroar.com.au/afl-draw/'\n",
    "    sauce = urllib.request.urlopen(url)\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "    fixture = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "\n",
    "    for x in soup.find_all('tbody'):\n",
    "        rnd_counter = 0\n",
    "\n",
    "        for y in x.find_all('tr'):\n",
    "\n",
    "            if y.find_all('strong'):\n",
    "                rnd_counter +=1\n",
    "\n",
    "            else:\n",
    "                if not y.find_all('h3') and 'Byes' not in y.text and 'TBC' not in y.text:\n",
    "                    dt,teams,venue,tm = y.text.strip().split('\\n')\n",
    "                    if dt == 'Sar Apr 21':\n",
    "                        dt = 'Sat Apr 21'\n",
    "\n",
    "                    dt = parser.parse(dt)\n",
    "                    if teams == 'North Melbourne Carlton':\n",
    "                            hm_team = 'North Melbourne'\n",
    "                            aw_team = 'Carlton'\n",
    "                    else:\n",
    "                        hm_team, aw_team = teams.split(' vs ')\n",
    "\n",
    "                    #print(rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue))\n",
    "                    df = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "                    df.loc[0]=[rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue)]\n",
    "                    fixture = pd.concat([fixture,df])\n",
    "    return fixture\n",
    "\n",
    "def get_odds_history(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this function gets odds history from footywire.com\n",
    "    min season from is 2010- so it will make the min date 2010 if less than that\n",
    "    set proxy=True if on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    if season_from<2010:\n",
    "        season_from=2010\n",
    "    odds_history=pd.DataFrame()\n",
    "    for season in range(season_from,season_to+1):\n",
    "        print('Getting odds for season',season,'...')\n",
    "        sauce = urllib.request.urlopen('https://www.footywire.com/afl/footy/afl_betting?year='+str(season))\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "\n",
    "        for x in soup.find_all('div',class_ ='datadiv'):\n",
    "            date=[]\n",
    "            venue=[]\n",
    "            team_HM=[]\n",
    "            odds_HM=[]\n",
    "            team_AW=[]\n",
    "            odds_AW=[]\n",
    "            counter =0\n",
    "\n",
    "            home_team_cursor = True\n",
    "            for y in x.find_all('tr'):\n",
    "\n",
    "                for z in y.find_all('td',class_='data'):\n",
    "                    counter = counter+1\n",
    "                    if z.has_attr('height'):\n",
    "                        counter = 0\n",
    "                        #print('new game ',z.text)\n",
    "                        date.append(z.text)\n",
    "                    elif z.has_attr('rowspan'):\n",
    "                        #print('venue ', z.text)\n",
    "                        venue.append(z.text)\n",
    "                    elif not z.has_attr('align'):\n",
    "                        if counter == 2:\n",
    "                            #print('Home team: ', z.text)\n",
    "                            team_HM.append(z.text)\n",
    "                            home_team_cursor=True    \n",
    "                        else:\n",
    "                            #print('Away team: ', z.text)\n",
    "                            counter = 0\n",
    "                            team_AW.append(z.text)\n",
    "                            home_team_cursor=False\n",
    "                    elif counter ==3 and not home_team_cursor:\n",
    "                        #print('away team odds: ',z.text)\n",
    "                        odds_AW.append(z.text)\n",
    "                    elif counter==5 and home_team_cursor:\n",
    "                        #print('home team odds: ',z.text)\n",
    "                        odds_HM.append(z.text)\n",
    "        odds = pd.DataFrame()\n",
    "        odds['Date']=[parser.parse(x,dayfirst=True) for x in date]\n",
    "        odds['Venue']=[fix_venue(x) for x in venue]\n",
    "        odds['HomeTeam']=[fix_team_name(x) for x in team_HM]\n",
    "        odds['OddsHome']=[x for x in odds_HM]\n",
    "        odds['AwayTeam']=[fix_team_name(x) for x in team_AW]\n",
    "        odds['OddsAway']=[x for x in odds_AW]\n",
    "        odds_history = pd.concat([odds_history,odds])  \n",
    "    odds = odds.drop_duplicates(subset=['Date','HomeTeam','AwayTeam'],keep='last')\n",
    "    return odds_history\n",
    "\n",
    "def get_games(proxy=False):\n",
    "    \n",
    "    '''\n",
    "    this function gets past games history\n",
    "    and gets attendance where it is available\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "        \n",
    "    col_specification =[(7, 15), (16, 33), (51, 68), (87, 116),(117,128)]\n",
    "    attend = pd.read_fwf('https://afltables.com/afl/stats/biglists/bg7.txt', \n",
    "                         colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    attend.columns = ['Attendance', 'HomeTeam', 'AwayTeam', 'Venue','Date']\n",
    "    attend['Date']  = pd.to_datetime(attend['Date'],dayfirst=True)\n",
    "    attend['Attendance'] = attend.Attendance.str.replace(r\"[\\*]\",'')\n",
    "    col_specification =[(0, 5), (7, 18), (24, 27), (29, 46),(47,63), (64,81),(82,99),(100,117)]\n",
    "    games= pd.read_fwf('http://afltables.com/afl/stats/biglists/bg3.txt', \n",
    "                       colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    games.columns = ['GameID', 'Date', 'Round', 'HomeTeam', 'ScoreHm','AwayTeam','ScoreAw','Venue']\n",
    "    games = pd.merge(games,attend,how='left',on=['Venue','Date','HomeTeam','AwayTeam'])\n",
    "\n",
    "    #fix rounds in games\n",
    "    games['Round'] = [fix_round(x) for x in games['Round']]\n",
    "    \n",
    "    games['Year']=games['Date'].map(lambda x: x.year)\n",
    "\n",
    "    #fix North Melb in games\n",
    "    games['HomeTeam'] = [fix_team_name(x) for x in games['HomeTeam']]\n",
    "    games['AwayTeam'] = [fix_team_name(x) for x in games['AwayTeam']]\n",
    "\n",
    "    # get result\n",
    "    games['H'] = [int(x.split('.')[2]) for x in games['ScoreHm']]\n",
    "    games['A'] = [int(x.split('.')[2]) for x in games['ScoreAw']]\n",
    "    games = games.drop(['ScoreHm','ScoreAw'],1)\n",
    "    games['Result'] = [round((x[0] /(x[0] +x[1])),3) for x in zip(games['H'],games['A'])]\n",
    "    #games = games.drop(['H','A'],1)\n",
    "    games['ResultWL'] = [1 if x>=0.5 else 0 for x in games.Result]\n",
    "    return games\n",
    "\n",
    "\n",
    "def get_team_performance_hist(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this is to get the team performance history\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BH'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TK'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RB'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CL'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CG'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FF'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BR'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UP'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CM'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MI'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BO'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GA'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    return team_performace\n",
    "\n",
    "\n",
    "def get_lineup(year,rnd,proxy=False):\n",
    "    '''\n",
    "    returns all available line-up for given year\n",
    "    year - current year you need to specify\n",
    "    rnd - current round where line-up has been released (could be improved into auto later)\n",
    "    proxy = True if on LAN\n",
    "    Pre-requisites: \n",
    "     1.TeamRef.csv - file which maps team names to AFL line-up abbreviated names\n",
    "     2.Fixture function is used\n",
    "\n",
    "    '''    \n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "\n",
    "    fixture = get_fixture(proxy)\n",
    "    fixture = fixture[fixture.Round==rnd]  #this limits to current round only\n",
    "    teams = pd.read_csv(get_drive()+'TeamRef.csv')\n",
    "\n",
    "    this_1 = pd.merge(fixture,teams,how=\"inner\",left_on=['HomeTeam'],right_on=['Team'])\n",
    "    this_2 = pd.merge(this_1,teams,how=\"inner\",left_on=['AwayTeam'],right_on=['Team'])\n",
    "    rounds = this_2.drop(['Team_x','Team_y'],1)\n",
    "    rounds['Game'] = [x + '-v-' +y for x,y in zip(rounds.AFL_Team_Nm_x,rounds.AFL_Team_Nm_y)]\n",
    "    rounds = rounds.drop(['AFL_Team_Nm_x','AFL_Team_Nm_y'],1)\n",
    "\n",
    "\n",
    "    # now get available line-up for player ref working\n",
    "\n",
    "    #rounds = rounds[rounds.Round<=max_round]    # needs updating, just available\n",
    "\n",
    "    lineup=pd.DataFrame()\n",
    "    for gm,rnd in zip(rounds['Game'],rounds['Round']):\n",
    "        url='http://www.afl.com.au/match-centre/'+str(year)+'/'+str(rnd)+'/'+gm\n",
    "        \n",
    "        sauce = urllib.request.urlopen(url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        plrs=[]\n",
    "        for x in soup.find_all('div',class_ ='lineup'):\n",
    "            for t in x.find_all('div',class_ ='text-inouts'):\n",
    "                team=''\n",
    "                for tm in t.find_all('h4'):\n",
    "                    team=tm.text\n",
    "\n",
    "                for p in t.find_all('div',class_ ='posGroup'):\n",
    "                    position=''\n",
    "                    for pos in p.find_all('p',class_ ='pos'):\n",
    "                        position =pos.text.strip()\n",
    "                    for player in p.find_all('li'):\n",
    "                        if position in ['B','HB','C','HF','F','Fol','I/C']:\n",
    "                            tms.append(team)\n",
    "                            plrs.append(player.text.strip().strip(','))\n",
    "\n",
    "        d = pd.DataFrame()\n",
    "        d['Team'] = tms\n",
    "        d['Player'] = plrs\n",
    "        lineup=pd.concat([lineup,d])\n",
    "    lineup['Team']=[fix_team_name(x) for x in lineup['Team']]\n",
    "    return lineup\n",
    "\n",
    "def get_player_base(proxy):\n",
    "    '''\n",
    "    !!! run only when need to update for new players !!!\n",
    "    returns a dataframe of player base table to enable to skip older players\n",
    "    e.g. players[players.DoB>'1975-01-01']  this gives 2.5k player subset\n",
    "    \n",
    "    typical use - to create Players.csv file in AFL directory - !!! pre-requisite for getting player performance\n",
    "\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    players = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days'])\n",
    "\n",
    "    # get player urls\n",
    "    links = []\n",
    "    for c in ascii_uppercase :\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/players'+c+'_idx.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "        for url in soup.find_all('a',href=True):\n",
    "            links.append('https://afltables.com/afl/stats/'+url['href'])\n",
    "    # now remove non-player links - ones that contain 'idx'\n",
    "    links = [item for item in links if 'players' in item and 'idx' not in item and 'afl_index' not in item]        \n",
    "\n",
    "    for cur_url in links:\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        #Name\n",
    "        x = soup.find_all('h1')\n",
    "        name = x[0].text\n",
    "\n",
    "        #DoB\n",
    "        found_dob=False\n",
    "\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Born:':\n",
    "                dob = x.next_sibling\n",
    "                found_dob=True\n",
    "                break\n",
    "        if found_dob:\n",
    "            dob=parser.parse(dob[0:11],dayfirst=True)\n",
    "        else:\n",
    "            dob = datetime.datetime(1900, 1, 1, 0, 0)\n",
    "\n",
    "        #Debut\n",
    "        found_debut = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Debut:':\n",
    "                debut = x.next_sibling\n",
    "                found_debut=True\n",
    "                break\n",
    "        if found_debut:\n",
    "            debut =debut.split()\n",
    "            debut1 = ''.join(c for c in debut[0] if c.isdigit())\n",
    "            if len(debut)>1:\n",
    "                debut2 = ''.join(c for c in debut[1] if c.isdigit())\n",
    "                debut = int(debut1)+int(debut2)/365\n",
    "            else:\n",
    "                debut = int(debut1)\n",
    "        else:\n",
    "            debut = 100\n",
    "        #age last played\n",
    "        found_last = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Last:':\n",
    "                age_last = x.next_sibling\n",
    "                found_last=True\n",
    "                break\n",
    "        if found_last:\n",
    "            age_last =age_last.split()\n",
    "            a1 = ''.join(c for c in age_last[0] if c.isdigit())\n",
    "            if len(age_last)>1:\n",
    "                a2 = ''.join(c for c in age_last[1] if c.isdigit())\n",
    "                age_last = int(a1)*365.25+int(a2) #in days\n",
    "            else:\n",
    "                age_last = int(a1)*365.25\n",
    "        else:\n",
    "            age_last = 40*365.25\n",
    "        today = datetime.datetime.today()\n",
    "        last_played_date = dob + datetime.timedelta(days=age_last)\n",
    "        since_last_game=today-last_played_date\n",
    "        df = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days','Last_Played_Date'])\n",
    "        df.loc[0]=[name,dob,cur_url,debut,age_last,last_played_date]\n",
    "        players = pd.concat([players,df])\n",
    "        print(name)\n",
    "    return players\n",
    "\n",
    "\n",
    "\n",
    "def get_player_perf(DoB_min='1975-01-01',proxy=False):\n",
    "    '''\n",
    "    Use this only once per complete round and save into CSV as it takes a while to run\n",
    "    this function returns a dataframe of player performance history\n",
    "    Entire player history is returned\n",
    "    DoB_min is limiting factor to get only player born after the date - for performance reasons\n",
    "    change the default if you need to go more back into older players or in reverse\n",
    "    Pre-requisite: Players.csv file exists in the AFL directory\n",
    "    set proxy=True when on office LAN\n",
    "    \n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "    players = pd.read_csv(get_drive()+'Players.csv')\n",
    "    players =players[players['DoB']>DoB_min]\n",
    "\n",
    "    player_stats = pd.DataFrame(columns=['Url','Team','Year'])\n",
    "\n",
    "    for cur_url in players.Url:\n",
    "        print(cur_url)\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        found=False\n",
    "        dfs=[]\n",
    "        for table in soup.find_all('table'):\n",
    "            #t1=tables[7]\n",
    "            t=table.find('tbody')\n",
    "            res = []\n",
    "            row = []\n",
    "            rows = t.find_all('tr')\n",
    "            for tr in rows:\n",
    "                for td in tr.find_all('td'):\n",
    "                    row.append(td.text)\n",
    "                res.append(row)\n",
    "                row = []\n",
    "            df=pd.DataFrame(data=res)\n",
    "\n",
    "            if len(df.columns)==28: # found first game\n",
    "                    found = True\n",
    "            if found:\n",
    "                h=table.find('thead')\n",
    "                h1 = h.find('tr')\n",
    "                h2 = h1.find('th')\n",
    "                header =h2.text\n",
    "                team_year = header.split('-')\n",
    "                team = team_year[0].strip()\n",
    "                year = team_year[1].strip()\n",
    "                df['Url']=cur_url\n",
    "                df['Team']=team\n",
    "                df['Year']=year\n",
    "                player_stats = pd.concat([player_stats,df])\n",
    "    player_stats = player_stats.rename(columns={0:'GameNo',1:'Opponent',2:'Round',3:'Result',4:'Jersey',5:'KI',6:'MK',7:'HB',8:'DI',9:'GL',10:'BH',11:'HO',12:'TK',13:'RB',14:'IF',15:'CL',16:'CG',17:'FF',18:'FA',19:'BR',20:'CP',21:'UP',22:'CM',23:'MI',24:'1%',25:'BO',26:'GA',27:'%P'})\n",
    "    player_stats['Round']=[fix_round(x) for x in player_stats['Round']]\n",
    "\n",
    "\n",
    "    games_set = get_games(proxy=False)\n",
    "\n",
    "\n",
    "\n",
    "    #create one game row for each team\n",
    "    gamesH = games_set.drop(['AwayTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesA = games_set.drop(['HomeTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesH=gamesH.rename(columns={'HomeTeam':'Team'})\n",
    "    gamesA=gamesA.rename(columns={'AwayTeam':'Team'})\n",
    "    gamesAH=pd.concat([gamesH,gamesA])\n",
    "    gamesAH['Year'] = [str(x) for x in gamesAH['Year']]\n",
    "    # get date and game id for each player record\n",
    "    player_stats=pd.merge(player_stats,gamesAH,how='inner',on=['Team','Year','Round'])\n",
    "    player_stats=player_stats.drop_duplicates(subset=['Url','Year','Round'],keep='first')\n",
    "    \n",
    "    return player_stats\n",
    "\n",
    "def get_pastXthis_opponent(x,team,opponent,dt,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, opponent, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    #last 3 against this team\n",
    "    tp = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Opponent']==opponent) ]  # later row.Team\n",
    "    tp = tp.sort_values(by=['Date'],ascending=False)\n",
    "    tp = tp.head(x)\n",
    "    tp = tp.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp['Score']=[g*6+b for g,b in zip(tp['GL'],tp['BH'])]  # new line this version\n",
    "    tp_avg = tp.groupby(by='Team').aggregate('mean')\n",
    "    tp_avg.columns = [str(col) + '_lstXopp' for col in tp_avg.columns]\n",
    "    if tp_avg.shape[0]==0:\n",
    "        print('empty row generated for ', dt,' team:',team, ' vs.', opponent)\n",
    "    return tp_avg\n",
    "\n",
    "def get_pastXground(x,team,dt,venue,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date and venue of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    tp2 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Venue'] == venue)] \n",
    "    tp2 = tp2.sort_values(by=['Date'],ascending=False)\n",
    "    tp2 = tp2.head(x)\n",
    "    tp2 = tp2.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp2['Score']=[g*6+b for g,b in zip(tp2['GL'],tp2['BH'])]  # new line this version\n",
    "    tp2_avg = tp2.groupby(by='Team').aggregate('mean')\n",
    "    tp2_avg.columns = [str(col) + '_lstXgrd' for col in tp2_avg.columns]\n",
    "    if tp2_avg.shape[0]==0:\n",
    "        print('empty row generated for ',dt,' at ', venue,' team:',team)\n",
    "    return tp2_avg\n",
    "\n",
    "def get_pastX(x,team,dt,team_performaceDF,print_missing=False):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tp1 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt)] \n",
    "    tp1 = tp1.sort_values(by=['Date'],ascending=False)\n",
    "    tp1 = tp1.head(x)\n",
    "    tp1 = tp1.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp1['Score']=[g*6+b for g,b in zip(tp1['GL'],tp1['BH'])] # new line this version\n",
    "    tp1_avg = tp1.groupby(by='Team').aggregate('mean')\n",
    "    tp1_avg.columns = [str(col) + '_lstX' for col in tp1_avg.columns]\n",
    "    if tp1_avg.shape[0]==0 and print_missing:\n",
    "        print('empty row generated for ', dt,' team:',team)\n",
    "    return tp1_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version 29 Aug 2018 \n",
    "# adding more metrics to team performance:\n",
    "# Make main meric e.g. KI as absolute difference between home team and opponent\n",
    "# added 2 sets of metrics for team and opponent (suffixed with \"t\" and \"o\" respectively)\n",
    "\n",
    "# on Aug 30 - added relative version of team performance\n",
    "\n",
    "# on Aug 30 - added relative version of team performance\n",
    "# Subiaco = Perth Stadium, Football Park = Adelaide Oval\n",
    "\n",
    "def get_drive():\n",
    "    '''\n",
    "    this is to automate switching between home PC and laptop\n",
    "    it returns J:\\\\AFL\\\\ or D:\\\\AFL\\\\ depending if D:\\ is available\n",
    "    \n",
    "    No parameters required\n",
    "    '''\n",
    "    \n",
    "    import win32api\n",
    "    drives = win32api.GetLogicalDriveStrings()\n",
    "    drives = drives.split('\\000')[:-1]\n",
    "    if 'D:\\\\' in drives:\n",
    "        drive = 'D:\\\\AFL\\\\'\n",
    "    else:\n",
    "        drive = 'J:\\\\AFL\\\\'\n",
    "    return drive\n",
    "\n",
    "\n",
    "def get_proxy(proxy):\n",
    "        if proxy:\n",
    "            from os import environ\n",
    "            #pwd = input('Please enter your LAN Pwd')\n",
    "            environ[\"http_proxy\"]=\"http://c819325:sWeater78-@http-gw.tcif.telstra.com.au:8080\"\n",
    "            environ[\"https_proxy\"]=environ.get(\"http_proxy\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fix_round(round_in):\n",
    "    '''\n",
    "    this function convert Round values into sequential integers\n",
    "    '''\n",
    "    if round_in=='QF':\n",
    "        rnd='25'\n",
    "    elif round_in=='EF':\n",
    "        rnd='26'\n",
    "    elif round_in=='SF':\n",
    "        rnd='27'\n",
    "    elif round_in=='PF':\n",
    "        rnd='28'\n",
    "    elif round_in=='GF':\n",
    "        rnd='29'\n",
    "    elif round_in[0]=='R':\n",
    "        rnd=round_in[1:]\n",
    "    else:\n",
    "        rnd=round_in\n",
    "    return int(rnd)\n",
    "\n",
    "def fix_team_name(name):\n",
    "    '''\n",
    "    this function converts any team name to a consistent\n",
    "    set of  names which are usable for joins\n",
    "    '''\n",
    "    if 'Crows' in name:\n",
    "        team_name='Adelaide'\n",
    "    elif name.strip()=='Adelaide Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='AD':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='Crows':\n",
    "        team_name='Adelaide'\n",
    "    elif name=='BL':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='Lions':\n",
    "        team_name='Brisbane Lions'\n",
    "    elif name=='CA':\n",
    "        team_name='Carlton'\n",
    "    elif name=='Blues':\n",
    "        team_name='Carlton'\n",
    "    elif name=='CW':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='Magpies':\n",
    "        team_name='Collingwood'\n",
    "    elif name=='ES':\n",
    "        team_name='Essendon'\n",
    "    elif name=='Bombers':\n",
    "        team_name='Essendon'\n",
    "    elif name=='FR':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='Dockers':\n",
    "        team_name='Fremantle'\n",
    "    elif name=='GE':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='Geelong Cats':\n",
    "        team_name='Geelong'\n",
    "    elif name=='GC':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='Gold Coast Suns':\n",
    "        team_name='Gold Coast'\n",
    "    elif name=='GWS Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GWS':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='Giants':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='GW Sydney':\n",
    "        team_name='Greater Western Sydney'\n",
    "    elif name=='HW':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='Hawks':\n",
    "        team_name='Hawthorn'\n",
    "    elif name=='ME':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Demons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='Deamons':\n",
    "        team_name='Melbourne'\n",
    "    elif name=='KA':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='NM':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='Kangaroos':\n",
    "        team_name='North Melbourne'\n",
    "    elif name=='PA':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='Power':\n",
    "        team_name='Port Adelaide'\n",
    "    elif name=='RI':\n",
    "        team_name='Richmond'\n",
    "    elif name=='Tigers':\n",
    "        team_name='Richmond'\n",
    "    elif name=='SK':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='Saints':\n",
    "        team_name='St Kilda'\n",
    "    elif name=='SY':\n",
    "        team_name='Sydney'\n",
    "    elif 'Swans' in name:\n",
    "        team_name='Sydney'\n",
    "    elif name=='WC':\n",
    "        team_name='West Coast'\n",
    "    elif name=='West Coast Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='Eagles':\n",
    "        team_name='West Coast'\n",
    "    elif name=='WB':\n",
    "        team_name='Western Bulldogs'\n",
    "    elif name=='Bulldogs':\n",
    "        team_name='Western Bulldogs'\n",
    "    else:\n",
    "        team_name=name\n",
    "    return team_name\n",
    "\n",
    "def fix_venue(name):\n",
    "    if name=='AAMI':\n",
    "        ground = 'Olympic Park'\n",
    "    elif name=='ANZ':\n",
    "        ground = 'Stadium Australia'\n",
    "    elif name=='Football Park':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Adelaide':\n",
    "        ground='Adelaide Oval'\n",
    "    elif name=='Aurora':\n",
    "        ground = 'York Park'\n",
    "    elif name=='Blacktown':\n",
    "        ground='Blacktown'\n",
    "    elif name=='Blundstone Arena':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name=='Blundstone':\n",
    "        ground = 'Bellerive Oval'\n",
    "    elif name==\"Cazaly's\":\n",
    "        ground= \"Cazaly's Stadium\"\n",
    "    elif name=='Domain':\n",
    "        ground='Subiaco'\n",
    "    elif name=='Etihad Stadium':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='Etihad':\n",
    "        ground = 'Docklands'\n",
    "    elif name=='GMHBA Stadium':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='GMHBA':\n",
    "        ground='Kardinia Park'\n",
    "    elif name=='Gabba':\n",
    "        ground = 'Gabba'\n",
    "    elif name=='Jiangwan':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='Jiangwan Stadium, China':\n",
    "        ground = 'Jiangwan Stadium'\n",
    "    elif name=='M.C.G':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='MCG':\n",
    "        ground = 'M.C.G.'\n",
    "    elif name=='Mars Stadium, Ballarat':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Mars':\n",
    "        ground = 'Eureka Stadium'\n",
    "    elif name=='Metricon Stadium':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Metricon':\n",
    "        ground = 'Carrara'\n",
    "    elif name=='Perth':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='Subiaco':\n",
    "        ground='Perth Stadium'\n",
    "    elif name=='SCG':\n",
    "        ground='S.C.G.'\n",
    "    elif name=='Spotless Stadium':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='Spotless':\n",
    "        ground='Sydney Showground'\n",
    "    elif name=='UNSW Canberra Oval':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='StarTrack':\n",
    "        ground='Manuka Oval'\n",
    "    elif name=='Treager Park, Alice Springs':\n",
    "        ground='Traeger Park'\n",
    "    elif name=='TIO Stadium, Darwin':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='TIO':\n",
    "        ground='Marrara Oval'\n",
    "    elif name=='University of Tasmania Stadium':\n",
    "        ground='York Park'\n",
    "    elif name=='UTAS':\n",
    "        ground='York Park'\n",
    "    elif name=='Westpac':\n",
    "        ground='Wellington'\n",
    "    else:\n",
    "        ground=name\n",
    "    return ground\n",
    "\n",
    "def get_ladder(seas_from,seas_to,proxy=False):\n",
    "    '''\n",
    "    this is just to get the ladder history\n",
    "\n",
    "    Input required - update season from and to in the function call at the bottom\n",
    "    this function returns a dataframe for AFL ladder position history\n",
    "    seas_from - season to start from\n",
    "    seas_to - season end - inclusive\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    ladder = pd.DataFrame(columns=['Team','Games','Points','Percentage','Round','Position','Season'])\n",
    "    for season in range(seas_from-1,seas_to+1): \n",
    "        cur_url = 'http://afltables.com/afl/seas/'+str(season)+'.html'\n",
    "        dfs = pd.read_html(cur_url)\n",
    "\n",
    "        for df in dfs:\n",
    "            if df.columns.nlevels>1:\n",
    "                break\n",
    "            if len(df)>1 and 'Ladder' in df[0][0] and 'Rd' in df[0][0] and len(df.columns)>2:\n",
    "                rnd = df[0][0][3:5]\n",
    "                ldr = df.copy() \n",
    "                ldr = ldr.drop(0,0)\n",
    "                ldr.columns = ['Team','Games','Points','Percentage']\n",
    "                ldr['Round']=rnd\n",
    "                ldr['Position']=ldr.index\n",
    "                ldr['Season']=season\n",
    "                ladder = pd.concat([ladder,ldr])\n",
    "    ladder['Team'] = [fix_team_name(x) for x in ladder['Team']]\n",
    "    \n",
    "    # repeat last round for last and until 29\n",
    "    ladder_f = ladder.copy()\n",
    "    ladder_f.drop_duplicates(subset=['Team','Season'], keep='last', inplace=True)\n",
    "\n",
    "    # get last round for each season\n",
    "    ladder_y = ladder_f.copy()\n",
    "    ladder_y.drop_duplicates(subset=['Season'], keep='last', inplace=True)\n",
    "    ladder_y=ladder_y.drop(['Team','Games','Points','Percentage','Position'],1)\n",
    "    rnd=[]\n",
    "    seas=[]\n",
    "    for index, row in ladder_y.iterrows():\n",
    "        st = int(row.Round)\n",
    "        #print(type(st))\n",
    "        for i in range(st+1,30):\n",
    "            rnd.append(i)\n",
    "            seas.append(row.Season)\n",
    "    ldr = pd.DataFrame()\n",
    "    ldr['Season'] = seas\n",
    "    ldr['Round'] = rnd\n",
    "    #ldr = pd.merge(ladder_f.drop(['Round'],1),ldr,how='inner',on=['Season'])\n",
    "    ladder = pd.concat([ladder,ldr],sort=False)\n",
    "    ladder = ladder.sort_values(by=['Team','Season'],axis=0)\n",
    "    ladder['PosOld']=ladder.Position.shift(1)  #previous ladder position taken\n",
    "    ladder = ladder.drop(['Position'],1)\n",
    "    ladder['Round']= [int(x) for x in ladder['Round']]\n",
    "    ladder=ladder.dropna(axis=0)\n",
    "    ladder['PosOld']= [int(x) for x in ladder['PosOld']]  \n",
    "    return ladder\n",
    "\n",
    "def get_fixture(proxy=False):\n",
    "    '''\n",
    "    this is to get AFL fixture from theroar.com.au\n",
    "    set proxy=True if you are on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    url='https://www.theroar.com.au/afl-draw/'\n",
    "    sauce = urllib.request.urlopen(url)\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "    fixture = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "\n",
    "    for x in soup.find_all('tbody'):\n",
    "        rnd_counter = 0\n",
    "\n",
    "        for y in x.find_all('tr'):\n",
    "\n",
    "            if y.find_all('strong'):\n",
    "                rnd_counter +=1\n",
    "\n",
    "            else:\n",
    "                if not y.find_all('h3') and 'Byes' not in y.text and 'TBC' not in y.text:\n",
    "                    dt,teams,venue,tm = y.text.strip().split('\\n')\n",
    "                    if dt == 'Sar Apr 21':\n",
    "                        dt = 'Sat Apr 21'\n",
    "\n",
    "                    dt = parser.parse(dt)\n",
    "                    if teams == 'North Melbourne Carlton':\n",
    "                            hm_team = 'North Melbourne'\n",
    "                            aw_team = 'Carlton'\n",
    "                    else:\n",
    "                        hm_team, aw_team = teams.split(' vs ')\n",
    "\n",
    "                    #print(rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue))\n",
    "                    df = pd.DataFrame(columns=['Round','Date','HomeTeam','AwayTeam','Venue'])\n",
    "                    df.loc[0]=[rnd_counter,dt,fix_team_name(hm_team),fix_team_name(aw_team),fix_venue(venue)]\n",
    "                    fixture = pd.concat([fixture,df])\n",
    "    return fixture\n",
    "\n",
    "def get_odds_history(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this function gets odds history from footywire.com\n",
    "    min season from is 2010- so it will make the min date 2010 if less than that\n",
    "    set proxy=True if on LAN\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    " \n",
    "    if season_from<2010:\n",
    "        season_from=2010\n",
    "    odds_history=pd.DataFrame()\n",
    "    for season in range(season_from,season_to+1):\n",
    "        print('Getting odds for season',season,'...')\n",
    "        sauce = urllib.request.urlopen('https://www.footywire.com/afl/footy/afl_betting?year='+str(season))\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "\n",
    "        for x in soup.find_all('div',class_ ='datadiv'):\n",
    "            date=[]\n",
    "            venue=[]\n",
    "            team_HM=[]\n",
    "            odds_HM=[]\n",
    "            team_AW=[]\n",
    "            odds_AW=[]\n",
    "            counter =0\n",
    "\n",
    "            home_team_cursor = True\n",
    "            for y in x.find_all('tr'):\n",
    "\n",
    "                for z in y.find_all('td',class_='data'):\n",
    "                    counter = counter+1\n",
    "                    if z.has_attr('height'):\n",
    "                        counter = 0\n",
    "                        #print('new game ',z.text)\n",
    "                        date.append(z.text)\n",
    "                    elif z.has_attr('rowspan'):\n",
    "                        #print('venue ', z.text)\n",
    "                        venue.append(z.text)\n",
    "                    elif not z.has_attr('align'):\n",
    "                        if counter == 2:\n",
    "                            #print('Home team: ', z.text)\n",
    "                            team_HM.append(z.text)\n",
    "                            home_team_cursor=True    \n",
    "                        else:\n",
    "                            #print('Away team: ', z.text)\n",
    "                            counter = 0\n",
    "                            team_AW.append(z.text)\n",
    "                            home_team_cursor=False\n",
    "                    elif counter ==3 and not home_team_cursor:\n",
    "                        #print('away team odds: ',z.text)\n",
    "                        odds_AW.append(z.text)\n",
    "                    elif counter==5 and home_team_cursor:\n",
    "                        #print('home team odds: ',z.text)\n",
    "                        odds_HM.append(z.text)\n",
    "        odds = pd.DataFrame()\n",
    "        odds['Date']=[parser.parse(x,dayfirst=True) for x in date]\n",
    "        odds['Venue']=[fix_venue(x) for x in venue]\n",
    "        odds['HomeTeam']=[fix_team_name(x) for x in team_HM]\n",
    "        odds['OddsHome']=[x for x in odds_HM]\n",
    "        odds['AwayTeam']=[fix_team_name(x) for x in team_AW]\n",
    "        odds['OddsAway']=[x for x in odds_AW]\n",
    "        odds_history = pd.concat([odds_history,odds])  \n",
    "    odds = odds.drop_duplicates(subset=['Date','HomeTeam','AwayTeam'],keep='last')\n",
    "    return odds_history\n",
    "\n",
    "def get_games(proxy=False):\n",
    "    \n",
    "    '''\n",
    "    this function gets past games history\n",
    "    and gets attendance where it is available\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    a =get_proxy(proxy)\n",
    "        \n",
    "    col_specification =[(7, 15), (16, 33), (51, 68), (87, 116),(117,128)]\n",
    "    attend = pd.read_fwf('https://afltables.com/afl/stats/biglists/bg7.txt', \n",
    "                         colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    attend.columns = ['Attendance', 'HomeTeam', 'AwayTeam', 'Venue','Date']\n",
    "    attend['Date']  = pd.to_datetime(attend['Date'],dayfirst=True)\n",
    "    attend['Attendance'] = attend.Attendance.str.replace(r\"[\\*]\",'')\n",
    "    col_specification =[(0, 5), (7, 18), (24, 27), (29, 46),(47,63), (64,81),(82,99),(100,117)]\n",
    "    games= pd.read_fwf('http://afltables.com/afl/stats/biglists/bg3.txt', \n",
    "                       colspecs=col_specification, skiprows=[0],parse_dates=[1])\n",
    "    games.columns = ['GameID', 'Date', 'Round', 'HomeTeam', 'ScoreHm','AwayTeam','ScoreAw','Venue']\n",
    "    games = pd.merge(games,attend,how='left',on=['Venue','Date','HomeTeam','AwayTeam'])\n",
    "\n",
    "    #fix rounds in games\n",
    "    games['Round'] = [fix_round(x) for x in games['Round']]\n",
    "    \n",
    "    games['Year']=games['Date'].map(lambda x: x.year)\n",
    "\n",
    "    #fix North Melb in games\n",
    "    games['HomeTeam'] = [fix_team_name(x) for x in games['HomeTeam']]\n",
    "    games['AwayTeam'] = [fix_team_name(x) for x in games['AwayTeam']]\n",
    "\n",
    "    # get result\n",
    "    games['H'] = [int(x.split('.')[2]) for x in games['ScoreHm']]\n",
    "    games['A'] = [int(x.split('.')[2]) for x in games['ScoreAw']]\n",
    "    games = games.drop(['ScoreHm','ScoreAw'],1)\n",
    "    games['Result'] = [round((x[0] /(x[0] +x[1])),3) for x in zip(games['H'],games['A'])]\n",
    "    #games = games.drop(['H','A'],1)\n",
    "    games['ResultWL'] = [1 if x>=0.5 else 0 for x in games.Result]\n",
    "    games['Venue']=[fix_venue(x) for x in games['Venue']]\n",
    "    return games\n",
    "\n",
    "\n",
    "def get_team_performance_hist(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this is to get the team performance history\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BHt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CGt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BRt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CMt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%t'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    #added Score metric SC\n",
    "    team_performace['SCt'] = [g*6+b for g,b in zip(team_performace['GLt'],team_performace['BHt'])]\n",
    "    # this version change - getting opponent's stats \"o\" in column name is for \"opposition\"\n",
    "    team_performace['KIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['KI']]\n",
    "    team_performace['MKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MK']]\n",
    "    team_performace['HBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HB']]\n",
    "    team_performace['DIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['DI']]\n",
    "    team_performace['GLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GL']]\n",
    "    team_performace['BHo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BH']]\n",
    "    team_performace['HOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HO']]\n",
    "    team_performace['TKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['TK']]\n",
    "    team_performace['RBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['RB']]\n",
    "    team_performace['IFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['IF']]\n",
    "    team_performace['CLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CL']]\n",
    "    team_performace['CGo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CG']]\n",
    "    team_performace['FFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FF']]\n",
    "    team_performace['FAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FA']]\n",
    "    team_performace['BRo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BR']]\n",
    "    team_performace['CPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CP']]\n",
    "    team_performace['UPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['UP']]\n",
    "    team_performace['CMo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CM']]\n",
    "    team_performace['MIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MI']]\n",
    "    team_performace['1%o'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['1%']]\n",
    "    team_performace['BOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BO']]\n",
    "    team_performace['GAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GA']]\n",
    "    team_performace['SCo'] = [g*6+b for g,b in zip(team_performace['GLo'],team_performace['BHo'])]\n",
    "    #added Score metric SC\n",
    "    \n",
    "    #difference metric\n",
    "    team_performace['KI'] = [t-o for t,o in zip(team_performace['KIt'],team_performace['KIo'])]\n",
    "    team_performace['MK'] = [t-o for t,o in zip(team_performace['MKt'],team_performace['MKo'])]\n",
    "    team_performace['HB'] = [t-o for t,o in zip(team_performace['HBt'],team_performace['HBo'])]\n",
    "    team_performace['DI'] = [t-o for t,o in zip(team_performace['DIt'],team_performace['DIo'])]\n",
    "    team_performace['GL'] = [t-o for t,o in zip(team_performace['GLt'],team_performace['GLo'])]\n",
    "    team_performace['BH'] = [t-o for t,o in zip(team_performace['BHt'],team_performace['BHo'])]\n",
    "    team_performace['HO'] = [t-o for t,o in zip(team_performace['HOt'],team_performace['HOo'])]\n",
    "    team_performace['TK'] = [t-o for t,o in zip(team_performace['TKt'],team_performace['TKo'])]\n",
    "    team_performace['RB'] = [t-o for t,o in zip(team_performace['RBt'],team_performace['RBo'])]\n",
    "    team_performace['IF'] = [t-o for t,o in zip(team_performace['IFt'],team_performace['IFo'])]\n",
    "    team_performace['CL'] = [t-o for t,o in zip(team_performace['CLt'],team_performace['CLo'])]\n",
    "    team_performace['CG'] = [t-o for t,o in zip(team_performace['CGt'],team_performace['CGo'])]\n",
    "    team_performace['FF'] = [t-o for t,o in zip(team_performace['FFt'],team_performace['FFo'])]\n",
    "    team_performace['FA'] = [t-o for t,o in zip(team_performace['FAt'],team_performace['FAo'])]\n",
    "    team_performace['BR'] = [t-o for t,o in zip(team_performace['BRt'],team_performace['BRo'])]\n",
    "    team_performace['CP'] = [t-o for t,o in zip(team_performace['CPt'],team_performace['CPo'])]\n",
    "    team_performace['UP'] = [t-o for t,o in zip(team_performace['UPt'],team_performace['UPo'])]\n",
    "    team_performace['CM'] = [t-o for t,o in zip(team_performace['CMt'],team_performace['CMo'])]\n",
    "    team_performace['MI'] = [t-o for t,o in zip(team_performace['MIt'],team_performace['MIo'])]\n",
    "    team_performace['1%'] = [t-o for t,o in zip(team_performace['1%t'],team_performace['1%o'])]\n",
    "    team_performace['BO'] = [t-o for t,o in zip(team_performace['BOt'],team_performace['BOo'])]\n",
    "    team_performace['GA'] = [t-o for t,o in zip(team_performace['GAt'],team_performace['GAo'])]\n",
    "    team_performace['SC'] = [t-o for t,o in zip(team_performace['SCt'],team_performace['SCo'])]\n",
    "    return team_performace\n",
    "\n",
    "def get_team_performance_hist_rel(season_from,season_to,proxy=False):\n",
    "    '''\n",
    "    this relative version of team performance history\n",
    "    main metric is expressed as team's relative advantage over the opponent\n",
    "    e.g. if team goals is 12 and opponent goals is 6\n",
    "    the main GL metric shows (12-6)/(12+6) = 0.333\n",
    "    if both team and opponent metrics are zero then combined one =0\n",
    "    so values range from -1 to +1\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from dateutil import parser\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "\n",
    "    games = get_games()\n",
    "    games_H = games.copy()\n",
    "    games_H['Team']=games_H['HomeTeam']\n",
    "    games_H['HomeFlag']=1\n",
    "    games_H = games_H.drop(['HomeTeam','AwayTeam'], 1)\n",
    "\n",
    "    games_A = games.copy()\n",
    "    games_A['Team']=games_A['AwayTeam']\n",
    "    games_A['HomeFlag']=0\n",
    "    games_A = games_A.drop(['HomeTeam','AwayTeam'], 1)\n",
    "    games_for_join = pd.concat([games_H,games_A])\n",
    "\n",
    "    team_performace = pd.DataFrame()\n",
    "    for season in range(season_from-4,season_to+1):\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/'+str(season)+'t.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        i=0\n",
    "        for x in soup.find_all('th'):\n",
    "            if 'Team Statistics [Players]' in x.text:\n",
    "                tms.append(x.text[0:-26])\n",
    "                i+=1\n",
    "        cur_url = 'https://afltables.com/afl/stats/'+str(season)+'t.html'\n",
    "        dfs = pd.read_html(cur_url,header=1)\n",
    "        all_dfs = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(dfs)):\n",
    "            if i % 2==0:\n",
    "                x= pd.concat([dfs[i],dfs[i+1].drop(['#','Opponent'],1)],1)\n",
    "                x['Team']=tms[i]\n",
    "                all_dfs = pd.concat([all_dfs, x])\n",
    "        all_dfs=all_dfs[all_dfs['#'] != 'W-D-L']\n",
    "        all_dfs['Year']=season\n",
    "        team_performace = pd.concat([team_performace,all_dfs])\n",
    "    team_performace = team_performace.rename(columns={'#': 'Round'})\n",
    "    team_performace['Round'] = [fix_round(x) for x in team_performace['Round']]\n",
    "    team_performace['Team'] = [fix_team_name(x) for x in team_performace['Team']]\n",
    "    team_performace['Opponent'] = [fix_team_name(x) for x in team_performace['Opponent']]\n",
    "\n",
    "    team_performace = pd.merge(team_performace,games_for_join.drop(['GameID','Attendance','Result'],1),how='left',on=\n",
    "\n",
    "['Year','Round','Team'])\n",
    "\n",
    "    team_performace['KIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['KI']]\n",
    "    team_performace['MKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MK']]\n",
    "    team_performace['HBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HB']]\n",
    "    team_performace['DIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['DI']]\n",
    "    team_performace['GLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GL']]\n",
    "    team_performace['BHt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BH']]\n",
    "    team_performace['HOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['HO']]\n",
    "    team_performace['TKt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['TK']]\n",
    "    team_performace['RBt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['RB']]\n",
    "    team_performace['IFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['IF']]\n",
    "    team_performace['CLt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CL']]\n",
    "    team_performace['CGt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CG']]\n",
    "    team_performace['FFt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FF']]\n",
    "    team_performace['FAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['FA']]\n",
    "    team_performace['BRt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BR']]\n",
    "    team_performace['CPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CP']]\n",
    "    team_performace['UPt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['UP']]\n",
    "    team_performace['CMt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['CM']]\n",
    "    team_performace['MIt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['MI']]\n",
    "    team_performace['1%t'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['1%']]\n",
    "    team_performace['BOt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['BO']]\n",
    "    team_performace['GAt'] = [0 if len(x.split('-')[0])==0 else int(x.split('-')[0]) for x in team_performace['GA']]\n",
    "    #added Score metric SC\n",
    "    team_performace['SCt'] = [g*6+b for g,b in zip(team_performace['GLt'],team_performace['BHt'])]\n",
    "    # this version change - getting opponent's stats \"o\" in column name is for \"opposition\"\n",
    "    team_performace['KIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['KI']]\n",
    "    team_performace['MKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MK']]\n",
    "    team_performace['HBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HB']]\n",
    "    team_performace['DIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['DI']]\n",
    "    team_performace['GLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GL']]\n",
    "    team_performace['BHo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BH']]\n",
    "    team_performace['HOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['HO']]\n",
    "    team_performace['TKo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['TK']]\n",
    "    team_performace['RBo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['RB']]\n",
    "    team_performace['IFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['IF']]\n",
    "    team_performace['CLo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CL']]\n",
    "    team_performace['CGo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CG']]\n",
    "    team_performace['FFo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FF']]\n",
    "    team_performace['FAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['FA']]\n",
    "    team_performace['BRo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BR']]\n",
    "    team_performace['CPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CP']]\n",
    "    team_performace['UPo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['UP']]\n",
    "    team_performace['CMo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['CM']]\n",
    "    team_performace['MIo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['MI']]\n",
    "    team_performace['1%o'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['1%']]\n",
    "    team_performace['BOo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['BO']]\n",
    "    team_performace['GAo'] = [0 if len(x.split('-')[1])==0 else int(x.split('-')[1]) for x in team_performace['GA']]\n",
    "    team_performace['SCo'] = [g*6+b for g,b in zip(team_performace['GLo'],team_performace['BHo'])]\n",
    "    #added Score metric SC\n",
    "    \n",
    "    #difference metric - now relative version ranging from -1 to +1 where 0 is even performance\n",
    "    team_performace['KI'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['KIt'],team_performace['KIo'])]\n",
    "    team_performace['MK'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['MKt'],team_performace['MKo'])]\n",
    "    team_performace['HB'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['HBt'],team_performace['HBo'])]\n",
    "    team_performace['DI'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['DIt'],team_performace['DIo'])]\n",
    "    team_performace['GL'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['GLt'],team_performace['GLo'])]\n",
    "    team_performace['BH'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['BHt'],team_performace['BHo'])]\n",
    "    team_performace['HO'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['HOt'],team_performace['HOo'])]\n",
    "    team_performace['TK'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['TKt'],team_performace['TKo'])]\n",
    "    team_performace['RB'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['RBt'],team_performace['RBo'])]\n",
    "    team_performace['IF'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['IFt'],team_performace['IFo'])]\n",
    "    team_performace['CL'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CLt'],team_performace['CLo'])]\n",
    "    team_performace['CG'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CGt'],team_performace['CGo'])]\n",
    "    team_performace['FF'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['FFt'],team_performace['FFo'])]\n",
    "    team_performace['FA'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['FAt'],team_performace['FAo'])]\n",
    "    team_performace['BR'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['BRt'],team_performace['BRo'])]\n",
    "    team_performace['CP'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CPt'],team_performace['CPo'])]\n",
    "    team_performace['UP'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['UPt'],team_performace['UPo'])]\n",
    "    team_performace['CM'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['CMt'],team_performace['CMo'])]\n",
    "    team_performace['MI'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['MIt'],team_performace['MIo'])]\n",
    "    team_performace['1%'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['1%t'],team_performace['1%o'])]\n",
    "    team_performace['BO'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['BOt'],team_performace['BOo'])]\n",
    "    team_performace['GA'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['GAt'],team_performace['GAo'])]\n",
    "    team_performace['SC'] = [(t-o)/(t+o) if (t+o)>0 else 0 for t,o in zip(team_performace['SCt'],team_performace['SCo'])]\n",
    "    return team_performace\n",
    "\n",
    "def get_lineup(year,rnd,proxy=False):\n",
    "    '''\n",
    "    returns all available line-up for given year\n",
    "    year - current year you need to specify\n",
    "    rnd - current round where line-up has been released (could be improved into auto later)\n",
    "    proxy = True if on LAN\n",
    "    Pre-requisites: \n",
    "     1.TeamRef.csv - file which maps team names to AFL line-up abbreviated names\n",
    "     2.Fixture function is used\n",
    "\n",
    "    '''    \n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from dateutil import parser\n",
    "\n",
    "\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "\n",
    "    fixture = get_fixture(proxy)\n",
    "    fixture = fixture[fixture.Round==rnd]  #this limits to current round only\n",
    "    teams = pd.read_csv(get_drive()+'TeamRef.csv')\n",
    "\n",
    "    this_1 = pd.merge(fixture,teams,how=\"inner\",left_on=['HomeTeam'],right_on=['Team'])\n",
    "    this_2 = pd.merge(this_1,teams,how=\"inner\",left_on=['AwayTeam'],right_on=['Team'])\n",
    "    rounds = this_2.drop(['Team_x','Team_y'],1)\n",
    "    rounds['Game'] = [x + '-v-' +y for x,y in zip(rounds.AFL_Team_Nm_x,rounds.AFL_Team_Nm_y)]\n",
    "    rounds = rounds.drop(['AFL_Team_Nm_x','AFL_Team_Nm_y'],1)\n",
    "\n",
    "\n",
    "    # now get available line-up for player ref working\n",
    "\n",
    "    #rounds = rounds[rounds.Round<=max_round]    # needs updating, just available\n",
    "\n",
    "    lineup=pd.DataFrame()\n",
    "    for gm,rnd in zip(rounds['Game'],rounds['Round']):\n",
    "        url='http://www.afl.com.au/match-centre/'+str(year)+'/'+str(rnd)+'/'+gm\n",
    "        \n",
    "        sauce = urllib.request.urlopen(url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        tms=[]\n",
    "        plrs=[]\n",
    "        for x in soup.find_all('div',class_ ='lineup'):\n",
    "            for t in x.find_all('div',class_ ='text-inouts'):\n",
    "                team=''\n",
    "                for tm in t.find_all('h4'):\n",
    "                    team=tm.text\n",
    "\n",
    "                for p in t.find_all('div',class_ ='posGroup'):\n",
    "                    position=''\n",
    "                    for pos in p.find_all('p',class_ ='pos'):\n",
    "                        position =pos.text.strip()\n",
    "                    for player in p.find_all('li'):\n",
    "                        if position in ['B','HB','C','HF','F','Fol','I/C']:\n",
    "                            tms.append(team)\n",
    "                            plrs.append(player.text.strip().strip(','))\n",
    "\n",
    "        d = pd.DataFrame()\n",
    "        d['Team'] = tms\n",
    "        d['Player'] = plrs\n",
    "        lineup=pd.concat([lineup,d])\n",
    "    lineup['Team']=[fix_team_name(x) for x in lineup['Team']]\n",
    "    return lineup\n",
    "\n",
    "def get_player_base(proxy):\n",
    "    '''\n",
    "    !!! run only when need to update for new players !!!\n",
    "    returns a dataframe of player base table to enable to skip older players\n",
    "    e.g. players[players.DoB>'1975-01-01']  this gives 2.5k player subset\n",
    "    \n",
    "    typical use - to create Players.csv file in AFL directory - !!! pre-requisite for getting player performance\n",
    "\n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    from string import ascii_uppercase\n",
    "    from dateutil import parser\n",
    "    import datetime\n",
    "    a =get_proxy(proxy)\n",
    "    \n",
    "    players = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days'])\n",
    "\n",
    "    # get player urls\n",
    "    links = []\n",
    "    for c in ascii_uppercase :\n",
    "        sauce = urllib.request.urlopen('https://afltables.com/afl/stats/players'+c+'_idx.html')\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "        for url in soup.find_all('a',href=True):\n",
    "            links.append('https://afltables.com/afl/stats/'+url['href'])\n",
    "    # now remove non-player links - ones that contain 'idx'\n",
    "    links = [item for item in links if 'players' in item and 'idx' not in item and 'afl_index' not in item]        \n",
    "\n",
    "    for cur_url in links:\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        #Name\n",
    "        x = soup.find_all('h1')\n",
    "        name = x[0].text\n",
    "\n",
    "        #DoB\n",
    "        found_dob=False\n",
    "\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Born:':\n",
    "                dob = x.next_sibling\n",
    "                found_dob=True\n",
    "                break\n",
    "        if found_dob:\n",
    "            dob=parser.parse(dob[0:11],dayfirst=True)\n",
    "        else:\n",
    "            dob = datetime.datetime(1900, 1, 1, 0, 0)\n",
    "\n",
    "        #Debut\n",
    "        found_debut = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Debut:':\n",
    "                debut = x.next_sibling\n",
    "                found_debut=True\n",
    "                break\n",
    "        if found_debut:\n",
    "            debut =debut.split()\n",
    "            debut1 = ''.join(c for c in debut[0] if c.isdigit())\n",
    "            if len(debut)>1:\n",
    "                debut2 = ''.join(c for c in debut[1] if c.isdigit())\n",
    "                debut = int(debut1)+int(debut2)/365\n",
    "            else:\n",
    "                debut = int(debut1)\n",
    "        else:\n",
    "            debut = 100\n",
    "        #age last played\n",
    "        found_last = False\n",
    "        for x in soup.find_all('b'):\n",
    "            if x.text == 'Last:':\n",
    "                age_last = x.next_sibling\n",
    "                found_last=True\n",
    "                break\n",
    "        if found_last:\n",
    "            age_last =age_last.split()\n",
    "            a1 = ''.join(c for c in age_last[0] if c.isdigit())\n",
    "            if len(age_last)>1:\n",
    "                a2 = ''.join(c for c in age_last[1] if c.isdigit())\n",
    "                age_last = int(a1)*365.25+int(a2) #in days\n",
    "            else:\n",
    "                age_last = int(a1)*365.25\n",
    "        else:\n",
    "            age_last = 40*365.25\n",
    "        today = datetime.datetime.today()\n",
    "        last_played_date = dob + datetime.timedelta(days=age_last)\n",
    "        since_last_game=today-last_played_date\n",
    "        df = pd.DataFrame(columns=['Name','DoB','Url','Debut_Age','Age_Last_Played_Days','Last_Played_Date'])\n",
    "        df.loc[0]=[name,dob,cur_url,debut,age_last,last_played_date]\n",
    "        players = pd.concat([players,df])\n",
    "        print(name)\n",
    "    return players\n",
    "\n",
    "\n",
    "\n",
    "def get_player_perf(DoB_min='1975-01-01',proxy=False):\n",
    "    '''\n",
    "    Use this only once per complete round and save into CSV as it takes a while to run\n",
    "    this function returns a dataframe of player performance history\n",
    "    Entire player history is returned\n",
    "    DoB_min is limiting factor to get only player born after the date - for performance reasons\n",
    "    change the default if you need to go more back into older players or in reverse\n",
    "    Pre-requisite: Players.csv file exists in the AFL directory\n",
    "    set proxy=True when on office LAN\n",
    "    \n",
    "    '''\n",
    "    import bs4 as bs\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "\n",
    "    a =get_proxy(proxy)\n",
    "\n",
    "    players = pd.read_csv(get_drive()+'Players.csv')\n",
    "    players =players[players['DoB']>DoB_min]\n",
    "\n",
    "    player_stats = pd.DataFrame(columns=['Url','Team','Year'])\n",
    "\n",
    "    for cur_url in players.Url:\n",
    "        print(cur_url)\n",
    "        sauce = urllib.request.urlopen(cur_url)\n",
    "        soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        found=False\n",
    "        dfs=[]\n",
    "        for table in soup.find_all('table'):\n",
    "            #t1=tables[7]\n",
    "            t=table.find('tbody')\n",
    "            res = []\n",
    "            row = []\n",
    "            rows = t.find_all('tr')\n",
    "            for tr in rows:\n",
    "                for td in tr.find_all('td'):\n",
    "                    row.append(td.text)\n",
    "                res.append(row)\n",
    "                row = []\n",
    "            df=pd.DataFrame(data=res)\n",
    "\n",
    "            if len(df.columns)==28: # found first game\n",
    "                    found = True\n",
    "            if found:\n",
    "                h=table.find('thead')\n",
    "                h1 = h.find('tr')\n",
    "                h2 = h1.find('th')\n",
    "                header =h2.text\n",
    "                team_year = header.split('-')\n",
    "                team = team_year[0].strip()\n",
    "                year = team_year[1].strip()\n",
    "                df['Url']=cur_url\n",
    "                df['Team']=team\n",
    "                df['Year']=year\n",
    "                player_stats = pd.concat([player_stats,df])\n",
    "    player_stats = player_stats.rename(columns={0:'GameNo',1:'Opponent',2:'Round',3:'Result',4:'Jersey',5:'KI',6:'MK',7:'HB',8:'DI',9:'GL',10:'BH',11:'HO',12:'TK',13:'RB',14:'IF',15:'CL',16:'CG',17:'FF',18:'FA',19:'BR',20:'CP',21:'UP',22:'CM',23:'MI',24:'1%',25:'BO',26:'GA',27:'%P'})\n",
    "    player_stats['Round']=[fix_round(x) for x in player_stats['Round']]\n",
    "\n",
    "\n",
    "    games_set = get_games(proxy=False)\n",
    "\n",
    "\n",
    "\n",
    "    #create one game row for each team\n",
    "    gamesH = games_set.drop(['AwayTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesA = games_set.drop(['HomeTeam','Venue','Attendance','Result','ResultWL'],1)\n",
    "    gamesH=gamesH.rename(columns={'HomeTeam':'Team'})\n",
    "    gamesA=gamesA.rename(columns={'AwayTeam':'Team'})\n",
    "    gamesAH=pd.concat([gamesH,gamesA])\n",
    "    gamesAH['Year'] = [str(x) for x in gamesAH['Year']]\n",
    "    # get date and game id for each player record\n",
    "    player_stats=pd.merge(player_stats,gamesAH,how='inner',on=['Team','Year','Round'])\n",
    "    player_stats=player_stats.drop_duplicates(subset=['Url','Year','Round'],keep='first')\n",
    "    \n",
    "    return player_stats\n",
    "\n",
    "def get_pastXthis_opponent(x,team,opponent,dt,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, opponent, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    #last 3 against this team\n",
    "    tp = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Opponent']==opponent) ]  # later row.Team\n",
    "    tp = tp.sort_values(by=['Date'],ascending=False)\n",
    "    tp = tp.head(x)\n",
    "    tp = tp.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "\n",
    "    tp_avg = tp.groupby(by='Team').aggregate('mean')\n",
    "    tp_avg.columns = [str(col) + '_lstXopp' for col in tp_avg.columns]\n",
    "    if tp_avg.shape[0]==0:\n",
    "        print('empty row generated for ', dt,' team:',team, ' vs.', opponent)\n",
    "    return tp_avg\n",
    "\n",
    "def get_pastXground(x,team,dt,venue,team_performaceDF):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date and venue of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "    tp2 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt) & (team_performaceDF['Venue'] == venue)] \n",
    "    tp2 = tp2.sort_values(by=['Date'],ascending=False)\n",
    "    tp2 = tp2.head(x)\n",
    "    tp2 = tp2.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp2_avg = tp2.groupby(by='Team').aggregate('mean')\n",
    "    tp2_avg.columns = [str(col) + '_lstXgrd' for col in tp2_avg.columns]\n",
    "    if tp2_avg.shape[0]==0:\n",
    "        print('empty row generated for ',dt,' at ', venue,' team:',team)\n",
    "    return tp2_avg\n",
    "\n",
    "def get_pastX(x,team,dt,team_performaceDF,print_missing=False):\n",
    "    '''\n",
    "    this function gets previous team performance coming to this game\n",
    "    takes x(how many games of history), team, date of current game, team stats dataframe to get games prior to this\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tp1 = team_performaceDF[(team_performaceDF['Team']==team) & (team_performaceDF['Date'] <dt)] \n",
    "    tp1 = tp1.sort_values(by=['Date'],ascending=False)\n",
    "    tp1 = tp1.head(x)\n",
    "    tp1 = tp1.drop(['Round','Date', 'HomeFlag','Year'],1)\n",
    "    tp1_avg = tp1.groupby(by='Team').aggregate('mean')\n",
    "    tp1_avg.columns = [str(col) + '_lstX' for col in tp1_avg.columns]\n",
    "    if tp1_avg.shape[0]==0 and print_missing:\n",
    "        print('empty row generated for ', dt,' team:',team)\n",
    "    return tp1_avg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
